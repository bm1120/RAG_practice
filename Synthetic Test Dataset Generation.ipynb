{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyC06D**********\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['GOOGLE_API_KEY'][:10]+'*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Synthetic Data Generation\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"Synthetic Data Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# 문서 로더 생성\n",
    "# loader = PDFPlumberLoader(\"data/Prompt_Tuning.pdf\")\n",
    "loader = PDFPlumberLoader(\"data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf\")\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 목차, 끝 페이지 제외\n",
    "docs = docs[3:-1]\n",
    "\n",
    "# 문서의 페이지수\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf',\n",
       " 'file_path': 'data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf',\n",
       " 'page': 3,\n",
       " 'total_pages': 29,\n",
       " 'Author': 'MS',\n",
       " 'CreationDate': \"D:20240328014510+09'00'\",\n",
       " 'Creator': 'PScript5.dll Version 5.2.2',\n",
       " 'ModDate': \"D:20240328014510+09'00'\",\n",
       " 'Producer': 'Acrobat Distiller 9.3.2 (Windows)',\n",
       " 'Title': '<C1F6B4C9C1A4BAB8203330B1C731C8A35FC5EBBABB2E687770>',\n",
       " 'rgid': 'PB:379341632_AS:11431281232126100@1711621456089'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for doc in docs:\n",
    "\ttext_org = doc.page_content\n",
    "\tclean_text = re.split(r'\\U000f080f', text_org)[-1]\n",
    "\tdoc.page_content = clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 설정(filename 이 존재해야 함)\n",
    "for doc in docs:\n",
    "    doc.metadata[\"filename\"] = doc.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "\n",
    "# 데이터셋 생성기\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# llm = ChatOllama(model=\"dnotitia/dna\")\n",
    "# llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# 문서 임베딩\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "# embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\최인규\\Documents\\RAG_practice\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "# LangChain의 gemini 모델을 LangchainLLMWrapper로 감싸 Ragas와 호환되게 만듭니다.\n",
    "generator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "# ragas_embeddings 생성\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 25, relationships: 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform 적용으로 노드 재생성 및 엣지(relationships) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "\n",
    "# define your LLM and Embedding Model\n",
    "# here we are using the same LLM and Embedding Model that we used to generate the testset\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = ragas_embeddings\n",
    "\n",
    "trans = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HeadlinesExtractor(name='HeadlinesExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x0000026DF21E16C0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='headlines', prompt=HeadlinesExtractorPrompt(instruction=Extract the most important max_num headlines from the given text that can be used to split the text into independent sections.Focus on Level 2 and Level 3 headings., examples=[(TextWithExtractionLimit(text='                Introduction\\n                Overview of the topic...\\n\\n                Main Concepts\\n                Explanation of core ideas...\\n\\n                Detailed Analysis\\n                Techniques and methods for analysis...\\n\\n                Subsection: Specialized Techniques\\n                Further details on specialized techniques...\\n\\n                Future Directions\\n                Insights into upcoming trends...\\n\\n                Subsection: Next Steps in Research\\n                Discussion of new areas of study...\\n\\n                Conclusion\\n                Final remarks and summary.\\n                ', max_num=6), Headlines(headlines=['Introduction', 'Main Concepts', 'Detailed Analysis', 'Subsection: Specialized Techniques', 'Future Directions', 'Conclusion']))], language=english), max_num=5),\n",
       " HeadlineSplitter(name='HeadlineSplitter', filter_nodes=<function default_filter at 0x0000026DF215AC00>, min_tokens=500, max_tokens=1000),\n",
       " SummaryExtractor(name='SummaryExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x0000026DF21E1DA0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='summary', prompt=SummaryExtractorPrompt(instruction=Summarize the given text in less than 10 sentences., examples=[(StringIO(text='Artificial intelligence\\n\\nArtificial intelligence is transforming various industries by automating tasks that previously required human intelligence. From healthcare to finance, AI is being used to analyze vast amounts of data quickly and accurately. This technology is also driving innovations in areas like self-driving cars and personalized recommendations.'), StringIO(text='AI is revolutionizing industries by automating tasks, analyzing data, and driving innovations like self-driving cars and personalized recommendations.'))], language=english)),\n",
       " CustomNodeFilter(name='CustomNodeFilter', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x0000026DF21E22A0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), scoring_prompt=QuestionPotentialPrompt(instruction=Given a document summary and node content, score the content of the node in 1 to 5 range., examples=[], language=english), min_score=2, rubrics={'score1_description': 'The page content is irrelevant or does not align with the main themes or topics of the document summary.', 'score2_description': \"The page content partially aligns with the document summary, but it includes unrelated details or lacks critical information related to the document's main themes.\", 'score3_description': 'The page content generally reflects the document summary but may miss key details or lack depth in addressing the main themes.', 'score4_description': 'The page content aligns well with the document summary, covering the main themes and topics with minor gaps or minimal unrelated information.', 'score5_description': \"The page content is highly relevant, accurate, and directly reflects the main themes of the document summary, covering all important details and adding depth to the understanding of the document's topics.\"}),\n",
       " <ragas.testset.transforms.engine.Parallel at 0x26df1faaf50>,\n",
       " <ragas.testset.transforms.engine.Parallel at 0x26decdc0590>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlineSplitter:   0%|          | 0/25 [00:00<?, ?it/s]           unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Applying SummaryExtractor:  30%|███       | 14/46 [00:05<00:10,  3.18it/s]Property 'summary' already exists in node 'a89c6a'. Skipping!\n",
      "Applying SummaryExtractor:  39%|███▉      | 18/46 [00:05<00:07,  3.77it/s]Property 'summary' already exists in node 'dc1a17'. Skipping!\n",
      "Applying SummaryExtractor:  43%|████▎     | 20/46 [00:06<00:07,  3.43it/s]Property 'summary' already exists in node '1ccf5c'. Skipping!\n",
      "Property 'summary' already exists in node '876026'. Skipping!\n",
      "Applying SummaryExtractor:  54%|█████▍    | 25/46 [00:07<00:03,  5.28it/s]Property 'summary' already exists in node '6e72bf'. Skipping!\n",
      "Applying SummaryExtractor:  57%|█████▋    | 26/46 [00:07<00:05,  3.76it/s]Property 'summary' already exists in node 'c5f3ca'. Skipping!\n",
      "Property 'summary' already exists in node '70701d'. Skipping!\n",
      "Applying SummaryExtractor:  63%|██████▎   | 29/46 [00:08<00:04,  3.41it/s]Property 'summary' already exists in node '7a9aab'. Skipping!\n",
      "Applying SummaryExtractor:  65%|██████▌   | 30/46 [00:08<00:03,  4.01it/s]Property 'summary' already exists in node '3debda'. Skipping!\n",
      "Applying SummaryExtractor:  67%|██████▋   | 31/46 [00:08<00:03,  4.12it/s]Property 'summary' already exists in node 'e33213'. Skipping!\n",
      "Applying SummaryExtractor:  70%|██████▉   | 32/46 [00:09<00:03,  3.55it/s]Property 'summary' already exists in node '8025c5'. Skipping!\n",
      "Applying SummaryExtractor:  74%|███████▍  | 34/46 [00:09<00:02,  4.95it/s]Property 'summary' already exists in node '5a06f5'. Skipping!\n",
      "Property 'summary' already exists in node 'b549a7'. Skipping!\n",
      "Applying SummaryExtractor:  78%|███████▊  | 36/46 [00:09<00:01,  6.73it/s]Property 'summary' already exists in node '43fb9d'. Skipping!\n",
      "Property 'summary' already exists in node '90498c'. Skipping!\n",
      "Applying SummaryExtractor:  83%|████████▎ | 38/46 [00:09<00:01,  6.55it/s]Property 'summary' already exists in node '28e213'. Skipping!\n",
      "Applying SummaryExtractor:  85%|████████▍ | 39/46 [00:10<00:01,  5.11it/s]Property 'summary' already exists in node '29ea77'. Skipping!\n",
      "Applying SummaryExtractor:  87%|████████▋ | 40/46 [00:10<00:01,  4.11it/s]Property 'summary' already exists in node 'e17607'. Skipping!\n",
      "Applying SummaryExtractor:  89%|████████▉ | 41/46 [00:11<00:01,  3.16it/s]Property 'summary' already exists in node 'c9af2b'. Skipping!\n",
      "Property 'summary' already exists in node '852a86'. Skipping!\n",
      "Applying SummaryExtractor:  93%|█████████▎| 43/46 [00:12<00:01,  2.72it/s]Property 'summary' already exists in node '71f591'. Skipping!\n",
      "Applying SummaryExtractor:  96%|█████████▌| 44/46 [00:12<00:00,  3.15it/s]Property 'summary' already exists in node 'faf241'. Skipping!\n",
      "Applying SummaryExtractor:  98%|█████████▊| 45/46 [00:13<00:00,  1.64it/s]Property 'summary' already exists in node 'fa2633'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/46 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node 'c5f3ca'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a89c6a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'dc1a17'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1ccf5c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '876026'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e33213'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '70701d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '90498c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6e72bf'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '43fb9d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8025c5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3debda'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b549a7'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '28e213'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5a06f5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7a9aab'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '29ea77'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '852a86'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '71f591'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fa2633'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c9af2b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'faf241'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e17607'. Skipping!\n",
      "                                                                                                            \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(kg, trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 48, relationships: 1035)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.save(\"knowledge_graph.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 48, relationships: 1035)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kg = KnowledgeGraph.load(\"knowledge_graph.json\")\n",
    "loaded_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "query_distribution = default_query_distribution(generator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, _ in query_distribution:\n",
    "    prompts = await query.adapt_prompts(\"korean\", llm=generator_llm)\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0),\n",
    "]\n",
    "\n",
    "for query, _ in distribution:\n",
    "    prompts = await query.adapt_prompts(\"korean\", llm=generator_llm)\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_distribution_change_ratio = [(dist[0], ratio)for dist, ratio in zip(query_distribution, [0.6,0.2,0.2])]\n",
    "query_distribution_single = distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SingleHopSpecificQuerySynthesizer(name='single_hop_specifc_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
       "  1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
       "  2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
       "  , examples=[(QueryCondition(persona=Persona(name='소프트웨어 엔지니어', role_description='코딩 모범 사례와 시스템 설계에 집중합니다.'), term='마이크로서비스', query_style='형식적', query_length='중간', context='마이크로서비스는 애플리케이션이 느슨하게 결합된 서비스 모음으로 구성되는 아키텍처 스타일입니다. 각 서비스는 세분화되어 있으며 단일 기능에 집중합니다.'), GeneratedQueryAnswer(query='소프트웨어 아키텍처에서 마이크로서비스의 목적은 무엇입니까?', answer='마이크로서비스는 애플리케이션을 느슨하게 결합된 서비스 모음으로 구조화하도록 설계되었으며, 각 서비스는 단일 기능에 집중합니다.'))], language=korean), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['공감', '포용성', '원격 근무'], personas=[Persona(name='인사 관리자', role_description='포용성과 직원 지원에 중점을 둡니다.'), Persona(name='원격 팀 리드', role_description='원격 팀 커뮤니케이션을 관리합니다.')]), PersonaThemesMapping(mapping={'HR Manager': ['포용성', '공감'], 'Remote Team Lead': ['원격 근무', '공감']}))], language=korean), property_name='entities'),\n",
       "  1.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_distribution_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loaded_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 페르소나: [Persona(name='Financial Data Scientist', role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'), Persona(name='Financial Data Scientist', role_description='Specializes in developing algorithms and models for financial data analysis, ensuring security, compliance, and accuracy in predictions.'), Persona(name='Financial Data Scientist', role_description='Specializes in applying machine learning algorithms to analyze and predict financial trends, while ensuring data privacy and compliance.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.persona import generate_personas_from_kg\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "if generator.persona_list is None:\n",
    "    personas = generate_personas_from_kg(\n",
    "        llm=generator.llm,\n",
    "        kg=generator.knowledge_graph,\n",
    "        num_personas=3,  # 원하는 페르소나 개수\n",
    "        callbacks=None   # 필요 시 콜백을 추가\n",
    "    )\n",
    "    generator.persona_list = personas\n",
    "else:\n",
    "    # 이미 페르소나가 있으면 섞어줍니다.\n",
    "    import random\n",
    "    random.shuffle(generator.persona_list)\n",
    "    personas = generator.persona_list\n",
    "\n",
    "print(\"생성된 페르소나:\", personas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios: 100%|██████████| 1/1 [01:05<00:00, 65.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 시나리오 샘플 리스트: [[SingleHopScenario(\n",
      "nodes=1\n",
      "term=\n",
      "persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
      "style=QueryStyle.PERFECT_GRAMMAR\n",
      "length=QueryLength.MEDIUM), SingleHopScenario(\n",
      "nodes=1\n",
      "term=\n",
      "persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
      "style=QueryStyle.PERFECT_GRAMMAR\n",
      "length=QueryLength.SHORT)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 및 함수 임포트\n",
    "from ragas.testset.synthesizers.utils import calculate_split_values\n",
    "from ragas.executor import Executor\n",
    "from ragas.callbacks import new_group\n",
    "\n",
    "# 테스트에 필요한 변수 설정\n",
    "testset_size = 10   # 총 생성할 시나리오 샘플 수\n",
    "num_personas = 3    # 사용할 페르소나 수\n",
    "batch_size = None   # 배치 사이즈 (필요에 따라 설정)\n",
    "run_config = None   # 실행 설정 (필요시 지정)\n",
    "callbacks = []      # 빈 콜백 리스트 (원하는 콜백이 있으면 추가)\n",
    "\n",
    "# 테스트셋 생성의 최상위 그룹 생성 (시나리오 생성 그룹의 상위 그룹)\n",
    "RAGAS_TESTSET_GENERATION_GROUP_NAME = \"ragas testset generation\"\n",
    "testset_generation_rm, testset_generation_grp = new_group(\n",
    "    name=RAGAS_TESTSET_GENERATION_GROUP_NAME,\n",
    "    inputs={\"testset_size\": testset_size},\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "\n",
    "# 전체 시나리오 샘플 수를 각 시나리오에 할당할 개수로 분할\n",
    "splits, _ = calculate_split_values(\n",
    "    [prob for _, prob in query_distribution_single],\n",
    "    testset_size\n",
    ")\n",
    "\n",
    "# 시나리오 생성 그룹 생성 (콜백 체인 상위에 연결)\n",
    "scenario_generation_rm, scenario_generation_grp = new_group(\n",
    "    name=\"Scenario Generation\",\n",
    "    inputs={\"splits\": splits},\n",
    "    callbacks=testset_generation_grp,\n",
    ")\n",
    "\n",
    "# Executor 객체를 생성하여 시나리오 생성 작업을 제출\n",
    "exec = Executor(\n",
    "    desc=\"Generating Scenarios\",\n",
    "    raise_exceptions=True,\n",
    "    run_config=run_config,\n",
    "    keep_progress_bar=False,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# 각 시나리오에 대해 generate_scenarios 함수를 호출하여 작업 제출\n",
    "for i, (scenario, _) in enumerate(query_distribution_single):\n",
    "    exec.submit(\n",
    "        scenario.generate_scenarios,\n",
    "        n=splits[i],\n",
    "        knowledge_graph=generator.knowledge_graph,\n",
    "        persona_list=generator.persona_list[:num_personas],\n",
    "        callbacks=scenario_generation_grp,\n",
    "    )\n",
    "\n",
    "# 작업 결과를 수집하고 에러가 있으면 처리\n",
    "try:\n",
    "    scenario_sample_list = exec.results()\n",
    "except Exception as e:\n",
    "    scenario_generation_rm.on_chain_error(e)\n",
    "    raise e\n",
    "else:\n",
    "    scenario_generation_rm.on_chain_end(outputs={\"scenario_sample_list\": scenario_sample_list})\n",
    "\n",
    "# 생성된 시나리오 샘플 리스트 출력\n",
    "print(\"생성된 시나리오 샘플 리스트:\", scenario_sample_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SingleHopScenario(\n",
       "  nodes=1\n",
       "  term=\n",
       "  persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
       "  style=QueryStyle.PERFECT_GRAMMAR\n",
       "  length=QueryLength.MEDIUM),\n",
       "  SingleHopScenario(\n",
       "  nodes=1\n",
       "  term=\n",
       "  persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
       "  style=QueryStyle.PERFECT_GRAMMAR\n",
       "  length=QueryLength.SHORT)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 평가 샘플: [SingleTurnSample(user_input='금융 데이터의 특성을 고려할 때, LLM 파인튜닝에서 어떤 요소를 중점적으로 다루어야 합니까?', retrieved_contexts=None, reference_contexts=['\\n데이터의 다양성을 높이기 위해 데이터 증 요하다. 금융 데이터는 다음과 같은 특성을 가지\\n강을 활용한다. 문장 내 단어 순서 변경, 동 고 있다.\\n의어 삽입 등의 기법을 사용하여 모델이\\n1) 금융 전문 용어의 사용: 금융 데이터에는\\n다양한 문맥을 학습하도록 도움을 준다.\\n다양한 전문 용어가 사용된다. LLM이 이\\n6) 실험 로깅 및 모니터링: TensorBoard나 원 러한 전문 용어를 이해하고 인식할 수 있\\n하는 로깅 도구를 사용하여 학습 중 성능 도록 해야 한다. 예를 들어, “주가 하락”,\\n을 모니터링하는데 학습 중에 중요한 지표 “환율 상승”, “금리 인상” 등이 있다. 또한\\n들을 로깅하여 모델의 성능을 실시간으로 금융 상품에는 “적립식 펀드”, “변액 보험”,\\n확인하고, 학습 과정에서 발생한 문제를 신 “대출” 등 다양하게 있다. 그리고 금융 상\\n속하게 파악할 수 있다. 품에는 다양한 특성이 있다. 예를 들어, “적\\n립식 펀드는 장기 투자에 적합하다.”, “변\\n7) 하이퍼파라미터 튜닝: 하이퍼파라미터 최\\n액 보험은 저축과 보험의 기능을 모두 가\\n적화 도구를 활용하여 자동으로 최적의 하이\\n지고 있다.”, “대출은 부채를 의미한다.” 등\\n퍼파라미터 조합 찾기를 하게 되는데 Grid\\n이 있다. LLM이 이러한 전문 용어를 이해\\nSearch 또는 Random Search와 같은 튜닝\\n하고 인식할 수 있도록, 사전 또는 어휘 사\\n기법을 사용하여 하이퍼파라미터를 조정하\\n전을 통해 전문 용어 및 금융 상품에 대한\\n면 모델의 성능을 극대화할 수 있다.\\n지식을 학습해야 한다.\\n이렇게 모델 파인튜닝 실행 환경 설정은 실험\\n2) 숫자의 사용: 금융 데이터에는 다양한 숫자\\n의 효율성 및 모델의 수렴을 보장하기 위해 신중\\n가 사용된다. LLM이 이러한 숫자를 정확\\n한 계획과 감독이 필요하다. 설정된 환경에서 수\\n하게 처리할 수 있도록 해야 한다. 예를 들어,\\n행되는 실험 결과를 기반으로 계속해서 최적화\\n“코스피 지수 2,300”, “달러 환율 1,300원”,\\n를 진행해야 한다.\\n“기준금리 2.0%” 등이 있다. LLM이 이러한\\n숫자를 정확하게 처리할 수 있도록, 숫자\\n3.3. 금융 특화 LLM 파인튜닝시 고려사항\\n처리 관련 기능을 활용해야 한다.\\n금융 분야의 LLM 파인튜닝은 다음과 같은 단 3) 규칙의 복잡성: 금융 데이터는 복잡한 규칙을\\n계를 포함하여 진행한다. 가지고 있다. LLM이 이러한 규칙을 이해\\n하고 적용할 수 있도록 해야 한다. 예를 들어,\\n3.3.1. 금융 데이터 특성을 고려한 도메인 특화 과거 주식 시장 데이터를 기반으로 학습된\\n어휘 구축\\n모델이 있을 때, 갑작스러운 뉴스 사건으로\\n금융 데이터는 독특한 특성을 지니고 있으며, 인해 시장이 급락하면 모델의 예측 정확도가\\n주식 가격의 변동, 금융 뉴스의 감성 등 다양한 크게 떨어질 수 있기 때문에 다양한 시장\\n측면이 모델에 영향을 미친다. 따라서, 이러한 상황을 반영하는 데이터를 사용하여 모델을\\n특성을 고려하여 모델을 파인튜닝하는 것이 중 학습해야 한다.\\n107\\n'], response=None, multi_responses=None, reference=\"금융 데이터의 특성을 고려한 LLM 파인튜닝은 다음과 같은 요소를 중점적으로 다루어야 합니다. 첫째, 금융 전문 용어의 사용을 통해 LLM이 다양한 전문 용어를 이해하고 인식할 수 있도록 해야 합니다. 둘째, 숫자의 사용을 정확하게 처리할 수 있도록 기능을 활용해야 하며, 예를 들어 '코스피 지수 2,300'과 같은 숫자를 정확히 인식해야 합니다. 셋째, 금융 데이터의 복잡한 규칙을 이해하고 적용할 수 있도록 해야 하며, 예를 들어 과거 주식 시장 데이터를 기반으로 학습된 모델이 갑작스러운 뉴스 사건으로 인해 시장이 급락할 때의 상황을 반영하는 데이터를 사용하여 모델을 학습해야 합니다.\", rubrics=None), SingleTurnSample(user_input='금융 분야에서 LLM 모델의 성능을 높이기 위한 방법은 무엇입니까?', retrieved_contexts=None, reference_contexts=['\\n하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융 특화 파인튜닝 LLM\\n보이고 있다. (LLM fine-tuned for finance)\\n금융 분야에 특화된 파인튜닝이 적용된 모델\\n3.4.1. 금융 분야를 위한 사전학습 LLM (LLM 로는 2023년 7월에 소개된 FinGPT와 Fin-LLaMA\\npre-trained for finance from Scratch)\\n가 있다. FinGPT는 OpenAI의 GPT 아키텍처를\\n처음부터 금융 도메인에서 학습된 모델로는 금융 분야에 특화시킨 모델로, ChatGLM-6B를\\n2023년 2월에 출시된 Fin-T5와 3월에 등장한 기본모델로 하여 50,000개의 샘플 데이터를 경량의\\nBloombergGPT가 있다. Fin-T5는 770M-T5 모델을 LoRA기술을 사용하여 파인튜닝하여 금융 텍스\\n기반으로 하며, 80B Finance tokens 규모의 데이 트의 특수성을 학습하였다. FinGPT는 금융 리서치,\\n터셋으로 학습되었다. BloombergGPT는 <표 7> 예측 분석, 자동 트레이딩과 같은 응용 분야에서\\n과 같이 금융 전문 언어를 학습한 GPT 기반 모 뛰어난 성과를 보여주고 있으며 Fin-LLaMA는\\n델로, Bloomberg의 금융 데이터와 뉴스를 활용 LLaMA-33B를 기본모델로 적용하여 16,900개의\\n하여 사전 훈련되었고, 50B-BLOOM 모델을 기본 데이터를 Instruction 파인튜닝한 모델로, 높은 성능\\n으로 363B Finance tokens과 345B public tokens 을 나타내고 있다. 이렇게 일반적으로 LLaMA2,\\n규모의 데이터로 파인튜닝 되었다. 대부분 NER Falcon, BLOOM같은 오픈소스 LLM을 기본모델\\n(Named Entity Recognition) 및 감정 분석(Sentiment 로 활용하여 금융 특화된 정보를 추가하여 사전\\nAnalysis) 같은 토큰 및 문장 분류 Task로 구성되 학습하거나 파인튜닝을 하는 것을 볼 수 있다.\\n어 있으며(Wu, et. al., 2023) 이 모델은 금융 시장 또한 모델마다 각각의 특징과 장단점을 지니고\\n동향 예측, 뉴스 감성 분석 등의 작업에 뛰어난 있는데 FinBERT는 특정 작업에 대한 성능이 우\\n성능을 보여주고 있다. 수하지만 데이터 양에 따라 성능이 크게 좌우될\\n또한, 금융 뉴스 데이터로 사전학습한 모델 중 수 있고 BloombergGPT는 실제 금융 데이터와\\nFinBERT는 BERT 아키텍처를 사용하여 금융 문 강력한 파인튜닝 메커니즘을 활용하여 실전 적\\n맥에서의 단어, 구문, 의미를 추가로 학습하였다. 용에 강점을 지닌다. FinGPT는 GPT 아키텍처를\\n이 모델은 주로 금융 리서치나 트레이딩과 관련 기반으로 하되, 금융 도메인에 특화된 데이터셋\\n된 문제에 적용되며, 도메인 특화된 정보를 추출 과 파인튜닝을 통해 높은 성능을 달성한다. 이러\\n하는 데 성공적으로 활용되고 있다. 한 금융 분야에서의 LLM 모델들은 향후 더욱\\n<표 7> Evaluation Benchmarks of BloombergGPT.\\nSuit Tasks What does it measure?\\nPublic Financial Tasks 5 Public datasets in the financial domain\\nBloomberg Financial Tasks 12 NER and sentiment analysis tasks\\nBig-bench Hard (Suzgun et al., 2022) 23 Reasoning and general NLP tasks\\nKnowledge Assessments 5 Testing closed-book information recall\\nReading Comprehension 5 Testing open-book tasks\\nLinguistic Tasks 9 Not directly user-facing NLP tasks\\n109\\n'], response=None, multi_responses=None, reference='금융 분야에서 LLM 모델의 성능을 높이기 위해서는 금융 특화 파인튜닝을 적용하는 것이 중요합니다. 예를 들어, FinGPT와 같은 모델은 금융 도메인에서 처음부터 학습되었으며, BloombergGPT는 실제 금융 데이터와 뉴스를 활용하여 사전 훈련되었습니다. 이러한 모델들은 금융 리서치, 예측 분석, 자동 트레이딩과 같은 응용 분야에서 뛰어난 성과를 보여주고 있습니다.', rubrics=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ragas.executor import Executor\n",
    "from ragas.callbacks import new_group\n",
    "\n",
    "# sample_generation 콜백 그룹 생성\n",
    "sample_generation_rm, sample_generation_grp = new_group(\n",
    "    name=\"Sample Generation\",\n",
    "    inputs={\"scenario_sample_list\": scenario_sample_list},\n",
    "    callbacks=[],\n",
    ")\n",
    "\n",
    "# Executor 객체 생성\n",
    "exec = Executor(\n",
    "    desc=\"Generating Samples\",\n",
    "    raise_exceptions=True,\n",
    "    run_config=None,   # 필요에 따라 실행 설정 지정\n",
    "    keep_progress_bar=True,\n",
    "    batch_size=None,   # 배치 크기 설정 (없으면 None)\n",
    ")\n",
    "\n",
    "# 평가 샘플 생성 시 synthesizer 객체의 generate_sample 메서드 사용\n",
    "additional_testset_info = []\n",
    "for i, (synthesizer, _) in enumerate(query_distribution_single):\n",
    "    for scenario in scenario_sample_list[i]:\n",
    "        exec.submit(\n",
    "            synthesizer.generate_sample,  # synthesizer 객체의 generate_sample 호출\n",
    "            scenario=scenario,            # 해당 시나리오 객체를 인자로 전달\n",
    "            callbacks=sample_generation_grp,\n",
    "        )\n",
    "        additional_testset_info.append({\"synthesizer_name\": synthesizer.name})\n",
    "\n",
    "# 작업 결과 수집\n",
    "try:\n",
    "    eval_samples = exec.results()\n",
    "except Exception as e:\n",
    "    sample_generation_rm.on_chain_error(e)\n",
    "    raise e\n",
    "else:\n",
    "    sample_generation_rm.on_chain_end(outputs={\"eval_samples\": eval_samples})\n",
    "\n",
    "print(\"생성된 평가 샘플:\", eval_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SingleHopScenario(\n",
       " nodes=1\n",
       " term=\n",
       " persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
       " style=QueryStyle.PERFECT_GRAMMAR\n",
       " length=QueryLength.MEDIUM),\n",
       " SingleHopScenario(\n",
       " nodes=1\n",
       " term=\n",
       " persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
       " style=QueryStyle.PERFECT_GRAMMAR\n",
       " length=QueryLength.SHORT)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_sample_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SingleTurnSample(user_input='금융 데이터의 특성을 고려할 때, LLM 파인튜닝에서 어떤 요소를 중점적으로 다루어야 합니까?', retrieved_contexts=None, reference_contexts=['\\n데이터의 다양성을 높이기 위해 데이터 증 요하다. 금융 데이터는 다음과 같은 특성을 가지\\n강을 활용한다. 문장 내 단어 순서 변경, 동 고 있다.\\n의어 삽입 등의 기법을 사용하여 모델이\\n1) 금융 전문 용어의 사용: 금융 데이터에는\\n다양한 문맥을 학습하도록 도움을 준다.\\n다양한 전문 용어가 사용된다. LLM이 이\\n6) 실험 로깅 및 모니터링: TensorBoard나 원 러한 전문 용어를 이해하고 인식할 수 있\\n하는 로깅 도구를 사용하여 학습 중 성능 도록 해야 한다. 예를 들어, “주가 하락”,\\n을 모니터링하는데 학습 중에 중요한 지표 “환율 상승”, “금리 인상” 등이 있다. 또한\\n들을 로깅하여 모델의 성능을 실시간으로 금융 상품에는 “적립식 펀드”, “변액 보험”,\\n확인하고, 학습 과정에서 발생한 문제를 신 “대출” 등 다양하게 있다. 그리고 금융 상\\n속하게 파악할 수 있다. 품에는 다양한 특성이 있다. 예를 들어, “적\\n립식 펀드는 장기 투자에 적합하다.”, “변\\n7) 하이퍼파라미터 튜닝: 하이퍼파라미터 최\\n액 보험은 저축과 보험의 기능을 모두 가\\n적화 도구를 활용하여 자동으로 최적의 하이\\n지고 있다.”, “대출은 부채를 의미한다.” 등\\n퍼파라미터 조합 찾기를 하게 되는데 Grid\\n이 있다. LLM이 이러한 전문 용어를 이해\\nSearch 또는 Random Search와 같은 튜닝\\n하고 인식할 수 있도록, 사전 또는 어휘 사\\n기법을 사용하여 하이퍼파라미터를 조정하\\n전을 통해 전문 용어 및 금융 상품에 대한\\n면 모델의 성능을 극대화할 수 있다.\\n지식을 학습해야 한다.\\n이렇게 모델 파인튜닝 실행 환경 설정은 실험\\n2) 숫자의 사용: 금융 데이터에는 다양한 숫자\\n의 효율성 및 모델의 수렴을 보장하기 위해 신중\\n가 사용된다. LLM이 이러한 숫자를 정확\\n한 계획과 감독이 필요하다. 설정된 환경에서 수\\n하게 처리할 수 있도록 해야 한다. 예를 들어,\\n행되는 실험 결과를 기반으로 계속해서 최적화\\n“코스피 지수 2,300”, “달러 환율 1,300원”,\\n를 진행해야 한다.\\n“기준금리 2.0%” 등이 있다. LLM이 이러한\\n숫자를 정확하게 처리할 수 있도록, 숫자\\n3.3. 금융 특화 LLM 파인튜닝시 고려사항\\n처리 관련 기능을 활용해야 한다.\\n금융 분야의 LLM 파인튜닝은 다음과 같은 단 3) 규칙의 복잡성: 금융 데이터는 복잡한 규칙을\\n계를 포함하여 진행한다. 가지고 있다. LLM이 이러한 규칙을 이해\\n하고 적용할 수 있도록 해야 한다. 예를 들어,\\n3.3.1. 금융 데이터 특성을 고려한 도메인 특화 과거 주식 시장 데이터를 기반으로 학습된\\n어휘 구축\\n모델이 있을 때, 갑작스러운 뉴스 사건으로\\n금융 데이터는 독특한 특성을 지니고 있으며, 인해 시장이 급락하면 모델의 예측 정확도가\\n주식 가격의 변동, 금융 뉴스의 감성 등 다양한 크게 떨어질 수 있기 때문에 다양한 시장\\n측면이 모델에 영향을 미친다. 따라서, 이러한 상황을 반영하는 데이터를 사용하여 모델을\\n특성을 고려하여 모델을 파인튜닝하는 것이 중 학습해야 한다.\\n107\\n'], response=None, multi_responses=None, reference=\"금융 데이터의 특성을 고려한 LLM 파인튜닝은 다음과 같은 요소를 중점적으로 다루어야 합니다. 첫째, 금융 전문 용어의 사용을 통해 LLM이 다양한 전문 용어를 이해하고 인식할 수 있도록 해야 합니다. 둘째, 숫자의 사용을 정확하게 처리할 수 있도록 기능을 활용해야 하며, 예를 들어 '코스피 지수 2,300'과 같은 숫자를 정확히 인식해야 합니다. 셋째, 금융 데이터의 복잡한 규칙을 이해하고 적용할 수 있도록 해야 하며, 예를 들어 과거 주식 시장 데이터를 기반으로 학습된 모델이 갑작스러운 뉴스 사건으로 인해 시장이 급락할 때의 상황을 반영하는 데이터를 사용하여 모델을 학습해야 합니다.\", rubrics=None),\n",
       " SingleTurnSample(user_input='금융 분야에서 LLM 모델의 성능을 높이기 위한 방법은 무엇입니까?', retrieved_contexts=None, reference_contexts=['\\n하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융 특화 파인튜닝 LLM\\n보이고 있다. (LLM fine-tuned for finance)\\n금융 분야에 특화된 파인튜닝이 적용된 모델\\n3.4.1. 금융 분야를 위한 사전학습 LLM (LLM 로는 2023년 7월에 소개된 FinGPT와 Fin-LLaMA\\npre-trained for finance from Scratch)\\n가 있다. FinGPT는 OpenAI의 GPT 아키텍처를\\n처음부터 금융 도메인에서 학습된 모델로는 금융 분야에 특화시킨 모델로, ChatGLM-6B를\\n2023년 2월에 출시된 Fin-T5와 3월에 등장한 기본모델로 하여 50,000개의 샘플 데이터를 경량의\\nBloombergGPT가 있다. Fin-T5는 770M-T5 모델을 LoRA기술을 사용하여 파인튜닝하여 금융 텍스\\n기반으로 하며, 80B Finance tokens 규모의 데이 트의 특수성을 학습하였다. FinGPT는 금융 리서치,\\n터셋으로 학습되었다. BloombergGPT는 <표 7> 예측 분석, 자동 트레이딩과 같은 응용 분야에서\\n과 같이 금융 전문 언어를 학습한 GPT 기반 모 뛰어난 성과를 보여주고 있으며 Fin-LLaMA는\\n델로, Bloomberg의 금융 데이터와 뉴스를 활용 LLaMA-33B를 기본모델로 적용하여 16,900개의\\n하여 사전 훈련되었고, 50B-BLOOM 모델을 기본 데이터를 Instruction 파인튜닝한 모델로, 높은 성능\\n으로 363B Finance tokens과 345B public tokens 을 나타내고 있다. 이렇게 일반적으로 LLaMA2,\\n규모의 데이터로 파인튜닝 되었다. 대부분 NER Falcon, BLOOM같은 오픈소스 LLM을 기본모델\\n(Named Entity Recognition) 및 감정 분석(Sentiment 로 활용하여 금융 특화된 정보를 추가하여 사전\\nAnalysis) 같은 토큰 및 문장 분류 Task로 구성되 학습하거나 파인튜닝을 하는 것을 볼 수 있다.\\n어 있으며(Wu, et. al., 2023) 이 모델은 금융 시장 또한 모델마다 각각의 특징과 장단점을 지니고\\n동향 예측, 뉴스 감성 분석 등의 작업에 뛰어난 있는데 FinBERT는 특정 작업에 대한 성능이 우\\n성능을 보여주고 있다. 수하지만 데이터 양에 따라 성능이 크게 좌우될\\n또한, 금융 뉴스 데이터로 사전학습한 모델 중 수 있고 BloombergGPT는 실제 금융 데이터와\\nFinBERT는 BERT 아키텍처를 사용하여 금융 문 강력한 파인튜닝 메커니즘을 활용하여 실전 적\\n맥에서의 단어, 구문, 의미를 추가로 학습하였다. 용에 강점을 지닌다. FinGPT는 GPT 아키텍처를\\n이 모델은 주로 금융 리서치나 트레이딩과 관련 기반으로 하되, 금융 도메인에 특화된 데이터셋\\n된 문제에 적용되며, 도메인 특화된 정보를 추출 과 파인튜닝을 통해 높은 성능을 달성한다. 이러\\n하는 데 성공적으로 활용되고 있다. 한 금융 분야에서의 LLM 모델들은 향후 더욱\\n<표 7> Evaluation Benchmarks of BloombergGPT.\\nSuit Tasks What does it measure?\\nPublic Financial Tasks 5 Public datasets in the financial domain\\nBloomberg Financial Tasks 12 NER and sentiment analysis tasks\\nBig-bench Hard (Suzgun et al., 2022) 23 Reasoning and general NLP tasks\\nKnowledge Assessments 5 Testing closed-book information recall\\nReading Comprehension 5 Testing open-book tasks\\nLinguistic Tasks 9 Not directly user-facing NLP tasks\\n109\\n'], response=None, multi_responses=None, reference='금융 분야에서 LLM 모델의 성능을 높이기 위해서는 금융 특화 파인튜닝을 적용하는 것이 중요합니다. 예를 들어, FinGPT와 같은 모델은 금융 도메인에서 처음부터 학습되었으며, BloombergGPT는 실제 금융 데이터와 뉴스를 활용하여 사전 훈련되었습니다. 이러한 모델들은 금융 리서치, 예측 분석, 자동 트레이딩과 같은 응용 분야에서 뛰어난 성과를 보여주고 있습니다.', rubrics=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n",
      "Generating Scenarios: 100%|██████████| 1/1 [00:42<00:00, 42.90s/it]\n",
      "Generating Samples: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution_single, with_debugging_logs=True)\n",
    "# testset = generator.generate(testset_size=10, query_distribution=query_distribution_change_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Testset(samples=[])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노드 속성: {'document_metadata', 'headlines', 'page_content', 'summary', 'summary_embedding'}\n",
      "노드 수: 48\n"
     ]
    }
   ],
   "source": [
    "# 지식 그래프의 노드 속성 확인\n",
    "node_properties = set()\n",
    "for node in loaded_kg.nodes:\n",
    "    for prop in node.properties:\n",
    "        node_properties.add(prop)\n",
    "print(f\"노드 속성: {node_properties}\")\n",
    "\n",
    "# 노드 수 확인\n",
    "print(f\"노드 수: {len(loaded_kg.nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm, embedding_model=generator_embeddings, persona_list=personas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generator.generate_with_langchain_docs(\n",
    "    docs[:],\n",
    "    testset_size=5,\n",
    "    transforms=transforms,\n",
    "    query_distribution=distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지식그래프 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 Node 생성\n",
    "- 각 문서당 1개의 노드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- default_transforms에 포함되어 있는 내용\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 논문은 Mistral 7B를 활용한 금융 분야의 LLM 파인튜닝 및 활용 방법을 다룬다. LLM은 자연어 처리(NLP)에서 중요한 발전을 이루었으며, ChatGPT와 같은 모델이 많은 관심을 받고 있다. LLM은 대량의 텍스트 데이터를 학습하여 다양한 자연어 태스크에 적용할 수 있는 강력한 표현을 학습한다. 금융 분야에서는 고객 응대 챗봇을 통해 최신 정보 제공의 중요성이 강조되고 있다. 그러나 LLM의 정보 제한성과 환각 문제는 여전히 도전 과제로 남아 있다. 이를 해결하기 위해 새로운 데이터로의 파인튜닝과 프롬프트 콘텍스트에 정보를 삽입하는 방법이 제안되었다. RAG 모델이 대안으로 제시되며, 정보 검색을 통해 LLM에 필요한 정보를 전달하는 방식도 구현되고 있다. 이러한 기술들은 AI의 딥러닝 기반으로 생성형 AI 서비스를 가능하게 한다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kg.nodes[0].get_property(\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "query_distribution = default_query_distribution(generator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_distribution_onlysingle = [(query_distribution[0][0], 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ragas.testset.synthesizers.single_hop.prompts.QueryAnswerGenerationPrompt'>\n",
      "QueryAnswerGenerationPrompt(\n",
      "  \"name\": \"query_answer_generation_prompt\",\n",
      "  \"instruction\": \"Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\\n1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\\n2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\\n\",\n",
      "  \"examples\": [\n",
      "    [\n",
      "      {\n",
      "        \"persona\": {\n",
      "          \"name\": \"Software Engineer\",\n",
      "          \"role_description\": \"Focuses on coding best practices and system design.\"\n",
      "        },\n",
      "        \"term\": \"microservices\",\n",
      "        \"query_style\": \"Formal\",\n",
      "        \"query_length\": \"Medium\",\n",
      "        \"context\": \"Microservices are an architectural style where applications are structured as a collection of loosely coupled services. Each service is fine-grained and focuses on a single functionality.\"\n",
      "      },\n",
      "      {\n",
      "        \"query\": \"What is the purpose of microservices in software architecture?\",\n",
      "        \"answer\": \"Microservices are designed to structure applications as a collection of loosely coupled services, each focusing on a single functionality.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"language\": \"english\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "prompts = query_type.get_prompts()\n",
    "query_generation = prompts['query_answer_generation_prompt']\n",
    "print(type(query_generation))\n",
    "print(query_generation)\n",
    "\n",
    "# print(prompts['themes_personas_matching_prompt'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=ragas_embeddings, knowledge_graph=loaded_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 3/3 [00:07<00:00,  2.44s/it]\n",
      "Generating Scenarios: 100%|██████████| 1/1 [01:01<00:00, 61.77s/it]\n",
      "Generating Samples:  33%|███▎      | 1/3 [02:04<04:09, 124.75s/it]\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: I am trying to understand how Large Language Models (LLMs) and Chatbots work, especially in the context of financial services. Can you explain it in simple terms?\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/output_parsers/json.py:83\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/utils/json.py:145\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    144\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/utils/json.py:161\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/utils/json.py:119\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/json/__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m testset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_distribution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_distribution_onlysingle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/testset/synthesizers/generate.py:451\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    450\u001b[39m     sample_generation_rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    453\u001b[39m     sample_generation_rm.on_chain_end(outputs={\u001b[33m\"\u001b[39m\u001b[33meval_samples\u001b[39m\u001b[33m\"\u001b[39m: eval_samples})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/testset/synthesizers/generate.py:448\u001b[39m, in \u001b[36mTestsetGenerator.generate\u001b[39m\u001b[34m(self, testset_size, query_distribution, num_personas, run_config, batch_size, callbacks, token_usage_parser, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    441\u001b[39m         additional_testset_info.append(\n\u001b[32m    442\u001b[39m             {\n\u001b[32m    443\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msynthesizer_name\u001b[39m\u001b[33m\"\u001b[39m: synthesizer.name,\n\u001b[32m    444\u001b[39m             }\n\u001b[32m    445\u001b[39m         )\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m     eval_samples = \u001b[43mexec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    450\u001b[39m     sample_generation_rm.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/executor.py:141\u001b[39m, in \u001b[36mExecutor._process_jobs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    137\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.jobs),\n\u001b[32m    138\u001b[39m         desc=\u001b[38;5;28mself\u001b[39m.desc,\n\u001b[32m    139\u001b[39m         disable=\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress,\n\u001b[32m    140\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m internal_pbar:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    142\u001b[39m             \u001b[38;5;28mself\u001b[39m.jobs, internal_pbar, results, max_workers\n\u001b[32m    143\u001b[39m         )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    146\u001b[39m         \u001b[38;5;28mself\u001b[39m.jobs, \u001b[38;5;28mself\u001b[39m.pbar, results, max_workers\n\u001b[32m    147\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/executor.py:191\u001b[39m, in \u001b[36mExecutor._process_coroutines\u001b[39m\u001b[34m(self, jobs, pbar, results, max_workers)\u001b[39m\n\u001b[32m    189\u001b[39m coroutines = [afunc(*args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m afunc, args, kwargs, _ \u001b[38;5;129;01min\u001b[39;00m jobs]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m as_completed(coroutines, max_workers):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    192\u001b[39m     results.append(result)\n\u001b[32m    193\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/asyncio/tasks.py:615\u001b[39m, in \u001b[36mas_completed.<locals>._wait_for_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    613\u001b[39m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/executor.py:48\u001b[39m, in \u001b[36mas_completed.<locals>.sema_coro\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msema_coro\u001b[39m(coro):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/executor.py:100\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_exceptions:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m         exec_name = \u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/executor.py:96\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_callable_async\u001b[39m(\n\u001b[32m     93\u001b[39m     *args, **kwargs\n\u001b[32m     94\u001b[39m ) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, t.Callable | \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(*args, **kwargs)\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m counter, result\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/testset/synthesizers/base.py:121\u001b[39m, in \u001b[36mBaseSynthesizer.generate_sample\u001b[39m\u001b[34m(self, scenario, callbacks)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# new group for Sample Generation\u001b[39;00m\n\u001b[32m    116\u001b[39m sample_generation_rm, sample_generation_grp = new_group(\n\u001b[32m    117\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    118\u001b[39m     inputs={\u001b[33m\"\u001b[39m\u001b[33mscenario\u001b[39m\u001b[33m\"\u001b[39m: scenario},\n\u001b[32m    119\u001b[39m     callbacks=callbacks,\n\u001b[32m    120\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m sample = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_sample(scenario, sample_generation_grp)\n\u001b[32m    122\u001b[39m sample_generation_rm.on_chain_end(outputs={\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m: sample})\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/testset/synthesizers/single_hop/base.py:134\u001b[39m, in \u001b[36mSingleHopQuerySynthesizer._generate_sample\u001b[39m\u001b[34m(self, scenario, callbacks)\u001b[39m\n\u001b[32m    126\u001b[39m reference_context = scenario.nodes[\u001b[32m0\u001b[39m].properties.get(\u001b[33m\"\u001b[39m\u001b[33mpage_content\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m prompt_input = QueryCondition(\n\u001b[32m    128\u001b[39m     persona=scenario.persona,\n\u001b[32m    129\u001b[39m     term=scenario.term,\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m     query_style=scenario.style.name,\n\u001b[32m    133\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_query_reference_prompt.generate(\n\u001b[32m    135\u001b[39m     data=prompt_input, llm=\u001b[38;5;28mself\u001b[39m.llm, callbacks=callbacks\n\u001b[32m    136\u001b[39m )\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m SingleTurnSample(\n\u001b[32m    138\u001b[39m     user_input=response.query,\n\u001b[32m    139\u001b[39m     reference=response.answer,\n\u001b[32m    140\u001b[39m     reference_contexts=[reference_context],\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:129\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    126\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    130\u001b[39m     llm=llm,\n\u001b[32m    131\u001b[39m     data=data,\n\u001b[32m    132\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    133\u001b[39m     temperature=temperature,\n\u001b[32m    134\u001b[39m     stop=stop,\n\u001b[32m    135\u001b[39m     callbacks=callbacks,\n\u001b[32m    136\u001b[39m     retries_left=retries_left,\n\u001b[32m    137\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:203\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    201\u001b[39m output_string = resp.generations[\u001b[32m0\u001b[39m][i].text\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     answer = \u001b[38;5;28;01mawait\u001b[39;00m parser.parse_output_string(\n\u001b[32m    204\u001b[39m         output_string=output_string,\n\u001b[32m    205\u001b[39m         prompt_value=prompt_value,\n\u001b[32m    206\u001b[39m         llm=llm,\n\u001b[32m    207\u001b[39m         callbacks=prompt_cb,\n\u001b[32m    208\u001b[39m         retries_left=retries_left,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m    210\u001b[39m     processed_output = \u001b[38;5;28mself\u001b[39m.process_output(answer, data)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    211\u001b[39m     output_models.append(processed_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:411\u001b[39m, in \u001b[36mRagasOutputParser.parse_output_string\u001b[39m\u001b[34m(self, output_string, prompt_value, llm, callbacks, retries_left)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retries_left != \u001b[32m0\u001b[39m:\n\u001b[32m    406\u001b[39m     retry_rm, retry_cb = new_group(\n\u001b[32m    407\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mfix_output_format\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    408\u001b[39m         inputs={\u001b[33m\"\u001b[39m\u001b[33moutput_string\u001b[39m\u001b[33m\"\u001b[39m: output_string},\n\u001b[32m    409\u001b[39m         callbacks=callbacks,\n\u001b[32m    410\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     fixed_output_string = \u001b[38;5;28;01mawait\u001b[39;00m fix_output_format_prompt.generate(\n\u001b[32m    412\u001b[39m         llm=llm,\n\u001b[32m    413\u001b[39m         data=OutputStringAndPrompt(\n\u001b[32m    414\u001b[39m             output_string=output_string,\n\u001b[32m    415\u001b[39m             prompt_value=prompt_value.to_string(),\n\u001b[32m    416\u001b[39m         ),\n\u001b[32m    417\u001b[39m         callbacks=retry_cb,\n\u001b[32m    418\u001b[39m         retries_left=retries_left - \u001b[32m1\u001b[39m,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m    420\u001b[39m     retry_rm.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33mfixed_output_string\u001b[39m\u001b[33m\"\u001b[39m: fixed_output_string})\n\u001b[32m    421\u001b[39m     result = \u001b[38;5;28msuper\u001b[39m().parse(fixed_output_string.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:129\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    126\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    130\u001b[39m     llm=llm,\n\u001b[32m    131\u001b[39m     data=data,\n\u001b[32m    132\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    133\u001b[39m     temperature=temperature,\n\u001b[32m    134\u001b[39m     stop=stop,\n\u001b[32m    135\u001b[39m     callbacks=callbacks,\n\u001b[32m    136\u001b[39m     retries_left=retries_left,\n\u001b[32m    137\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:203\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    201\u001b[39m output_string = resp.generations[\u001b[32m0\u001b[39m][i].text\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     answer = \u001b[38;5;28;01mawait\u001b[39;00m parser.parse_output_string(\n\u001b[32m    204\u001b[39m         output_string=output_string,\n\u001b[32m    205\u001b[39m         prompt_value=prompt_value,\n\u001b[32m    206\u001b[39m         llm=llm,\n\u001b[32m    207\u001b[39m         callbacks=prompt_cb,\n\u001b[32m    208\u001b[39m         retries_left=retries_left,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m    210\u001b[39m     processed_output = \u001b[38;5;28mself\u001b[39m.process_output(answer, data)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    211\u001b[39m     output_models.append(processed_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:411\u001b[39m, in \u001b[36mRagasOutputParser.parse_output_string\u001b[39m\u001b[34m(self, output_string, prompt_value, llm, callbacks, retries_left)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retries_left != \u001b[32m0\u001b[39m:\n\u001b[32m    406\u001b[39m     retry_rm, retry_cb = new_group(\n\u001b[32m    407\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mfix_output_format\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    408\u001b[39m         inputs={\u001b[33m\"\u001b[39m\u001b[33moutput_string\u001b[39m\u001b[33m\"\u001b[39m: output_string},\n\u001b[32m    409\u001b[39m         callbacks=callbacks,\n\u001b[32m    410\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     fixed_output_string = \u001b[38;5;28;01mawait\u001b[39;00m fix_output_format_prompt.generate(\n\u001b[32m    412\u001b[39m         llm=llm,\n\u001b[32m    413\u001b[39m         data=OutputStringAndPrompt(\n\u001b[32m    414\u001b[39m             output_string=output_string,\n\u001b[32m    415\u001b[39m             prompt_value=prompt_value.to_string(),\n\u001b[32m    416\u001b[39m         ),\n\u001b[32m    417\u001b[39m         callbacks=retry_cb,\n\u001b[32m    418\u001b[39m         retries_left=retries_left - \u001b[32m1\u001b[39m,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m    420\u001b[39m     retry_rm.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33mfixed_output_string\u001b[39m\u001b[33m\"\u001b[39m: fixed_output_string})\n\u001b[32m    421\u001b[39m     result = \u001b[38;5;28msuper\u001b[39m().parse(fixed_output_string.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:129\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    126\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    130\u001b[39m     llm=llm,\n\u001b[32m    131\u001b[39m     data=data,\n\u001b[32m    132\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    133\u001b[39m     temperature=temperature,\n\u001b[32m    134\u001b[39m     stop=stop,\n\u001b[32m    135\u001b[39m     callbacks=callbacks,\n\u001b[32m    136\u001b[39m     retries_left=retries_left,\n\u001b[32m    137\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:203\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    201\u001b[39m output_string = resp.generations[\u001b[32m0\u001b[39m][i].text\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     answer = \u001b[38;5;28;01mawait\u001b[39;00m parser.parse_output_string(\n\u001b[32m    204\u001b[39m         output_string=output_string,\n\u001b[32m    205\u001b[39m         prompt_value=prompt_value,\n\u001b[32m    206\u001b[39m         llm=llm,\n\u001b[32m    207\u001b[39m         callbacks=prompt_cb,\n\u001b[32m    208\u001b[39m         retries_left=retries_left,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m    210\u001b[39m     processed_output = \u001b[38;5;28mself\u001b[39m.process_output(answer, data)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    211\u001b[39m     output_models.append(processed_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/ragas/prompt/pydantic_prompt.py:421\u001b[39m, in \u001b[36mRagasOutputParser.parse_output_string\u001b[39m\u001b[34m(self, output_string, prompt_value, llm, callbacks, retries_left)\u001b[39m\n\u001b[32m    411\u001b[39m     fixed_output_string = \u001b[38;5;28;01mawait\u001b[39;00m fix_output_format_prompt.generate(\n\u001b[32m    412\u001b[39m         llm=llm,\n\u001b[32m    413\u001b[39m         data=OutputStringAndPrompt(\n\u001b[32m   (...)\u001b[39m\u001b[32m    418\u001b[39m         retries_left=retries_left - \u001b[32m1\u001b[39m,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m    420\u001b[39m     retry_rm.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33mfixed_output_string\u001b[39m\u001b[33m\"\u001b[39m: fixed_output_string})\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_output_string\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RagasOutputParserException()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/output_parsers/pydantic.py:83\u001b[39m, in \u001b[36mPydanticOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> TBaseModel:\n\u001b[32m     75\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m        The parsed pydantic object.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/output_parsers/json.py:97\u001b[39m, in \u001b[36mJsonOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a JSON object.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m        The parsed JSON object.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/output_parsers/pydantic.py:67\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the result of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m \u001b[33;03m    The parsed pydantic object.\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     json_object = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_obj(json_object)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/langchain_core/output_parsers/json.py:86\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     85\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: I am trying to understand how Large Language Models (LLMs) and Chatbots work, especially in the context of financial services. Can you explain it in simple terms?\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
      "Prompt query_answer_generation_prompt failed to parse output: The output parser failed to parse the output including retries.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testset = generator.generate(testset_size=3, query_distribution=query_distribution_onlysingle, num_personas=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:   0%|          | 0/22 [00:00<?, ?it/s]           Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Applying SummaryExtractor:   9%|▉         | 2/22 [00:02<00:17,  1.15it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Applying SummaryExtractor:  14%|█▎        | 3/22 [00:02<00:10,  1.77it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Applying SummaryExtractor:  18%|█▊        | 4/22 [00:02<00:07,  2.39it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Applying SummaryExtractor:  23%|██▎       | 5/22 [00:02<00:05,  3.07it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Applying SummaryExtractor:  27%|██▋       | 6/22 [00:04<00:11,  1.45it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Applying SummaryExtractor:  32%|███▏      | 7/22 [00:04<00:09,  1.51it/s]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Property 'summary' already exists in node 'd4470d'. Skipping!\n",
      "Property 'summary' already exists in node '952696'. Skipping!\n",
      "Applying SummaryExtractor:  55%|█████▍    | 12/22 [01:02<00:55,  5.52s/it]Property 'summary' already exists in node '8f24eb'. Skipping!\n",
      "Applying SummaryExtractor:  59%|█████▉    | 13/22 [01:03<00:37,  4.22s/it]Property 'summary' already exists in node '4f1a5a'. Skipping!\n",
      "Property 'summary' already exists in node '7be98a'. Skipping!\n",
      "Applying SummaryExtractor:  73%|███████▎  | 16/22 [01:06<00:14,  2.47s/it]Property 'summary' already exists in node 'fe1d56'. Skipping!\n",
      "Applying SummaryExtractor:  77%|███████▋  | 17/22 [01:07<00:10,  2.02s/it]Property 'summary' already exists in node '9b0b6c'. Skipping!\n",
      "Applying SummaryExtractor:  82%|████████▏ | 18/22 [01:13<00:12,  3.11s/it]Property 'summary' already exists in node '864979'. Skipping!\n",
      "Applying SummaryExtractor:  86%|████████▋ | 19/22 [01:14<00:07,  2.35s/it]Property 'summary' already exists in node 'e570ec'. Skipping!\n",
      "Applying SummaryExtractor:  91%|█████████ | 20/22 [01:19<00:06,  3.31s/it]Property 'summary' already exists in node '158cc0'. Skipping!\n",
      "Applying SummaryExtractor:  95%|█████████▌| 21/22 [01:20<00:02,  2.52s/it]Property 'summary' already exists in node 'e581ae'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/22 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node '952696'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8f24eb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9b0b6c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e570ec'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd4470d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '158cc0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fe1d56'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4f1a5a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '864979'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e581ae'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7be98a'. Skipping!\n",
      "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]                                                  Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Generating personas:  33%|███▎      | 1/3 [00:01<00:02,  1.21s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Generating personas:  67%|██████▋   | 2/3 [00:05<00:03,  3.26s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Generating personas: 100%|██████████| 3/3 [00:17<00:00,  5.95s/it]\n",
      "Generating Scenarios:  50%|█████     | 1/2 [00:03<00:03,  3.77s/it]Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "Generating Scenarios: 100%|██████████| 2/2 [07:47<00:00, 233.57s/it]\n",
      "Generating Samples: 100%|██████████| 5/5 [00:03<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "generator = TestsetGenerator(llm = generator_llm, embedding_model=ragas_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10, with_debugging_logs=True, raise_exceptions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What learning rate was used when tuning the pu...</td>\n",
       "      <td>[modelthatwecanreuseforprompttuningacross ingr...</td>\n",
       "      <td>When tuning the public T5.1.1 checkpoints on S...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a machine learning researcher, can you elab...</td>\n",
       "      <td>[100\\n90\\n80\\n70\\n60\\n50\\n108 109 1010\\nModel ...</td>\n",
       "      <td>Increasing to 20+ tokens generally confers a l...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Considering my expertise in machine lerning an...</td>\n",
       "      <td>[the class based initialization performs best....</td>\n",
       "      <td>The context indicates that pre-training object...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Considering the differences between prompt tun...</td>\n",
       "      <td>[ateverytransformerlayer. Thisisakintolearning...</td>\n",
       "      <td>Adapters modify the actual function that acts ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wat is teh accurecy of teh BoolQ model?</td>\n",
       "      <td>[Train Eval Tuning Accuracy F1 Dataset Metric ...</td>\n",
       "      <td>The BoolQ model has an accuracy of 91.1, 91.3,...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What learning rate was used when tuning the pu...   \n",
       "1  As a machine learning researcher, can you elab...   \n",
       "2  Considering my expertise in machine lerning an...   \n",
       "3  Considering the differences between prompt tun...   \n",
       "4            Wat is teh accurecy of teh BoolQ model?   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [modelthatwecanreuseforprompttuningacross ingr...   \n",
       "1  [100\\n90\\n80\\n70\\n60\\n50\\n108 109 1010\\nModel ...   \n",
       "2  [the class based initialization performs best....   \n",
       "3  [ateverytransformerlayer. Thisisakintolearning...   \n",
       "4  [Train Eval Tuning Accuracy F1 Dataset Metric ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  When tuning the public T5.1.1 checkpoints on S...   \n",
       "1  Increasing to 20+ tokens generally confers a l...   \n",
       "2  The context indicates that pre-training object...   \n",
       "3  Adapters modify the actual function that acts ...   \n",
       "4  The BoolQ model has an accuracy of 91.1, 91.3,...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  single_hop_specifc_query_synthesizer  \n",
       "4  single_hop_specifc_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 테스트셋을 pandas DataFrame으로 변환\n",
    "test_df = dataset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deeper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
