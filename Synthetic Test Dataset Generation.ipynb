{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyC06D**********\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['GOOGLE_API_KEY'][:10]+'*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Synthetic Data Generation\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"Synthetic Data Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# 문서 로더 생성\n",
    "# loader = PDFPlumberLoader(\"data/Prompt_Tuning.pdf\")\n",
    "loader = PDFPlumberLoader(\"data/2025 KB 부동산 보고서.pdf\")\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 목차, 끝 페이지 제외\n",
    "docs = docs[1:-1]\n",
    "\n",
    "# 문서의 페이지수\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망\\nEx ecutive Summary 1\\n\\uf06e 2025년 주택시장 하향 안정, 정부 정책 방향이 중요한 한 해가 될 전망\\n주택시장은 2022년 하반기 이후 상승과 하락을 반복하는 상황이 지속되고 있다. 이러한 시장 흐름은\\n올해도 이어질 것으로 보인다. 높은 가격에 대한 부담, 대출 규제 등의 하락 요인과 함께 공급 부족, 금리 인하\\n등의 상승 요인이 혼재되어 있기 때문이다. 다만, 선호도에 따른 지역별 차별화 현상은 더욱 확대될 수 있다.\\n올해 주택시장의 가장 큰 변수는 정부의 정책이 될 가능성이 높다. 지난해 하반기 시장 흐름에서 볼 수\\n있듯이, 실수요자 중심인 현재의 주택시장에서 대출 규제의 영향은 상당히 크다. 올해 주택시장의 또 다른\\n변수는 주택 공급이 될 수 있다. 공사비 증가, 부동산 프로젝트파이낸싱(PF) 시장 경색으로 민간 공급이\\n제한적인 상황에서 3기 신도시 등 공공 주도의 공급이 미치는 영향이 클 수 있기 때문이다. 도심지 주택 공급을\\n위해서는 재건축, 재개발 등 정비사업의 원활한 진행이 중요한데, 이 또한 규제 및 정부 정책과 밀접한 관련이\\n있다. 정부 정책은 늘 주택시장에 큰 영향을 미쳐 왔으나 올해는 더욱 중요하게 작용할 전망이다.\\n\\uf06e 7대 이슈를 통해 바라보는 2025년 주택시장\\n1 주택시장 불안의 핵심 요인으로 지목되는 공급물량\\n공급물량 부족이 주택시장 불안 요인으로 지적되면서 정부는 공급 확대를 위해 다양한 정책을\\n발표. 주택 경기가 좋지 않다는 점에서 물량보다는 선호 지역 공급 여부가 관건이 될 것임\\n2 침체가 지속되고 있는 비수도권 주택시장 반등 가능성\\n지난해 하반기 이후 수도권과 비수도권의 차별화가 뚜렷하게 나타나고 있음. 높은 가격에 대한\\n수요자의 부담이 여전한 데다 미분양 아파트도 적체되어 지역별 양극화 현상이 지속될 것임\\n3 2025년 주택시장의 핵심 변수인 금리 인하와 대출 규제\\n기준금리 인하에 따른 매수 수요 회복에 대한 기대감이 존재하나 단기적으로 정부의 가계부채\\n관리 강화 정책이 시장에 미치는 영향이 더 클 것임\\n4 서민의 주된 주거 수단인 비아파트 시장 정상화 가능성\\n전세사기 사건 이후 연립·다세대주택 기피 현상이 심화되면서 비아파트 거래 및 공급이 크게 위\\n축. 정부 정책과 월세 증가로 시장 정상화 가능성이 존재하나 회복까지는 다소 시간이 걸릴 것임\\n5 우려와 기대 속에 본궤도에 오르는 노후계획도시 정비사업\\n노후계획도시 정비사업의 중요한 이정표가 될 선도지구 선정이 완료되었으나 추가 분담금, 조합\\n원 간의 갈등, 대규모 이주 등 해결 과제가 여전히 많아 올해가 중요한 한 해가 될 것임\\n6 주택 경기 판단의 바로미터인 서울 아파트 시장\\n세부 지역별로 상승폭 격차가 확대되면서 고점 대비 현재 가격 차이가 크며, 대출 규제 이후 수\\n요가 크게 둔화되어 향후 가격 상승폭은 제한적일 것으로 보이나 국지적 시장 과열 가능성 존재\\n7 상승세가 지속되고 있는 전세시장의 불안 요인\\n매매 수요 위축으로 전세 수요가 과거보다 높으며, 특히 수요자 선호도가 높은 아파트를 중심으\\n로 전세가격 상승세가 지속될 전망. 비아파트 중심의 월세 상승도 시장 불안 요인이 될 것임\\n1\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for doc in docs:\n",
    "\ttext_org = doc.page_content\n",
    "\tclean_text = re.split(r'\\U000f080f', text_org)[-1]\n",
    "\tdoc.page_content = clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망\\nEx ecutive Summary 1\\n\\uf06e 2025년 주택시장 하향 안정, 정부 정책 방향이 중요한 한 해가 될 전망\\n주택시장은 2022년 하반기 이후 상승과 하락을 반복하는 상황이 지속되고 있다. 이러한 시장 흐름은\\n올해도 이어질 것으로 보인다. 높은 가격에 대한 부담, 대출 규제 등의 하락 요인과 함께 공급 부족, 금리 인하\\n등의 상승 요인이 혼재되어 있기 때문이다. 다만, 선호도에 따른 지역별 차별화 현상은 더욱 확대될 수 있다.\\n올해 주택시장의 가장 큰 변수는 정부의 정책이 될 가능성이 높다. 지난해 하반기 시장 흐름에서 볼 수\\n있듯이, 실수요자 중심인 현재의 주택시장에서 대출 규제의 영향은 상당히 크다. 올해 주택시장의 또 다른\\n변수는 주택 공급이 될 수 있다. 공사비 증가, 부동산 프로젝트파이낸싱(PF) 시장 경색으로 민간 공급이\\n제한적인 상황에서 3기 신도시 등 공공 주도의 공급이 미치는 영향이 클 수 있기 때문이다. 도심지 주택 공급을\\n위해서는 재건축, 재개발 등 정비사업의 원활한 진행이 중요한데, 이 또한 규제 및 정부 정책과 밀접한 관련이\\n있다. 정부 정책은 늘 주택시장에 큰 영향을 미쳐 왔으나 올해는 더욱 중요하게 작용할 전망이다.\\n\\uf06e 7대 이슈를 통해 바라보는 2025년 주택시장\\n1 주택시장 불안의 핵심 요인으로 지목되는 공급물량\\n공급물량 부족이 주택시장 불안 요인으로 지적되면서 정부는 공급 확대를 위해 다양한 정책을\\n발표. 주택 경기가 좋지 않다는 점에서 물량보다는 선호 지역 공급 여부가 관건이 될 것임\\n2 침체가 지속되고 있는 비수도권 주택시장 반등 가능성\\n지난해 하반기 이후 수도권과 비수도권의 차별화가 뚜렷하게 나타나고 있음. 높은 가격에 대한\\n수요자의 부담이 여전한 데다 미분양 아파트도 적체되어 지역별 양극화 현상이 지속될 것임\\n3 2025년 주택시장의 핵심 변수인 금리 인하와 대출 규제\\n기준금리 인하에 따른 매수 수요 회복에 대한 기대감이 존재하나 단기적으로 정부의 가계부채\\n관리 강화 정책이 시장에 미치는 영향이 더 클 것임\\n4 서민의 주된 주거 수단인 비아파트 시장 정상화 가능성\\n전세사기 사건 이후 연립·다세대주택 기피 현상이 심화되면서 비아파트 거래 및 공급이 크게 위\\n축. 정부 정책과 월세 증가로 시장 정상화 가능성이 존재하나 회복까지는 다소 시간이 걸릴 것임\\n5 우려와 기대 속에 본궤도에 오르는 노후계획도시 정비사업\\n노후계획도시 정비사업의 중요한 이정표가 될 선도지구 선정이 완료되었으나 추가 분담금, 조합\\n원 간의 갈등, 대규모 이주 등 해결 과제가 여전히 많아 올해가 중요한 한 해가 될 것임\\n6 주택 경기 판단의 바로미터인 서울 아파트 시장\\n세부 지역별로 상승폭 격차가 확대되면서 고점 대비 현재 가격 차이가 크며, 대출 규제 이후 수\\n요가 크게 둔화되어 향후 가격 상승폭은 제한적일 것으로 보이나 국지적 시장 과열 가능성 존재\\n7 상승세가 지속되고 있는 전세시장의 불안 요인\\n매매 수요 위축으로 전세 수요가 과거보다 높으며, 특히 수요자 선호도가 높은 아파트를 중심으\\n로 전세가격 상승세가 지속될 전망. 비아파트 중심의 월세 상승도 시장 불안 요인이 될 것임\\n1\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/2025 KB 부동산 보고서.pdf',\n",
       " 'file_path': 'data/2025 KB 부동산 보고서.pdf',\n",
       " 'page': 1,\n",
       " 'total_pages': 82,\n",
       " 'Title': 'Morning Meeting',\n",
       " 'Author': '손은경',\n",
       " 'Creator': 'Microsoft® Word 2016',\n",
       " 'CreationDate': \"D:20250319181811+09'00'\",\n",
       " 'ModDate': \"D:20250319181811+09'00'\",\n",
       " 'Producer': 'Microsoft® Word 2016'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 설정(filename 이 존재해야 함)\n",
    "for doc in docs:\n",
    "    doc.metadata[\"filename\"] = doc.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "# from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "\n",
    "# 데이터셋 생성기\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# llm = ChatOllama(model=\"dnotitia/dna\")\n",
    "# llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# 문서 임베딩\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "# embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choeingyu/Library/Caches/pypoetry/virtualenvs/rag-practice-yRokgf4J-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "# LangChain의 gemini 모델을 LangchainLLMWrapper로 감싸 Ragas와 호환되게 만듭니다.\n",
    "generator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "# ragas_embeddings 생성\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 Default 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지식그래프 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서 노드 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kg = KnowledgeGraph()\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 80, relationships: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform 적용으로 노드 재생성 및 엣지(relationships) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "\n",
    "# define your LLM and Embedding Model\n",
    "# here we are using the same LLM and Embedding Model that we used to generate the testset\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = ragas_embeddings\n",
    "\n",
    "trans = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HeadlinesExtractor(name='HeadlinesExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ff7e0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='headlines', prompt=HeadlinesExtractorPrompt(instruction=Extract the most important max_num headlines from the given text that can be used to split the text into independent sections.Focus on Level 2 and Level 3 headings., examples=[(TextWithExtractionLimit(text='                Introduction\\n                Overview of the topic...\\n\\n                Main Concepts\\n                Explanation of core ideas...\\n\\n                Detailed Analysis\\n                Techniques and methods for analysis...\\n\\n                Subsection: Specialized Techniques\\n                Further details on specialized techniques...\\n\\n                Future Directions\\n                Insights into upcoming trends...\\n\\n                Subsection: Next Steps in Research\\n                Discussion of new areas of study...\\n\\n                Conclusion\\n                Final remarks and summary.\\n                ', max_num=6), Headlines(headlines=['Introduction', 'Main Concepts', 'Detailed Analysis', 'Subsection: Specialized Techniques', 'Future Directions', 'Conclusion']))], language=english), max_num=5),\n",
       " HeadlineSplitter(name='HeadlineSplitter', filter_nodes=<function default_filter at 0x16fe68860>, min_tokens=500, max_tokens=1000),\n",
       " SummaryExtractor(name='SummaryExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ff920>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='summary', prompt=SummaryExtractorPrompt(instruction=Summarize the given text in less than 10 sentences., examples=[(StringIO(text='Artificial intelligence\\n\\nArtificial intelligence is transforming various industries by automating tasks that previously required human intelligence. From healthcare to finance, AI is being used to analyze vast amounts of data quickly and accurately. This technology is also driving innovations in areas like self-driving cars and personalized recommendations.'), StringIO(text='AI is revolutionizing industries by automating tasks, analyzing data, and driving innovations like self-driving cars and personalized recommendations.'))], language=english)),\n",
       " CustomNodeFilter(name='CustomNodeFilter', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ffce0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), scoring_prompt=QuestionPotentialPrompt(instruction=Given a document summary and node content, score the content of the node in 1 to 5 range., examples=[], language=english), min_score=2, rubrics={'score1_description': 'The page content is irrelevant or does not align with the main themes or topics of the document summary.', 'score2_description': \"The page content partially aligns with the document summary, but it includes unrelated details or lacks critical information related to the document's main themes.\", 'score3_description': 'The page content generally reflects the document summary but may miss key details or lack depth in addressing the main themes.', 'score4_description': 'The page content aligns well with the document summary, covering the main themes and topics with minor gaps or minimal unrelated information.', 'score5_description': \"The page content is highly relevant, accurate, and directly reflects the main themes of the document summary, covering all important details and adding depth to the understanding of the document's topics.\"}),\n",
       " <ragas.testset.transforms.engine.Parallel at 0x16a7cecd0>,\n",
       " <ragas.testset.transforms.engine.Parallel at 0x16fe21ed0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 80, relationships: 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HeadlinesExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/1041252660.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(trans[0].generate_execution_plan(kg=kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[0].generate_execution_plan(kg=kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/966529865.py:3: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(a.generate_execution_plan(kg=kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms.extractors.llm_based import HeadlinesExtractor\n",
    "a = HeadlinesExtractor(llm=generator_llm)\n",
    "len(a.generate_execution_plan(kg=kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.utils import num_tokens_from_string\n",
    "num_tokens_from_string(kg.nodes[1].get_property(\"page_content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(kg, trans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 80, relationships: 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.save(\"kg_docs/kg_HeadlineExtractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg = KnowledgeGraph().load(\"kg_docs/kg_HeadlineExtractor.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HeadlinesSpliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadlineSplitter(name='HeadlineSplitter', filter_nodes=<function default_filter at 0x16fe68860>, min_tokens=500, max_tokens=1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/3840880366.py:1: RuntimeWarning: coroutine 'Splitter.generate_execution_plan.<locals>.apply_split' was never awaited\n",
      "  len(trans[1].generate_execution_plan(kg=load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[1].generate_execution_plan(kg=load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Executive Summary',\n",
       " '7대 이슈를 통해 바라보는 2025년 주택시장',\n",
       " '주택시장 불안의 핵심 요인으로 지목되는 공급물량',\n",
       " '침체가 지속되고 있는 비수도권 주택시장 반등 가능성',\n",
       " '2025년 주택시장의 핵심 변수인 금리 인하와 대출 규제']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg.nodes[0].get_property(\"headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_kg.nodes[0].get_property(\"page_content\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans[1].filter_nodes = trans[0].filter_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=[node for node in load_kg.nodes if trans[1].filter_nodes(node)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadlineSplitter(name='HeadlineSplitter', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ff7e0>, min_tokens=500, max_tokens=1000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_kg.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "from ragas.testset.transforms.splitters.headline import HeadlineSplitter\n",
    "apply_transforms(load_kg, HeadlineSplitter(filter_nodes=trans[0].filter_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 154, relationships: 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg.save(\"kg_docs/kg_HeadlineSpliter.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg=KnowledgeGraph().load(\"kg_docs/kg_HeadlineSpliter.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Executive Summary',\n",
       " '7대 이슈를 통해 바라보는 2025년 주택시장',\n",
       " '주택시장 불안의 핵심 요인으로 지목되는 공급물량',\n",
       " '침체가 지속되고 있는 비수도권 주택시장 반등 가능성',\n",
       " '2025년 주택시장의 핵심 변수인 금리 인하와 대출 규제']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg.nodes[0].get_property(\"headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 154, relationships: 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_doc = [n for n in load_kg.nodes if n.type == NodeType.DOCUMENT]\n",
    "len(node_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_chunk = [n for n in load_kg.nodes if n.type == NodeType.CHUNK]\n",
    "len(node_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망\n",
      "Ex ecutive Summary 3\n",
      " 현장에서 바라본 주택시장\n",
      "2024년 주택 매매가격은 3분기 이후 상승세를 보였으나 4분기 들어 상승폭이 크게 위축되었다. 그러나\n",
      "매수 대기 수요가 존재하여 수요자가 선호하는 지역이나 주요 이슈가 존재하는 지역에 대한 관심은\n",
      "여전히 큰 것으로 나타났다. KB금융지주 경영연구소는 수요가 높은 수도권 15개 지역을 5개 구역으로\n",
      "구분해 지역별 주택시장을 점검해 보았다.\n",
      "구분 지역 주요 이슈\n",
      "강남구 서울 25개 자치구 중 가장 높은 상승률 기록. 압구정 재건축 단지의 사업 진행 상황이 시장에 큰 영향\n",
      "서울\n",
      "한강 서초구 분양시장 중심으로 주택가격 크게 상승. 매수세는 둔화되었으나 여전히 매도자 우위 시장이 형성\n",
      "이남 송파구 재건축 사업이 탄력을 받으며 시장 관심 증가. 토지거래허가구역 해제 이후 시장 내 기대감 상승\n",
      "서울 마포구 강북 최고 분양가를 기록하는 등 상승세가 지속되었으나 매수세는 다소 위축\n",
      "한강 용산구 한남 뉴타운 및 용산국제업무지구 개발 사업 진행에 따른 긍정적 기대감 지속\n",
      "이북 성동구 실수요자 중심 시장으로 대출 규제 이후 관망세. 성수전략정비구역 심의 통과는 긍정적 요인\n",
      "서울 대치동 학군지에 대한 꾸준한 수요와 재건축 단지에 대한 관심 지속\n",
      "주요 목동 목동 14개 단지 중 6개 단지가 정비구역으로 지정되면서 재건축 진행 속도가 주요 변수로 등장\n",
      "학군 지역 중계동 노원구 주택시장 침체에도 상대적으로 양호한 흐름. 매수자는 대출 규제 완화 등 여건 개선 기대\n",
      "수도권 분당 선도지구 선정 이후 보합세 지속. 향후 사업 추진 상황이 중요한 요인으로 작용\n",
      "주요 과천 2024년 전국에서 가장 높은 상승률 기록. 기존 과천 도심에 대한 수요는 여전\n",
      "정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 상황에서 분양가 상승이 변수\n",
      "수도권 위례 위례선 트램, 위례신사선 등 교통 관련 사업 진행 상황이 시장의 주요 관심사\n",
      "교통 이슈 동탄 GTX 개통 이후 접근성, 비용 문제 등이 부각. 추가적인 교통 개발과 반도체 등 산업 수요는 증가\n",
      "지역 송도 GTX 건설 추진 지연으로 기대감 감소. 제약·바이오 산업 유입에 따른 수요 증가는 긍정적 요인\n",
      " 상업용 부동산시장\n",
      "2024년 상업용 부동산 거래량은 2023년 대비 11.6% 감소한 4.6만 건으로 2021년 9.6만 건으로 고점을\n",
      "기록한 이후 3년 연속 감소하였다. 상업용 부동산 평균 매매가격은 전년 대비 수도권이 0.9%, 비수도권이\n",
      "8.3% 하락하였다. 거래가 줄고 가격이 하락하면서 시장은 경기 순환 국면상 침체기 흐름을 보였다.\n",
      "2025년에는 기준금리 추가 인하 가능성이 시장 회복에 긍정적인 요인으로 작용할 것으로 기대된다.\n",
      "부동산 경기 침체, 건설사 PF 이슈 등으로 인해 공급이 감소하여 시장의 공급 부담도 크게 낮아질 수\n",
      "있다. 다만, 국내 경제 불확실성이 큰 상황에서 부동산 투자는 리스크 최소화에 중점을 둘 수밖에 없으며,\n",
      "우량자산 위주의 투자로 인해 시장 회복은 제한적일 것으로 전망된다.\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(load_kg.relationships[0].source.get_property(\"page_content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2. 파운데이션 모델(Foundation Model) 및 첫 번째 작업은 LLM이 학습될 리소스인 학습 데 LLM 사전학습(Pre-training) 이터 세트를 수집하는 것이다. 데이터는 책, 웹 생성형 AI 모델은 어떤 출력을 생성하는가에 사이트, 기사, 공개 데이터세트 등 다양한 소스에서 따라서 언어모델, 이미지 모델, 동영상 모델 등 가져올 수 있다. 유능한 LLM을 개발하기 위해 을 사용한다. 하지만 현재는 이미지와 텍스트를 사전 학습된 자료로 텍스트 데이터 세트를 사용 동시에 학습하는 멀티모달(Multi-modal) 모델들이 한다. 사전 학습된 코퍼스의 소스는 크게 일반 데이 하루가 다르게 성능과 기능이 업그레이드고 있고 터와 전문 데이터의 두 가지 유형으로 분류할 수 있으며 기초모델로 자리잡아가고 있다(정천수, 있으며 웹 페이지, 서적 및 대화 텍스트와 같은 2023d). 파운데이션 모델(Foundation Model)의 데 일반 데이터는 크고 다양하며 접근 가능한 특성 이터는 텍스트, 이미지, 음성, 정형데이터, 3D 시 으로 인해 대부분의 LLM에서 활용되며 LLM의 그널 등 구분하지 않고 학습에 이용되며 인간의 언어 모델링 및 일반화 능력을 향상시킬 수 있다. 창의력과 추론력을 포함한 일을 수행하며 이러한 또한 다국어 데이터, 과학 데이터 및 코드와 같은 기초모델은 방대한 양의 데이터를 비지도 학습 보다 전문화된 데이터 세트로 확장하여 LLM에 (Unsupervised learning)을 통해 모델을 학습시킨 특정 작업 해결 기능을 부여하는 연구도 발표되고 후 배포되어 사용자가 원하는 목적에 맞게 다운 있다(Chowdhery et al., 2023; Nijkamp et al., 2022). 스트림 작업에 대해 파인튜닝이나 문맥 내 학습 <그림 3>은 일반적인 LLM의 데이터 수집 및 (In-context learning)등과 같은 과정을 거처 완성 사전학습 절차를 보여주고 있다(Zhao et al., 2023). 되는 것이 파운데이션 모델이라고 볼 수 있다 모델 학습은 지도 학습(Supervised learning)을 사용 (Bommasani, et. al., 2021). 하여 전 처리된 텍스트 데이터에 대해 학습된다. 파운데이션 모델 중에서 언어모델로서의 LLM은 또한 모델과 데이터의 크기가 크기 때문에 모델을 일반 Text 데이터인 Wikipidia 등 거대한 일반적인 학습하려면 엄청난 계산 능력이 필요하며 학습 지식들을 수집하여 자기지도학습(Self-Supervised 시간을 줄이기 위해 모델 병렬화라는 기술이 사 Learning)이나 반자기지도학습(Semi-Supervised 용된다. 이렇게 대규모 언어 모델을 처음부터 학 Learning)을 사용하여 레이블링되지 않은 상당한 습하려면 상당한 투자가 필요하기 때문에 보다 양의 텍스트로 사전 학습된 언어 모델(Pre-trained 경제적인 대안으로 기존 언어 모델을 특정 사용 Language Model, PLM)이다.\n"
     ]
    }
   ],
   "source": [
    "print(load_kg.relationships[0].target.get_property(\"page_content\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중복 Node 제거 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_kg=KnowledgeGraph().load(\"kg_docs/kg_HeadlineSpliter.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 154, relationships: 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes = set()\n",
    "for node in loaded_kg.nodes:\n",
    "    unique_nodes.add(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rels = set()\n",
    "for rel in loaded_kg.relationships:\n",
    "    unique_rels.add(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(unique_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in loaded_kg.relationships:\n",
    "    if (rel.source in unique_nodes) & (rel.target in unique_nodes):\n",
    "        continue\n",
    "    else:\n",
    "        print(rel.source, rel.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.base import NodeFilter\n",
    "# from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_node = loaded_kg.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 80],\n",
       " [1, 81],\n",
       " [2],\n",
       " [3, 84],\n",
       " [4],\n",
       " [5, 85],\n",
       " [6, 86],\n",
       " [7, 87],\n",
       " [8, 88],\n",
       " [9, 89],\n",
       " [10, 90],\n",
       " [11, 91],\n",
       " [12, 92],\n",
       " [13, 93],\n",
       " [14, 94],\n",
       " [15, 95],\n",
       " [16, 96],\n",
       " [17, 97],\n",
       " [18],\n",
       " [19, 100],\n",
       " [20, 101],\n",
       " [21, 102],\n",
       " [22, 103],\n",
       " [23, 104],\n",
       " [24, 105],\n",
       " [25, 106],\n",
       " [26],\n",
       " [27, 107],\n",
       " [28, 108],\n",
       " [29, 109],\n",
       " [30],\n",
       " [31],\n",
       " [32, 110],\n",
       " [33, 111],\n",
       " [34, 112],\n",
       " [35, 113],\n",
       " [36, 114],\n",
       " [37, 115],\n",
       " [38, 116],\n",
       " [39, 117],\n",
       " [40],\n",
       " [41, 118],\n",
       " [42],\n",
       " [43],\n",
       " [44, 119],\n",
       " [45, 120],\n",
       " [46, 121],\n",
       " [47, 122],\n",
       " [48, 123],\n",
       " [49, 124],\n",
       " [50, 125],\n",
       " [51, 126],\n",
       " [52, 127],\n",
       " [53, 128],\n",
       " [54, 129],\n",
       " [55, 130],\n",
       " [56, 131],\n",
       " [57, 132],\n",
       " [58, 133],\n",
       " [59, 134],\n",
       " [60],\n",
       " [61, 135],\n",
       " [62, 136],\n",
       " [63, 137],\n",
       " [64, 138],\n",
       " [65, 139],\n",
       " [66, 140],\n",
       " [67, 141],\n",
       " [68, 142],\n",
       " [69, 143],\n",
       " [70, 144],\n",
       " [71, 145],\n",
       " [72, 146],\n",
       " [73, 147],\n",
       " [74, 148],\n",
       " [75, 149],\n",
       " [76, 150],\n",
       " [77, 151],\n",
       " [78, 152],\n",
       " [79, 153],\n",
       " [0, 80],\n",
       " [1, 81],\n",
       " [82],\n",
       " [83],\n",
       " [3, 84],\n",
       " [5, 85],\n",
       " [6, 86],\n",
       " [7, 87],\n",
       " [8, 88],\n",
       " [9, 89],\n",
       " [10, 90],\n",
       " [11, 91],\n",
       " [12, 92],\n",
       " [13, 93],\n",
       " [14, 94],\n",
       " [15, 95],\n",
       " [16, 96],\n",
       " [17, 97],\n",
       " [98],\n",
       " [99],\n",
       " [19, 100],\n",
       " [20, 101],\n",
       " [21, 102],\n",
       " [22, 103],\n",
       " [23, 104],\n",
       " [24, 105],\n",
       " [25, 106],\n",
       " [27, 107],\n",
       " [28, 108],\n",
       " [29, 109],\n",
       " [32, 110],\n",
       " [33, 111],\n",
       " [34, 112],\n",
       " [35, 113],\n",
       " [36, 114],\n",
       " [37, 115],\n",
       " [38, 116],\n",
       " [39, 117],\n",
       " [41, 118],\n",
       " [44, 119],\n",
       " [45, 120],\n",
       " [46, 121],\n",
       " [47, 122],\n",
       " [48, 123],\n",
       " [49, 124],\n",
       " [50, 125],\n",
       " [51, 126],\n",
       " [52, 127],\n",
       " [53, 128],\n",
       " [54, 129],\n",
       " [55, 130],\n",
       " [56, 131],\n",
       " [57, 132],\n",
       " [58, 133],\n",
       " [59, 134],\n",
       " [61, 135],\n",
       " [62, 136],\n",
       " [63, 137],\n",
       " [64, 138],\n",
       " [65, 139],\n",
       " [66, 140],\n",
       " [67, 141],\n",
       " [68, 142],\n",
       " [69, 143],\n",
       " [70, 144],\n",
       " [71, 145],\n",
       " [72, 146],\n",
       " [73, 147],\n",
       " [74, 148],\n",
       " [75, 149],\n",
       " [76, 150],\n",
       " [77, 151],\n",
       " [78, 152],\n",
       " [79, 153]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[[idx for idx, node in enumerate(loaded_kg.nodes) if node == check_node] for check_node in loaded_kg.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuplicateFilter(NodeFilter):\n",
    "    async def custom_filter(self, node, kg):\n",
    "        return len([n for n in kg.nodes if n==node])>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/1716648303.py:1: RuntimeWarning: coroutine 'NodeFilter.generate_execution_plan.<locals>.apply_filter' was never awaited\n",
      "  len(DuplicateFilter().generate_execution_plan(loaded_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(DuplicateFilter().generate_execution_plan(loaded_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 154, relationships: 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "test_kg = deepcopy(loaded_kg)\n",
    "apply_transforms(test_kg, DuplicateFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[n for n in loaded_kg.nodes if n not in test_kg.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kg = KnowledgeGraph(nodes=list(unique_nodes), relationships=loaded_kg.relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kg.save(\"kg_docs/kg_HeadlineSpliter_NoDupli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 38, relationships: 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg=KnowledgeGraph().load(\"kg_docs/kg_HeadlineSpliter_NoDupli.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SummaryExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SummaryExtractor(name='SummaryExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ff920>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='summary', prompt=SummaryExtractorPrompt(instruction=Summarize the given text in less than 10 sentences., examples=[(StringIO(text='Artificial intelligence\\n\\nArtificial intelligence is transforming various industries by automating tasks that previously required human intelligence. From healthcare to finance, AI is being used to analyze vast amounts of data quickly and accurately. This technology is also driving innovations in areas like self-driving cars and personalized recommendations.'), StringIO(text='AI is revolutionizing industries by automating tasks, analyzing data, and driving innovations like self-driving cars and personalized recommendations.'))], language=english))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.extractors.llm_based import SummaryExtractor, SummaryExtractorPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/515234645.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(SummaryExtractor().generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SummaryExtractor().generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/346516686.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(trans[2].generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[2].generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the given text in less than 10 sentences.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"text\": {\"title\": \"Text\", \"type\": \"string\"}}, \"required\": [\"text\"], \"title\": \"StringIO\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"text\": \"Artificial intelligence\\n\\nArtificial intelligence is transforming various industries by automating tasks that previously required human intelligence. From healthcare to finance, AI is being used to analyze vast amounts of data quickly and accurately. This technology is also driving innovations in areas like self-driving cars and personalized recommendations.\"\n",
      "}\n",
      "Output: {\n",
      "    \"text\": \"AI is revolutionizing industries by automating tasks, analyzing data, and driving innovations like self-driving cars and personalized recommendations.\"\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "Input: (None)\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(SummaryExtractorPrompt().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(load_kg, trans[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg.save(\"kg_docs/kg_SummaryExtractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg=KnowledgeGraph().load(\"kg_docs/kg_SummaryExtractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CustomNodeFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNodeFilter(name='CustomNodeFilter', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ffce0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), scoring_prompt=QuestionPotentialPrompt(instruction=Given a document summary and node content, score the content of the node in 1 to 5 range., examples=[], language=english), min_score=2, rubrics={'score1_description': 'The page content is irrelevant or does not align with the main themes or topics of the document summary.', 'score2_description': \"The page content partially aligns with the document summary, but it includes unrelated details or lacks critical information related to the document's main themes.\", 'score3_description': 'The page content generally reflects the document summary but may miss key details or lack depth in addressing the main themes.', 'score4_description': 'The page content aligns well with the document summary, covering the main themes and topics with minor gaps or minimal unrelated information.', 'score5_description': \"The page content is highly relevant, accurate, and directly reflects the main themes of the document summary, covering all important details and adding depth to the understanding of the document's topics.\"})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.filters import CustomNodeFilter, QuestionPotentialInput, QuestionPotentialOutput, QuestionPotentialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/901010791.py:1: RuntimeWarning: coroutine 'NodeFilter.generate_execution_plan.<locals>.apply_filter' was never awaited\n",
      "  len(trans[3].generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[3].generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a document summary and node content, score the content of the node in 1 to 5 range.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"score\": {\"description\": \"1 to 5 score\", \"title\": \"Score\", \"type\": \"integer\"}}, \"required\": [\"score\"], \"title\": \"QuestionPotentialOutput\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "input: {\n",
      "    \"document_summary\": \"\",\n",
      "    \"node_content\": \"\",\n",
      "    \"rubrics\": {\n",
      "        \"score1_description\": \"The page content is irrelevant or does not align with the main themes or topics of the document summary.\",\n",
      "        \"score2_description\": \"The page content partially aligns with the document summary, but it includes unrelated details or lacks critical information related to the document's main themes.\",\n",
      "        \"score3_description\": \"The page content generally reflects the document summary but may miss key details or lack depth in addressing the main themes.\",\n",
      "        \"score4_description\": \"The page content aligns well with the document summary, covering the main themes and topics with minor gaps or minimal unrelated information.\",\n",
      "        \"score5_description\": \"The page content is highly relevant, accurate, and directly reflects the main themes of the document summary, covering all important details and adding depth to the understanding of the document's topics.\"\n",
      "    }\n",
      "}\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(trans[3].scoring_prompt.to_string(data = QuestionPotentialInput(document_summary=\"\", node_content=\"\", rubrics=trans[3].rubrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(load_kg, trans[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg.save(\"kg_docs/kg_CustomNodeFilter.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg = KnowledgeGraph().load(\"kg_docs/kg_CustomNodeFilter.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Transformation(Extractor)\n",
    "- EmbeddingExtractor\n",
    "- ThemesExtractor\n",
    "- NERExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ragas.testset.transforms.engine.Parallel at 0x16a7cecd0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EmbeddingExtractor(name='EmbeddingExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ffb00>, property_name='summary_embedding', embed_property_name='summary', embedding_model=LangchainEmbeddingsWrapper(embeddings=OpenAIEmbeddings(...))),\n",
       " ThemesExtractor(name='ThemesExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ff9c0>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='themes', prompt=ThemesAndConceptsExtractorPrompt(instruction=Extract the main themes and concepts from the given text., examples=[(TextWithExtractionLimit(text='Artificial intelligence is transforming industries by automating tasks requiring human intelligence. AI analyzes vast data quickly and accurately, driving innovations like self-driving cars and personalized recommendations.', max_num=10), ThemesAndConcepts(output=['Artificial intelligence', 'Automation', 'Data analysis', 'Innovation', 'Self-driving cars', 'Personalized recommendations']))], language=english), max_num_themes=10),\n",
       " NERExtractor(name='NERExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ffa60>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='entities', prompt=NERPrompt(instruction=Extract the named entities from the given text, limiting the output to the top entities. Ensure the number of entities does not exceed the specified maximum., examples=[(TextWithExtractionLimit(text='Elon Musk, the CEO of Tesla and SpaceX, announced plans to expand operations to new locations in Europe and Asia.\\n                This expansion is expected to create thousands of jobs, particularly in cities like Berlin and Shanghai.', max_num=10), NEROutput(entities=['Elon Musk', 'Tesla', 'SpaceX', 'Europe', 'Asia', 'Berlin', 'Shanghai']))], language=english), max_num_entities=10)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[4].transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/229079015.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(trans[4].generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[4].generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms.extractors.llm_based import ThemesExtractor, ThemesAndConceptsExtractorPrompt, NERExtractor, NERPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the main themes and concepts from the given text.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"output\": {\"items\": {\"type\": \"string\"}, \"title\": \"Output\", \"type\": \"array\"}}, \"required\": [\"output\"], \"title\": \"ThemesAndConcepts\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"text\": \"Artificial intelligence is transforming industries by automating tasks requiring human intelligence. AI analyzes vast data quickly and accurately, driving innovations like self-driving cars and personalized recommendations.\",\n",
      "    \"max_num\": 10\n",
      "}\n",
      "Output: {\n",
      "    \"output\": [\n",
      "        \"Artificial intelligence\",\n",
      "        \"Automation\",\n",
      "        \"Data analysis\",\n",
      "        \"Innovation\",\n",
      "        \"Self-driving cars\",\n",
      "        \"Personalized recommendations\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "Input: (None)\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(ThemesAndConceptsExtractorPrompt().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the named entities from the given text, limiting the output to the top entities. Ensure the number of entities does not exceed the specified maximum.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"entities\": {\"items\": {\"type\": \"string\"}, \"title\": \"Entities\", \"type\": \"array\"}}, \"required\": [\"entities\"], \"title\": \"NEROutput\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"text\": \"Elon Musk, the CEO of Tesla and SpaceX, announced plans to expand operations to new locations in Europe and Asia.\\n                This expansion is expected to create thousands of jobs, particularly in cities like Berlin and Shanghai.\",\n",
      "    \"max_num\": 10\n",
      "}\n",
      "Output: {\n",
      "    \"entities\": [\n",
      "        \"Elon Musk\",\n",
      "        \"Tesla\",\n",
      "        \"SpaceX\",\n",
      "        \"Europe\",\n",
      "        \"Asia\",\n",
      "        \"Berlin\",\n",
      "        \"Shanghai\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "Input: (None)\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(NERPrompt().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/2979926559.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(trans[4].transformations[0].generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[4].transformations[0].generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/4038458144.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(trans[4].transformations[1].generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[4].transformations[1].generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/k3_nqc096bj2nlgzjqr24y7m0000gn/T/ipykernel_8120/3790453885.py:1: RuntimeWarning: coroutine 'Extractor.generate_execution_plan.<locals>.apply_extract' was never awaited\n",
      "  len(trans[4].transformations[2].generate_execution_plan(load_kg))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans[4].transformations[2].generate_execution_plan(load_kg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                              \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(load_kg, trans[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg.save(\"kg_docs/kg_ParallelExtractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg = KnowledgeGraph().load(\"kg_docs/kg_ParallelExtractor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 6)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Transformation 2(Relation Builder)\n",
    "- CosineSimilarityBuilder\n",
    "- OverlapScoreBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ragas.testset.transforms.engine.Parallel at 0x16fe21ed0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CosineSimilarityBuilder(name='CosineSimilarityBuilder', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ffba0>, property_name='summary_embedding', new_property_name='summary_similarity', threshold=0.7),\n",
       " OverlapScoreBuilder(name='', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x3147ffc40>, property_name='entities', key_name=None, new_property_name='overlap_score', distance_measure=<DistanceMeasure.JARO_WINKLER: 'jaro_winkler'>, distance_threshold=0.9, threshold=0.01)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[5].transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<coroutine object RelationshipBuilder.generate_execution_plan.<locals>.apply_build_relationships at 0x16aeb97e0>,\n",
       " <coroutine object RelationshipBuilder.generate_execution_plan.<locals>.apply_build_relationships at 0x3281af3e0>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[5].generate_execution_plan(load_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<coroutine object RelationshipBuilder.generate_execution_plan.<locals>.apply_build_relationships at 0x3281af060>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[5].transformations[0].generate_execution_plan(load_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<coroutine object RelationshipBuilder.generate_execution_plan.<locals>.apply_build_relationships at 0x3281ae500>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[5].transformations[1].generate_execution_plan(load_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(load_kg, trans[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 429)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg.save(\"kg_docs/kg_RelationshipBuilder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kg = KnowledgeGraph().load(\"kg_docs/kg_RelationshipBuilder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 84, relationships: 429)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=load_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "query_distribution = default_query_distribution(generator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SingleHopSpecificQuerySynthesizer(name='single_hop_specifc_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
       "  1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
       "  2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
       "  , examples=[(QueryCondition(persona=Persona(name='Software Engineer', role_description='Focuses on coding best practices and system design.'), term='microservices', query_style='Formal', query_length='Medium', context='Microservices are an architectural style where applications are structured as a collection of loosely coupled services. Each service is fine-grained and focuses on a single functionality.'), GeneratedQueryAnswer(query='What is the purpose of microservices in software architecture?', answer='Microservices are designed to structure applications as a collection of loosely coupled services, each focusing on a single functionality.'))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english), property_name='entities'),\n",
       "  0.3333333333333333),\n",
       " (MultiHopAbstractQuerySynthesizer(name='multi_hop_abstract_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "  1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "  2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "  3. **Multi-Hop Context Tags**:\n",
       "     - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "     - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), concept_combination_prompt=ConceptCombinationPrompt(instruction=Form combinations by pairing concepts from at least two different lists.\n",
       "  **Instructions:**\n",
       "  - Review the concepts from each node.\n",
       "  - Identify concepts that can logically be connected or contrasted.\n",
       "  - Form combinations that involve concepts from different nodes.\n",
       "  - Each combination should include at least one concept from two or more nodes.\n",
       "  - List the combinations clearly and concisely.\n",
       "  - Do not repeat the same combination more than once., examples=[(ConceptsList(lists_of_concepts=[['Artificial intelligence', 'Automation'], ['Healthcare', 'Data privacy']], max_combinations=2), ConceptCombinations(combinations=[['Artificial intelligence', 'Healthcare'], ['Automation', 'Data privacy']]))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)),\n",
       "  0.3333333333333333),\n",
       " (MultiHopSpecificQuerySynthesizer(name='multi_hop_specific_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "  1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "  2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "  3. **Multi-Hop Context Tags**:\n",
       "     - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "     - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), relation_type='entities_overlap', property_name='entities', theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)),\n",
       "  0.3333333333333333)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, _ in query_distribution:\n",
    "    prompts = await query.adapt_prompts(\"korean\", llm=generator_llm)\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SingleHopSpecificQuerySynthesizer(name='single_hop_specifc_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
       "  1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
       "  2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
       "  , examples=[(QueryCondition(persona=Persona(name='소프트웨어 엔지니어', role_description='코딩 모범 사례와 시스템 설계에 집중합니다.'), term='마이크로서비스', query_style='정식', query_length='중간', context='마이크로서비스는 애플리케이션이 느슨하게 결합된 서비스 모음으로 구성되는 아키텍처 스타일입니다. 각 서비스는 세분화되어 있으며 단일 기능에 집중합니다.'), GeneratedQueryAnswer(query='소프트웨어 아키텍처에서 마이크로서비스의 목적은 무엇입니까?', answer='마이크로서비스는 애플리케이션을 느슨하게 결합된 서비스 모음으로 구조화하도록 설계되었으며, 각 서비스는 단일 기능에 집중합니다.'))], language=korean), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['공감', '포용성', '원격 근무'], personas=[Persona(name='인사 관리자', role_description='포용성과 직원 지원에 중점을 둡니다.'), Persona(name='원격 팀 리드', role_description='원격 팀 커뮤니케이션을 관리합니다.')]), PersonaThemesMapping(mapping={'HR Manager': ['포용성', '공감'], 'Remote Team Lead': ['원격 근무', '공감']}))], language=korean), property_name='entities'),\n",
       "  0.3333333333333333),\n",
       " (MultiHopAbstractQuerySynthesizer(name='multi_hop_abstract_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "  1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "  2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "  3. **Multi-Hop Context Tags**:\n",
       "     - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "     - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='역사학자', role_description='주요 과학적 이정표와 그들의 글로벌 영향에 초점을 맞춥니다.'), themes=['상대성 이론', '실험적 검증'], query_style='형식적', query_length='중간', context=['<1-hop> 알버트 아인슈타인은 상대성 이론을 개발하여 시공간 개념을 도입했습니다.', '<2-hop> 중력에 의한 빛의 굴절은 1919년 일식 동안 확인되어 아인슈타인의 이론을 지지했습니다.']), GeneratedQueryAnswer(query='1919년 일식 동안 상대성 이론의 실험적 검증은 어떻게 이루어졌나요?', answer='상대성 이론의 실험적 검증은 1919년 일식 동안 중력에 의한 빛의 굴절을 확인함으로써 이루어졌으며, 이는 아인슈타인이 제안한 시공간 개념을 지지했습니다.'))], language=korean), concept_combination_prompt=ConceptCombinationPrompt(instruction=Form combinations by pairing concepts from at least two different lists.\n",
       "  **Instructions:**\n",
       "  - Review the concepts from each node.\n",
       "  - Identify concepts that can logically be connected or contrasted.\n",
       "  - Form combinations that involve concepts from different nodes.\n",
       "  - Each combination should include at least one concept from two or more nodes.\n",
       "  - List the combinations clearly and concisely.\n",
       "  - Do not repeat the same combination more than once., examples=[(ConceptsList(lists_of_concepts=[['인공지능', '자동화'], ['헬스케어', '데이터 프라이버시']], max_combinations=2), ConceptCombinations(combinations=[['인공지능', '헬스케어'], ['자동화', '데이터 프라이버시']]))], language=korean), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['공감', '포용성', '원격 근무'], personas=[Persona(name='인사 관리자', role_description='포용성과 직원 지원에 중점을 둡니다.'), Persona(name='원격 팀 리드', role_description='원격 팀 커뮤니케이션을 관리합니다.')]), PersonaThemesMapping(mapping={'HR Manager': ['포용성', '공감'], 'Remote Team Lead': ['원격 근무', '공감']}))], language=korean)),\n",
       "  0.3333333333333333),\n",
       " (MultiHopSpecificQuerySynthesizer(name='multi_hop_specific_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "  1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "  2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "  3. **Multi-Hop Context Tags**:\n",
       "     - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "     - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='역사학자', role_description='주요 과학적 이정표와 그들의 세계적 영향을 집중적으로 다룹니다.'), themes=['상대성 이론', '실험적 검증'], query_style='형식적', query_length='중간', context=['<1-hop> 알버트 아인슈타인은 상대성 이론을 개발하여 시공간 개념을 도입했습니다.', '<2-hop> 중력에 의한 빛의 굴절은 1919년 일식 동안 확인되어 아인슈타인의 이론을 지지했습니다.']), GeneratedQueryAnswer(query='1919년 일식 동안 상대성 이론의 실험적 검증은 어떻게 이루어졌나요?', answer='상대성 이론의 실험적 검증은 1919년 일식 동안 중력에 의한 빛의 굴절을 확인함으로써 이루어졌으며, 이는 아인슈타인이 제안한 시공간 개념을 지지했습니다.'))], language=korean), relation_type='entities_overlap', property_name='entities', theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['공감', '포용성', '원격 근무'], personas=[Persona(name='인사 관리자', role_description='포용성과 직원 지원에 중점을 둡니다.'), Persona(name='원격 팀 리드', role_description='원격 팀 커뮤니케이션을 관리합니다.')]), PersonaThemesMapping(mapping={'HR Manager': ['포용성', '공감'], 'Remote Team Lead': ['원격 근무', '공감']}))], language=korean)),\n",
       "  0.3333333333333333)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import default_filter, generate_personas_from_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([node for node in load_kg.nodes if default_filter(node)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the provided summary, generate a single persona who would likely interact with or benefit from the content. Include a unique name and a concise role description of who they are.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"role_description\": {\"title\": \"Role Description\", \"type\": \"string\"}}, \"required\": [\"name\", \"role_description\"], \"title\": \"Persona\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"text\": \"Guide to Digital Marketing explains strategies for engaging audiences across various online platforms.\"\n",
      "}\n",
      "Output: {\n",
      "    \"name\": \"Digital Marketing Specialist\",\n",
      "    \"role_description\": \"Focuses on engaging audiences and growing the brand online.\"\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "Input: (None)\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(PersonaGenerationPrompt().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "persona_list=generate_personas_from_kg(\n",
    "    llm = generator_llm,\n",
    "    kg = load_kg,\n",
    "    num_personas=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Persona(name='Real Estate Market Analyst', role_description='Analyzes housing market trends and forecasts impacts of loan regulations and interest rates on buyer demand.'),\n",
       " Persona(name='Real Estate Analyst', role_description='Analyzes housing market trends and provides insights on property investments and market dynamics.'),\n",
       " Persona(name='Real Estate Investment Analyst', role_description='Analyzes market trends and investment opportunities in income-generating real estate, focusing on knowledge industry centers.'),\n",
       " Persona(name='Real Estate Analyst', role_description='Studies market trends and provides insights on housing conditions and policies to inform investment decisions.'),\n",
       " Persona(name='Real Estate Analyst', role_description='Analyzes market trends and forecasts in the real estate sector to inform investment and business decisions.')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios: 100%|██████████| 3/3 [03:00<00:00, 60.25s/it]\n",
      "Generating Samples: 100%|██████████| 32/32 [00:09<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "testset_generator = TestsetGenerator(embedding_model=ragas_embeddings, llm=generator_llm, knowledge_graph=load_kg, persona_list=persona_list)\n",
    "samples = testset_generator.generate(testset_size=30, query_distribution=query_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>송도의 부동산 시장에서 최근의 주요 이슈는 무엇인가요?</td>\n",
       "      <td>[정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 ...</td>\n",
       "      <td>송도에서는 GTX 건설 추진 지연으로 기대감이 감소하고 있으며, 제약·바이오 산업 ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023년 부동산 시장에서 어떤 주요 변화가 있었나요?</td>\n",
       "      <td>[정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 ...</td>\n",
       "      <td>2023년 부동산 시장은 상업용 부동산 거래량이 2022년 대비 11.6% 감소하여...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023년 상업용 부동산 시장의 주요 동향은 무엇인가요?</td>\n",
       "      <td>[정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 ...</td>\n",
       "      <td>2023년 상업용 부동산 시장은 거래량이 2024년에는 11.6% 감소한 4.6만 ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024년 주택시장에 대한 분석 결과는 무엇인가요?</td>\n",
       "      <td>[2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive...</td>\n",
       "      <td>2024년 주택 매매가격은 3분기 이후 상승세를 보였으나 4분기 들어 상승폭이 크게...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>압구정의 주택시장 상황은 어때요?</td>\n",
       "      <td>[2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive...</td>\n",
       "      <td>압구정은 재건축 단지의 사업 진행 상황이 시장에 큰 영향을 미치고 있으며, 서울 2...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024년 주택시장 전망에서 마포구의 주택 매매가격 상승세와 매수세 위축에 대한 분...</td>\n",
       "      <td>[2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive...</td>\n",
       "      <td>2024년 주택시장 진단에 따르면, 마포구는 강북 최고 분양가를 기록하며 상승세가 ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KB부동산 보고서 뭐에요?</td>\n",
       "      <td>[2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ■]</td>\n",
       "      <td>2025 KB부동산 보고서는 2025년 주택시장 진단과 전망에 대한 내용을 담고 있...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025 KB부동산 보고서에서 주택시장에 대한 진단과 전망은 무엇인가요?</td>\n",
       "      <td>[2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ■]</td>\n",
       "      <td>2025 KB부동산 보고서는 2025년 주택시장에 대한 진단과 전망을 다루고 있습니다.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025년 주택시장에 대한 진단과 전망은 무엇인가요?</td>\n",
       "      <td>[2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ■]</td>\n",
       "      <td>2025 KB부동산 보고서에서는 2025년 주택시장에 대한 진단과 전망을 다루고 있...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>정부의 대출 규제 강화가 주택시장에 미치는 영향은 무엇인가요?</td>\n",
       "      <td>[단기적으로 금리 인하보다는 대출 규제 강화가 더 큰 영향 지난해 주택시장에는 금리...</td>\n",
       "      <td>정부의 대출 규제 강화는 주택시장에 직접적인 영향을 미칠 수 있으며, 특히 스트레스...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023년 주택시장에 대한 대출 규제의 영향은 무엇인가요?</td>\n",
       "      <td>[단기적으로 금리 인하보다는 대출 규제 강화가 더 큰 영향 지난해 주택시장에는 금리...</td>\n",
       "      <td>2023년 주택시장에서는 대출 규제가 금리 인하보다 더 큰 영향을 미칠 것으로 전망...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>정부가 2025년 주택시장에 미치는 영향은 무엇인가요?</td>\n",
       "      <td>[단기적으로 금리 인하보다는 대출 규제 강화가 더 큰 영향 지난해 주택시장에는 금리...</td>\n",
       "      <td>정부는 2025년 7월에 스트레스 DSR 적용 범위와 스트레스 금리 적용 비율을 확...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024년 주택시장과 정비 지역의 재건축 사업이 어떻게 상호작용하고 있나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장은 매매가격이 3분기 이후 상승세를 보였으나 4분기 들어 상승폭이...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024년 주택시장과 정비 지역의 재건축 사업 진행 상황은 어떻게 연결되나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장은 매수 대기 수요가 존재하지만, 상승폭이 위축된 상황입니다. 특...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업이 주택 가격에 미치는 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장에서 정비 지역인 광명의 재건축 사업 진행 이후 신축 단지에 대한...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업이 매수 대기 수요에 미치는 영향은 ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업은 매수 대기 수요에 긍정적인 영향을...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025년 주택시장에서 금리 인하가 미치는 영향은 무엇이며, 대출 규제와의 관계는 ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서 기준금리 인하가 호재로 작용할 것임은 분명하지만, 가계부채 ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업 진행이 매매가격에 미치는 영향은 무...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장에서 정비 지역인 광명에서 재건축 사업이 진행됨에 따라 신축 단지...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업이 수요에 미치는 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장에서 정비 지역인 광명의 재건축 사업 진행 이후 신축 단지에 대한...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업이 매수 대기 수요에 어떤 영향을 미...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장에서 정비 지역의 재건축 사업은 매수 대기 수요에 긍정적인 영향을...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025년 주택시장에 대한 금리 인하의 영향은 무엇이며, 대출 규제 강화가 미치는 ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024년 주택시장과 정비 지역의 재건축 사업 진행 상황은 어떻게 연결되며, 이로 ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...</td>\n",
       "      <td>2024년 주택시장은 매수 대기 수요가 존재하지만, 상승폭이 위축된 상황입니다. 특...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025년 주택시장에서 금리 인하와 대출 규제가 미치는 영향은 무엇이며, 이러한 요...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서 금리 인하가 호재로 작용할 것임은 분명하지만, 가계부채 관리...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025년 주택시장에 대한 금리 인하와 대출 규제의 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025년 주택시장에 대한 금리 인하와 대출 규제의 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025년 주택시장에 대한 금리 인하와 대출 규제의 영향은 어떻게 될 것인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025년 주택시장에 대출 규제가 미치는 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...</td>\n",
       "      <td>2025년 주택시장에서는 대출 규제가 금리 인하보다 더 큰 영향을 미칠 것으로 전망...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021년과 2025년의 주택시장 변화에 대한 대출 규제의 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...</td>\n",
       "      <td>2021년 주택시장에는 금리 인하에 대한 기대감과 가계부채 관리를 위한 일련의 조치...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023년 한국의 주택시장과 상업용 부동산 시장의 동향은 어떻게 변화하고 있으며, ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...</td>\n",
       "      <td>2023년 한국의 주택시장은 금리 인하에 대한 기대감과 가계부채 관리를 위한 조치들...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021년과 2023년 사이의 주택시장 변화는 어떤 영향을 받았나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...</td>\n",
       "      <td>2021년에는 상업용 부동산 거래량이 9.6만 건으로 고점을 기록했으나, 2023년...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021년과 2025년의 주택시장 동향은 어떻게 변화할 것으로 예상되며, 금리 인하...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...</td>\n",
       "      <td>2021년에는 상업용 부동산 거래량이 9.6만 건으로 고점을 기록한 이후, 2024...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023년 주택시장에 대한 금리 인하와 대출 규제 강화의 영향은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...</td>\n",
       "      <td>2023년 주택시장에는 금리 인하에 대한 기대감과 가계부채 관리를 위한 일련의 조치...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0                      송도의 부동산 시장에서 최근의 주요 이슈는 무엇인가요?   \n",
       "1                      2023년 부동산 시장에서 어떤 주요 변화가 있었나요?   \n",
       "2                     2023년 상업용 부동산 시장의 주요 동향은 무엇인가요?   \n",
       "3                        2024년 주택시장에 대한 분석 결과는 무엇인가요?   \n",
       "4                                  압구정의 주택시장 상황은 어때요?   \n",
       "5   2024년 주택시장 전망에서 마포구의 주택 매매가격 상승세와 매수세 위축에 대한 분...   \n",
       "6                                      KB부동산 보고서 뭐에요?   \n",
       "7            2025 KB부동산 보고서에서 주택시장에 대한 진단과 전망은 무엇인가요?   \n",
       "8                       2025년 주택시장에 대한 진단과 전망은 무엇인가요?   \n",
       "9                  정부의 대출 규제 강화가 주택시장에 미치는 영향은 무엇인가요?   \n",
       "10                   2023년 주택시장에 대한 대출 규제의 영향은 무엇인가요?   \n",
       "11                     정부가 2025년 주택시장에 미치는 영향은 무엇인가요?   \n",
       "12         2024년 주택시장과 정비 지역의 재건축 사업이 어떻게 상호작용하고 있나요?   \n",
       "13        2024년 주택시장과 정비 지역의 재건축 사업 진행 상황은 어떻게 연결되나요?   \n",
       "14  2024년 주택시장에서 정비 지역의 재건축 사업이 주택 가격에 미치는 영향은 무엇인가요?   \n",
       "15  2024년 주택시장에서 정비 지역의 재건축 사업이 매수 대기 수요에 미치는 영향은 ...   \n",
       "16  2025년 주택시장에서 금리 인하가 미치는 영향은 무엇이며, 대출 규제와의 관계는 ...   \n",
       "17  2024년 주택시장에서 정비 지역의 재건축 사업 진행이 매매가격에 미치는 영향은 무...   \n",
       "18     2024년 주택시장에서 정비 지역의 재건축 사업이 수요에 미치는 영향은 무엇인가요?   \n",
       "19  2024년 주택시장에서 정비 지역의 재건축 사업이 매수 대기 수요에 어떤 영향을 미...   \n",
       "20  2025년 주택시장에 대한 금리 인하의 영향은 무엇이며, 대출 규제 강화가 미치는 ...   \n",
       "21  2024년 주택시장과 정비 지역의 재건축 사업 진행 상황은 어떻게 연결되며, 이로 ...   \n",
       "22  2025년 주택시장에서 금리 인하와 대출 규제가 미치는 영향은 무엇이며, 이러한 요...   \n",
       "23            2025년 주택시장에 대한 금리 인하와 대출 규제의 영향은 무엇인가요?   \n",
       "24            2025년 주택시장에 대한 금리 인하와 대출 규제의 영향은 무엇인가요?   \n",
       "25       2025년 주택시장에 대한 금리 인하와 대출 규제의 영향은 어떻게 될 것인가요?   \n",
       "26                  2025년 주택시장에 대출 규제가 미치는 영향은 무엇인가요?   \n",
       "27        2021년과 2025년의 주택시장 변화에 대한 대출 규제의 영향은 무엇인가요?   \n",
       "28  2023년 한국의 주택시장과 상업용 부동산 시장의 동향은 어떻게 변화하고 있으며, ...   \n",
       "29             2021년과 2023년 사이의 주택시장 변화는 어떤 영향을 받았나요?   \n",
       "30  2021년과 2025년의 주택시장 동향은 어떻게 변화할 것으로 예상되며, 금리 인하...   \n",
       "31         2023년 주택시장에 대한 금리 인하와 대출 규제 강화의 영향은 무엇인가요?   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 ...   \n",
       "1   [정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 ...   \n",
       "2   [정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 ...   \n",
       "3   [2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive...   \n",
       "4   [2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive...   \n",
       "5   [2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive...   \n",
       "6               [2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ■]   \n",
       "7               [2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ■]   \n",
       "8               [2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ■]   \n",
       "9   [단기적으로 금리 인하보다는 대출 규제 강화가 더 큰 영향 지난해 주택시장에는 금리...   \n",
       "10  [단기적으로 금리 인하보다는 대출 규제 강화가 더 큰 영향 지난해 주택시장에는 금리...   \n",
       "11  [단기적으로 금리 인하보다는 대출 규제 강화가 더 큰 영향 지난해 주택시장에는 금리...   \n",
       "12  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "13  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "14  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "15  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "16  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "17  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "18  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "19  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "20  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "21  [<1-hop>\\n\\n2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망...   \n",
       "22  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "23  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "24  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "25  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "26  [<1-hop>\\n\\n2025 KB부동산 보고서: 2025년 주택시장 진단과 전망 ...   \n",
       "27  [<1-hop>\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...   \n",
       "28  [<1-hop>\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...   \n",
       "29  [<1-hop>\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...   \n",
       "30  [<1-hop>\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...   \n",
       "31  [<1-hop>\\n\\n정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   송도에서는 GTX 건설 추진 지연으로 기대감이 감소하고 있으며, 제약·바이오 산업 ...   \n",
       "1   2023년 부동산 시장은 상업용 부동산 거래량이 2022년 대비 11.6% 감소하여...   \n",
       "2   2023년 상업용 부동산 시장은 거래량이 2024년에는 11.6% 감소한 4.6만 ...   \n",
       "3   2024년 주택 매매가격은 3분기 이후 상승세를 보였으나 4분기 들어 상승폭이 크게...   \n",
       "4   압구정은 재건축 단지의 사업 진행 상황이 시장에 큰 영향을 미치고 있으며, 서울 2...   \n",
       "5   2024년 주택시장 진단에 따르면, 마포구는 강북 최고 분양가를 기록하며 상승세가 ...   \n",
       "6   2025 KB부동산 보고서는 2025년 주택시장 진단과 전망에 대한 내용을 담고 있...   \n",
       "7    2025 KB부동산 보고서는 2025년 주택시장에 대한 진단과 전망을 다루고 있습니다.   \n",
       "8   2025 KB부동산 보고서에서는 2025년 주택시장에 대한 진단과 전망을 다루고 있...   \n",
       "9   정부의 대출 규제 강화는 주택시장에 직접적인 영향을 미칠 수 있으며, 특히 스트레스...   \n",
       "10  2023년 주택시장에서는 대출 규제가 금리 인하보다 더 큰 영향을 미칠 것으로 전망...   \n",
       "11  정부는 2025년 7월에 스트레스 DSR 적용 범위와 스트레스 금리 적용 비율을 확...   \n",
       "12  2024년 주택시장은 매매가격이 3분기 이후 상승세를 보였으나 4분기 들어 상승폭이...   \n",
       "13  2024년 주택시장은 매수 대기 수요가 존재하지만, 상승폭이 위축된 상황입니다. 특...   \n",
       "14  2024년 주택시장에서 정비 지역인 광명의 재건축 사업 진행 이후 신축 단지에 대한...   \n",
       "15  2024년 주택시장에서 정비 지역의 재건축 사업은 매수 대기 수요에 긍정적인 영향을...   \n",
       "16  2025년 주택시장에서 기준금리 인하가 호재로 작용할 것임은 분명하지만, 가계부채 ...   \n",
       "17  2024년 주택시장에서 정비 지역인 광명에서 재건축 사업이 진행됨에 따라 신축 단지...   \n",
       "18  2024년 주택시장에서 정비 지역인 광명의 재건축 사업 진행 이후 신축 단지에 대한...   \n",
       "19  2024년 주택시장에서 정비 지역의 재건축 사업은 매수 대기 수요에 긍정적인 영향을...   \n",
       "20  2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...   \n",
       "21  2024년 주택시장은 매수 대기 수요가 존재하지만, 상승폭이 위축된 상황입니다. 특...   \n",
       "22  2025년 주택시장에서 금리 인하가 호재로 작용할 것임은 분명하지만, 가계부채 관리...   \n",
       "23  2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...   \n",
       "24  2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...   \n",
       "25  2025년 주택시장에서는 기준금리 인하가 호재로 작용할 것으로 예상되지만, 가계부채...   \n",
       "26  2025년 주택시장에서는 대출 규제가 금리 인하보다 더 큰 영향을 미칠 것으로 전망...   \n",
       "27  2021년 주택시장에는 금리 인하에 대한 기대감과 가계부채 관리를 위한 일련의 조치...   \n",
       "28  2023년 한국의 주택시장은 금리 인하에 대한 기대감과 가계부채 관리를 위한 조치들...   \n",
       "29  2021년에는 상업용 부동산 거래량이 9.6만 건으로 고점을 기록했으나, 2023년...   \n",
       "30  2021년에는 상업용 부동산 거래량이 9.6만 건으로 고점을 기록한 이후, 2024...   \n",
       "31  2023년 주택시장에는 금리 인하에 대한 기대감과 가계부채 관리를 위한 일련의 조치...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   single_hop_specifc_query_synthesizer  \n",
       "6   single_hop_specifc_query_synthesizer  \n",
       "7   single_hop_specifc_query_synthesizer  \n",
       "8   single_hop_specifc_query_synthesizer  \n",
       "9   single_hop_specifc_query_synthesizer  \n",
       "10  single_hop_specifc_query_synthesizer  \n",
       "11  single_hop_specifc_query_synthesizer  \n",
       "12  multi_hop_abstract_query_synthesizer  \n",
       "13  multi_hop_abstract_query_synthesizer  \n",
       "14  multi_hop_abstract_query_synthesizer  \n",
       "15  multi_hop_abstract_query_synthesizer  \n",
       "16  multi_hop_abstract_query_synthesizer  \n",
       "17  multi_hop_abstract_query_synthesizer  \n",
       "18  multi_hop_abstract_query_synthesizer  \n",
       "19  multi_hop_abstract_query_synthesizer  \n",
       "20  multi_hop_abstract_query_synthesizer  \n",
       "21  multi_hop_abstract_query_synthesizer  \n",
       "22  multi_hop_specific_query_synthesizer  \n",
       "23  multi_hop_specific_query_synthesizer  \n",
       "24  multi_hop_specific_query_synthesizer  \n",
       "25  multi_hop_specific_query_synthesizer  \n",
       "26  multi_hop_specific_query_synthesizer  \n",
       "27  multi_hop_specific_query_synthesizer  \n",
       "28  multi_hop_specific_query_synthesizer  \n",
       "29  multi_hop_specific_query_synthesizer  \n",
       "30  multi_hop_specific_query_synthesizer  \n",
       "31  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = samples.to_pandas()\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트셋 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class QA_check(BaseModel):\n",
    "    validity: bool\n",
    "    reference_context_relevance: bool\n",
    "    qa_appropriateness:bool \n",
    "    \n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=QA_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "다음 질문과 답변이 주어진 논문을 기준으로 적절한지 평가하십시오.\n",
    "\n",
    "다음 항목을 순차적으로 평가해 주세요:\n",
    "\n",
    "1. 질문의 적절성 (Validity)\n",
    "- 질문이 논문에 언급된 용어, 표현, 개념에 대해 논문에서 제공하는 정보를 바탕으로 답할 수 있도록 명확히 구성되었나요?\n",
    "- 논문에서 인용된 사람의 이름 또는 특정 저자명을 단순 인용 표기(예: (홍길동, 2024))임에도 불구하고 단어나 개념처럼 잘못 해석하여 그 의미를 묻는 질문은 부적절합니다.\n",
    "(예: 논문 인용 표기에서 \"(홍길동, 2024)\"와 같은 저자 이름을 하나의 개념이나 용어로 잘못 파악하고 질문하는 경우는 잘못된 질문임.)\n",
    "\n",
    "2. 참조 문맥의 관련성 (Reference Context Relevance)\n",
    "- 제공된 참조 문맥이 질문과 답변에 관련 있으며, 논문의 실제 내용과 정확히 일치하는가요?\n",
    "\n",
    "3. 답변의 적합성 (QA Appropriateness)\n",
    "- 제공된 답변이 논문에서 실제로 제시된 정보를 근거로 질문에 적절히 대응하는가요?\n",
    "\n",
    "# 질문\n",
    "{user_input}\n",
    "\n",
    "# 답변\n",
    "{reference}\n",
    "\n",
    "# 참조 문맥\n",
    "{reference_contexts}\n",
    "\n",
    "# 포맷\n",
    "```json\n",
    "{{\"validity\": true or false, \"reference_context_relevance\": true or false, \"qa_appropriateness\": true or false}}\n",
    "```\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough()|PromptTemplate(template=prompt, input_variables=[\"user_input\", \"reference\", \"reference_contexts\"])|llm_gemini|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': '2024년 주택시장 전망에서 마포구의 주택 매매가격 상승세와 매수세 위축에 대한 분석은 무엇입니까?',\n",
       " 'reference_contexts': ['2024 KB 부동산 보고서: 2024년 주택시장 진단과 전망 Ex ecutive Summary 3 \\uf06e 현장에서 바라본 주택시장 2024년 주택 매매가격은 3분기 이후 상승세를 보였으나 4분기 들어 상승폭이 크게 위축되었다. 그러나 매수 대기 수요가 존재하여 수요자가 선호하는 지역이나 주요 이슈가 존재하는 지역에 대한 관심은 여전히 큰 것으로 나타났다. KB금융지주 경영연구소는 수요가 높은 수도권 15개 지역을 5개 구역으로 구분해 지역별 주택시장을 점검해 보았다. 구분 지역 주요 이슈 강남구 서울 25개 자치구 중 가장 높은 상승률 기록. 압구정 재건축 단지의 사업 진행 상황이 시장에 큰 영향 서울 한강 서초구 분양시장 중심으로 주택가격 크게 상승. 매수세는 둔화되었으나 여전히 매도자 우위 시장이 형성 이남 송파구 재건축 사업이 탄력을 받으며 시장 관심 증가. 토지거래허가구역 해제 이후 시장 내 기대감 상승 서울 마포구 강북 최고 분양가를 기록하는 등 상승세가 지속되었으나 매수세는 다소 위축 한강 용산구 한남 뉴타운 및 용산국제업무지구 개발 사업 진행에 따른 긍정적 기대감 지속 이북 성동구 실수요자 중심 시장으로 대출 규제 이후 관망세. 성수전략정비구역 심의 통과는 긍정적 요인 서울 대치동 학군지에 대한 꾸준한 수요와 재건축 단지에 대한 관심 지속 주요 목동 목동 14개 단지 중 6개 단지가 정비구역으로 지정되면서 재건축 진행 속도가 주요 변수로 등장 학군 지역 중계동 노원구 주택시장 침체에도 상대적으로 양호한 흐름. 매수자는 대출 규제 완화 등 여건 개선 기대 수도권 분당 선도지구 선정 이후 보합세 지속. 향후 사업 추진 상황이 중요한 요인으로 작용 주요 과천 2024년 전국에서 가장 높은 상승률 기록. 기존 과천 도심에 대한 수요는 여전 정비 지역 광명 재건축 사업 진행 이후 신축 단지에 관심 집중. 수요가 감소하는 상황에서 분양가 상승이 변수 수도권 위례 위례선 트램, 위례신사선 등 교통 관련 사업 진행 상황이 시장의 주요 관심사 교통 이슈 동탄 GTX 개통 이후 접근성, 비용 문제 등이 부각. 추가적인 교통 개발과 반도체 등 산업 수요는 증가 지역 송도 GTX 건설 추진 지연으로 기대감 감소. 제약·바이오 산업 유입에 따른 수요 증가는 긍정적 요인 \\uf06e  주요 이슈가 존재하는 지역에 대한 관심은 여전히 큰 것으로 나타났다. KB금융지주 경영연구소는 수요가 높은 수도권 15개 지역을 5개 구역으로 구분해 지역별 주택시장을 점검해 보았다. 구분 지역 주요 이슈 강남구 서울 25개 자치구 중 가장 높은 상승률 기록. 압구정 재건축 단지의 사업 진행 상황이 시장에 큰 영향 서울 한강 서초구 분양시장 중심으로 주택가격 크게 상승. 매수세는 둔화되었으나 여전히 매도자 우위 시장이 형성 이남 송파구 재건축 사업이 탄력을 받으며 시장 관심 증가. 토지거래허가구역 해제 이후 시장 내 기대감 상승 서울 마포구 강북 최고 분양가를 기록하는 등 상승세가 지속되었으나 매수세는 다소 위축 한강 용산구 한남 뉴타운 및 용산국제업무지구 개발 사업 진행에 따른 긍정적 기대감 지속 이북 성동구 실수요자 중심 시장으로 대출 규제 이후 관망세. 성수전략정비구역 심의 통과는 긍정적 요인 서울 대치동 학군지에 대한 꾸준한 수요와 재건축 단지에 대한 관심 지속 주요 목동 목동 14개 단지 중 6개 단지가 정비구역으로 지정되면서 재건축 진행 속도가 주요 변수로 등장 학군 지역 중계동 노원구 주택시장 침체에도 상대적으로 양호한 흐름. 매수자는 대출 규제 완화 등 여건 개선 기대 수도권 분당 선도지구 선정 이후 보합세 지속. 향후 사업 추진 상황이 중요한 요인으로 작용 주요 과천 2024년 전국에서 가장 높은 상승률 기록. 기존 과천 도심에 대한 수요는 여전'],\n",
       " 'reference': '2024년 주택시장 진단에 따르면, 마포구는 강북 최고 분양가를 기록하며 상승세가 지속되었으나, 매수세는 다소 위축된 것으로 나타났습니다. 이는 수요가 여전히 존재하지만, 매수자들이 시장에 대한 신중한 접근을 하고 있음을 시사합니다.'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sample = sample_df.loc[5,:\"reference\"]\n",
    "check_sample.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_check = chain.invoke(check_sample.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QA_check(validity=True, reference_context_relevance=True, qa_appropriateness=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 1min...\n",
      "0 10\n",
      "Waiting 1min...\n",
      "10 20\n",
      "Waiting 1min...\n",
      "20 30\n",
      "Waiting 1min...\n",
      "30 40\n"
     ]
    }
   ],
   "source": [
    "ans_total = []\n",
    "for sample_start in range(0,sample_df.shape[0],10):\n",
    "    print(\"Waiting 1min...\")\n",
    "    time.sleep(60.0)\n",
    "    print(sample_start, sample_start+10)\n",
    "    ans = chain.batch(list(sample_df.loc[sample_start:sample_start+10,:\"reference\"].T.to_dict().values()))\n",
    "    ans_total.extend(ans)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "final_data0 = pd.concat([sample_df,pd.DataFrame([i.model_dump() for i in ans_total])], axis=1).dropna()\n",
    "print(final_data0.query(\"~validity|~reference_context_relevance|~qa_appropriateness\").shape[0])\n",
    "final_data = final_data0.query(\"validity&reference_context_relevance&qa_appropriateness\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 233.59ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/copycatQ/ragas_practice_dataset/commit/68e04af2eb7db359886b12262ae93fe7d606d596', commit_message='Upload dataset', commit_description='', oid='68e04af2eb7db359886b12262ae93fe7d606d596', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/copycatQ/ragas_practice_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='copycatQ/ragas_practice_dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "# pandas DataFrame을 Hugging Face Dataset으로 변환\n",
    "dataset = Dataset.from_pandas(final_data)\n",
    "\n",
    "# 데이터셋 이름 설정 (원하는 이름으로 변경하세요)\n",
    "dataset_name = \"copycatQ/ragas_practice_dataset\"\n",
    "\n",
    "# 데이터셋 업로드\n",
    "dataset.push_to_hub(\n",
    "    dataset_name,\n",
    "    private=True,  # private=False로 설정하면 공개 데이터셋이 됩니다.\n",
    "    split=\"korean_estate\",  # 데이터셋 split 이름 입력\n",
    "    token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시나리오 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "query_distribution = default_query_distribution(generator_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigle Hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_nodes = query_distribution[0][0].get_node_clusters(loaded_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플사이즈를 고려해 각 노드에서 생성할 쿼리의 수를 계산\n",
    "int(np.ceil(10 / len(query_distribution[0][0].get_node_clusters(loaded_kg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.prompts import ThemesPersonasMatchingPrompt, ThemesPersonasInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Foundation Model',\n",
       " 'LLM',\n",
       " 'Unsupervised learning',\n",
       " 'Supervised learning',\n",
       " 'Self-Supervised Learning',\n",
       " 'Semi-Supervised Learning',\n",
       " 'Wikipidia',\n",
       " 'Chowdhery et al.',\n",
       " 'Nijkamp et al.',\n",
       " 'Zhao et al.']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_nodes[0].get_property(\"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_input = ThemesPersonasInput(themes=filtered_nodes[0].get_property(\"entities\"), personas=persona_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThemesPersonasInput(themes=['Foundation Model', 'LLM', 'Unsupervised learning', 'Supervised learning', 'Self-Supervised Learning', 'Semi-Supervised Learning', 'Wikipidia', 'Chowdhery et al.', 'Nijkamp et al.', 'Zhao et al.'], personas=[Persona(name='Financial Technology Analyst', role_description='Analyzes the application of large language models in the finance sector, focusing on customer service automation and AI-driven solutions.'), Persona(name='AI Product Manager', role_description='Oversees the development of AI products, ensuring they leverage the latest advancements in language models and remain competitive in the market.'), Persona(name='AI Solutions Architect', role_description='Designs and implements AI models and solutions, focusing on performance and customer satisfaction.'), Persona(name='AI Research Scientist', role_description='Engages in research and development of foundation models, focusing on advancements in language processing and multi-modal learning.'), Persona(name='AI Research Engineer', role_description='Specializes in improving language models through fine-tuning and exploring efficient methods for domain-specific adaptations.'), Persona(name='AI Model Optimization Engineer', role_description=\"Specializes in enhancing large language models' performance through techniques like fine-tuning and data management.\"), Persona(name='Financial Data Scientist', role_description='Specializes in developing and optimizing LLMs tailored for the finance sector, focusing on data preprocessing and model tuning.'), Persona(name='Financial Data Analyst', role_description='Gathers and analyzes financial datasets to derive insights and support investment decisions.'), Persona(name='Financial Data Analyst', role_description='Specializes in analyzing financial news sentiment and optimizing product recommendations through tailored LLM models.'), Persona(name='Financial Data Scientist', role_description='Specializes in applying natural language processing techniques to analyze sentiment in financial news and optimize machine learning models for effective predictions.'), Persona(name='Machine Learning Engineer', role_description='Specializes in optimizing model performance through fine-tuning and careful selection of hyperparameters and training environments.'), Persona(name='Financial Data Scientist', role_description='Specializes in developing and fine-tuning algorithms for analyzing financial data while ensuring compliance with privacy and security regulations.'), Persona(name='Financial AI Specialist', role_description='Focuses on fine-tuning large language models for financial applications, evaluating model performance, and utilizing MLOps tools for efficient development and deployment.'), Persona(name='Financial Data Analyst', role_description='Specializes in evaluating and interpreting financial models to ensure high accuracy in predictions and reporting.'), Persona(name='Machine Learning Engineer', role_description='Responsible for optimizing and training models, specifically in the insurance domain, to ensure high-quality performance with user queries.'), Persona(name='Financial Technology Analyst', role_description='Specializes in integrating AI solutions to enhance operational efficiency in the finance sector.'), Persona(name='Financial Data Analyst', role_description='Specializes in analyzing financial data to improve prediction accuracy and customer service through advanced machine learning models.'), Persona(name='Insurance Technology Analyst', role_description='Researches and analyzes the application of AI innovations in the insurance industry to enhance customer experiences and optimize business processes.'), Persona(name='AI Research Analyst', role_description='Studies advancements in AI and evaluates the impact of large language models on various industries.'), Persona(name='Financial Data Scientist', role_description='Specializes in leveraging domain-specific language models to enhance applications of natural language processing in the financial sector.')])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"mapping\": {\"additionalProperties\": {\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"title\": \"Mapping\", \"type\": \"object\"}}, \"required\": [\"mapping\"], \"title\": \"PersonaThemesMapping\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"themes\": [\n",
      "        \"Empathy\",\n",
      "        \"Inclusivity\",\n",
      "        \"Remote work\"\n",
      "    ],\n",
      "    \"personas\": [\n",
      "        {\n",
      "            \"name\": \"HR Manager\",\n",
      "            \"role_description\": \"Focuses on inclusivity and employee support.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Remote Team Lead\",\n",
      "            \"role_description\": \"Manages remote team communication.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Output: {\n",
      "    \"mapping\": {\n",
      "        \"HR Manager\": [\n",
      "            \"Inclusivity\",\n",
      "            \"Empathy\"\n",
      "        ],\n",
      "        \"Remote Team Lead\": [\n",
      "            \"Remote work\",\n",
      "            \"Empathy\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "input: {\n",
      "    \"themes\": [\n",
      "        \"Foundation Model\",\n",
      "        \"LLM\",\n",
      "        \"Unsupervised learning\",\n",
      "        \"Supervised learning\",\n",
      "        \"Self-Supervised Learning\",\n",
      "        \"Semi-Supervised Learning\",\n",
      "        \"Wikipidia\",\n",
      "        \"Chowdhery et al.\",\n",
      "        \"Nijkamp et al.\",\n",
      "        \"Zhao et al.\"\n",
      "    ],\n",
      "    \"personas\": [\n",
      "        {\n",
      "            \"name\": \"Financial Technology Analyst\",\n",
      "            \"role_description\": \"Analyzes the application of large language models in the finance sector, focusing on customer service automation and AI-driven solutions.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"AI Product Manager\",\n",
      "            \"role_description\": \"Oversees the development of AI products, ensuring they leverage the latest advancements in language models and remain competitive in the market.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"AI Solutions Architect\",\n",
      "            \"role_description\": \"Designs and implements AI models and solutions, focusing on performance and customer satisfaction.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"AI Research Scientist\",\n",
      "            \"role_description\": \"Engages in research and development of foundation models, focusing on advancements in language processing and multi-modal learning.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"AI Research Engineer\",\n",
      "            \"role_description\": \"Specializes in improving language models through fine-tuning and exploring efficient methods for domain-specific adaptations.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"AI Model Optimization Engineer\",\n",
      "            \"role_description\": \"Specializes in enhancing large language models' performance through techniques like fine-tuning and data management.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Scientist\",\n",
      "            \"role_description\": \"Specializes in developing and optimizing LLMs tailored for the finance sector, focusing on data preprocessing and model tuning.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Analyst\",\n",
      "            \"role_description\": \"Gathers and analyzes financial datasets to derive insights and support investment decisions.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Analyst\",\n",
      "            \"role_description\": \"Specializes in analyzing financial news sentiment and optimizing product recommendations through tailored LLM models.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Scientist\",\n",
      "            \"role_description\": \"Specializes in applying natural language processing techniques to analyze sentiment in financial news and optimize machine learning models for effective predictions.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Machine Learning Engineer\",\n",
      "            \"role_description\": \"Specializes in optimizing model performance through fine-tuning and careful selection of hyperparameters and training environments.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Scientist\",\n",
      "            \"role_description\": \"Specializes in developing and fine-tuning algorithms for analyzing financial data while ensuring compliance with privacy and security regulations.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial AI Specialist\",\n",
      "            \"role_description\": \"Focuses on fine-tuning large language models for financial applications, evaluating model performance, and utilizing MLOps tools for efficient development and deployment.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Analyst\",\n",
      "            \"role_description\": \"Specializes in evaluating and interpreting financial models to ensure high accuracy in predictions and reporting.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Machine Learning Engineer\",\n",
      "            \"role_description\": \"Responsible for optimizing and training models, specifically in the insurance domain, to ensure high-quality performance with user queries.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Technology Analyst\",\n",
      "            \"role_description\": \"Specializes in integrating AI solutions to enhance operational efficiency in the finance sector.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Analyst\",\n",
      "            \"role_description\": \"Specializes in analyzing financial data to improve prediction accuracy and customer service through advanced machine learning models.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Insurance Technology Analyst\",\n",
      "            \"role_description\": \"Researches and analyzes the application of AI innovations in the insurance industry to enhance customer experiences and optimize business processes.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"AI Research Analyst\",\n",
      "            \"role_description\": \"Studies advancements in AI and evaluates the impact of large language models on various industries.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Financial Data Scientist\",\n",
      "            \"role_description\": \"Specializes in leveraging domain-specific language models to enhance applications of natural language processing in the financial sector.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(ThemesPersonasMatchingPrompt().to_string(data=persona_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_concepts = await ThemesPersonasMatchingPrompt().generate(data=persona_input, llm=generator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Financial Technology Analyst': ['LLM',\n",
       "  'Foundation Model',\n",
       "  'Supervised learning'],\n",
       " 'AI Product Manager': ['Foundation Model', 'LLM'],\n",
       " 'AI Solutions Architect': ['Foundation Model', 'LLM'],\n",
       " 'AI Research Scientist': ['Foundation Model',\n",
       "  'Unsupervised learning',\n",
       "  'Self-Supervised Learning'],\n",
       " 'AI Research Engineer': ['LLM',\n",
       "  'Supervised learning',\n",
       "  'Self-Supervised Learning'],\n",
       " 'AI Model Optimization Engineer': ['LLM', 'Supervised learning'],\n",
       " 'Financial Data Scientist': ['LLM', 'Foundation Model'],\n",
       " 'Financial Data Analyst': ['LLM', 'Supervised learning'],\n",
       " 'Machine Learning Engineer': ['LLM', 'Supervised learning'],\n",
       " 'Financial AI Specialist': ['LLM', 'Supervised learning'],\n",
       " 'Insurance Technology Analyst': ['LLM', 'Foundation Model'],\n",
       " 'AI Research Analyst': ['Foundation Model', 'LLM']}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persona_concepts.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_scenarios  = query_distribution[0][0].prepare_combinations(\n",
    "                filtered_nodes[0],\n",
    "                filtered_nodes[0].get_property(\"entities\"),\n",
    "                personas=persona_list,\n",
    "                persona_concepts=persona_concepts.mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SingleHopScenario(\n",
       " nodes=1\n",
       " term=Supervised learning\n",
       " persona=name='AI Solutions Architect' role_description='Designs and implements AI models and solutions, focusing on performance and customer satisfaction.'\n",
       " style=QueryStyle.PERFECT_GRAMMAR\n",
       " length=QueryLength.SHORT)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_sample_list = query_distribution[0][0].sample_combinations(base_scenarios,1)\n",
    "scenario_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_distribution[0][0].generate_sample(scenario=scenario_sample_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(id: 421d36, type: NodeType.CHUNK, properties: ['page_content', 'entities', 'themes'])]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_sample_list[0].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description.\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"mapping\": {\"additionalProperties\": {\"items\": {\"type\": \"string\"}, \"type\": \"array\"}, \"title\": \"Mapping\", \"type\": \"object\"}}, \"required\": [\"mapping\"], \"title\": \"PersonaThemesMapping\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"themes\": [\n",
      "        \"Empathy\",\n",
      "        \"Inclusivity\",\n",
      "        \"Remote work\"\n",
      "    ],\n",
      "    \"personas\": [\n",
      "        {\n",
      "            \"name\": \"HR Manager\",\n",
      "            \"role_description\": \"Focuses on inclusivity and employee support.\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Remote Team Lead\",\n",
      "            \"role_description\": \"Manages remote team communication.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Output: {\n",
      "    \"mapping\": {\n",
      "        \"HR Manager\": [\n",
      "            \"Inclusivity\",\n",
      "            \"Empathy\"\n",
      "        ],\n",
      "        \"Remote Team Lead\": [\n",
      "            \"Remote work\",\n",
      "            \"Empathy\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "Input: (None)\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(ThemesPersonasMatchingPrompt().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SingleHopSpecificQuerySynthesizer(name='single_hop_specifc_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
       "  1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
       "  2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
       "  , examples=[(QueryCondition(persona=Persona(name='Software Engineer', role_description='Focuses on coding best practices and system design.'), term='microservices', query_style='Formal', query_length='Medium', context='Microservices are an architectural style where applications are structured as a collection of loosely coupled services. Each service is fine-grained and focuses on a single functionality.'), GeneratedQueryAnswer(query='What is the purpose of microservices in software architecture?', answer='Microservices are designed to structure applications as a collection of loosely coupled services, each focusing on a single functionality.'))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english), property_name='entities'),\n",
       "  0.3333333333333333),\n",
       " (MultiHopAbstractQuerySynthesizer(name='multi_hop_abstract_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "  1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "  2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "  3. **Multi-Hop Context Tags**:\n",
       "     - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "     - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), concept_combination_prompt=ConceptCombinationPrompt(instruction=Form combinations by pairing concepts from at least two different lists.\n",
       "  **Instructions:**\n",
       "  - Review the concepts from each node.\n",
       "  - Identify concepts that can logically be connected or contrasted.\n",
       "  - Form combinations that involve concepts from different nodes.\n",
       "  - Each combination should include at least one concept from two or more nodes.\n",
       "  - List the combinations clearly and concisely.\n",
       "  - Do not repeat the same combination more than once., examples=[(ConceptsList(lists_of_concepts=[['Artificial intelligence', 'Automation'], ['Healthcare', 'Data privacy']], max_combinations=2), ConceptCombinations(combinations=[['Artificial intelligence', 'Healthcare'], ['Automation', 'Data privacy']]))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)),\n",
       "  0.3333333333333333),\n",
       " (MultiHopSpecificQuerySynthesizer(name='multi_hop_specific_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "  1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "  2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "  3. **Multi-Hop Context Tags**:\n",
       "     - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "     - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), relation_type='entities_overlap', property_name='entities', theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)),\n",
       "  0.3333333333333333)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "from ragas.testset.synthesizers.single_hop.prompts import QueryAnswerGenerationPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
      "1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
      "2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
      "\n",
      "Please return the output in a JSON format that complies with the following schema as specified in JSON Schema:\n",
      "{\"properties\": {\"query\": {\"title\": \"Query\", \"type\": \"string\"}, \"answer\": {\"title\": \"Answer\", \"type\": \"string\"}}, \"required\": [\"query\", \"answer\"], \"title\": \"GeneratedQueryAnswer\", \"type\": \"object\"}Do not use single quotes in your response but double quotes,properly escaped with a backslash.\n",
      "\n",
      "--------EXAMPLES-----------\n",
      "Example 1\n",
      "Input: {\n",
      "    \"persona\": {\n",
      "        \"name\": \"Software Engineer\",\n",
      "        \"role_description\": \"Focuses on coding best practices and system design.\"\n",
      "    },\n",
      "    \"term\": \"microservices\",\n",
      "    \"query_style\": \"Formal\",\n",
      "    \"query_length\": \"Medium\",\n",
      "    \"context\": \"Microservices are an architectural style where applications are structured as a collection of loosely coupled services. Each service is fine-grained and focuses on a single functionality.\"\n",
      "}\n",
      "Output: {\n",
      "    \"query\": \"What is the purpose of microservices in software architecture?\",\n",
      "    \"answer\": \"Microservices are designed to structure applications as a collection of loosely coupled services, each focusing on a single functionality.\"\n",
      "}\n",
      "-----------------------------\n",
      "\n",
      "Now perform the same with the following input\n",
      "Input: (None)\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "print(QueryAnswerGenerationPrompt().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = await query_distribution[0][0].generate_sample(scenario=scenario_sample_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How is supervised learning utilized in the training of foundation models?'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supervised learning is used in the training of foundation models by learning from pre-processed text data.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2. 파운데이션 모델(Foundation Model) 및 첫 번째 작업은 LLM이 학습될 리소스인 학습 데 LLM 사전학습(Pre-training) 이터 세트를 수집하는 것이다. 데이터는 책, 웹 생성형 AI 모델은 어떤 출력을 생성하는가에 사이트, 기사, 공개 데이터세트 등 다양한 소스에서 따라서 언어모델, 이미지 모델, 동영상 모델 등 가져올 수 있다. 유능한 LLM을 개발하기 위해 을 사용한다. 하지만 현재는 이미지와 텍스트를 사전 학습된 자료로 텍스트 데이터 세트를 사용 동시에 학습하는 멀티모달(Multi-modal) 모델들이 한다. 사전 학습된 코퍼스의 소스는 크게 일반 데이 하루가 다르게 성능과 기능이 업그레이드고 있고 터와 전문 데이터의 두 가지 유형으로 분류할 수 있으며 기초모델로 자리잡아가고 있다(정천수, 있으며 웹 페이지, 서적 및 대화 텍스트와 같은 2023d). 파운데이션 모델(Foundation Model)의 데 일반 데이터는 크고 다양하며 접근 가능한 특성 이터는 텍스트, 이미지, 음성, 정형데이터, 3D 시 으로 인해 대부분의 LLM에서 활용되며 LLM의 그널 등 구분하지 않고 학습에 이용되며 인간의 언어 모델링 및 일반화 능력을 향상시킬 수 있다. 창의력과 추론력을 포함한 일을 수행하며 이러한 또한 다국어 데이터, 과학 데이터 및 코드와 같은 기초모델은 방대한 양의 데이터를 비지도 학습 보다 전문화된 데이터 세트로 확장하여 LLM에 (Unsupervised learning)을 통해 모델을 학습시킨 특정 작업 해결 기능을 부여하는 연구도 발표되고 후 배포되어 사용자가 원하는 목적에 맞게 다운 있다(Chowdhery et al., 2023; Nijkamp et al., 2022). 스트림 작업에 대해 파인튜닝이나 문맥 내 학습 <그림 3>은 일반적인 LLM의 데이터 수집 및 (In-context learning)등과 같은 과정을 거처 완성 사전학습 절차를 보여주고 있다(Zhao et al., 2023). 되는 것이 파운데이션 모델이라고 볼 수 있다 모델 학습은 지도 학습(Supervised learning)을 사용 (Bommasani, et. al., 2021). 하여 전 처리된 텍스트 데이터에 대해 학습된다. 파운데이션 모델 중에서 언어모델로서의 LLM은 또한 모델과 데이터의 크기가 크기 때문에 모델을 일반 Text 데이터인 Wikipidia 등 거대한 일반적인 학습하려면 엄청난 계산 능력이 필요하며 학습 지식들을 수집하여 자기지도학습(Self-Supervised 시간을 줄이기 위해 모델 병렬화라는 기술이 사 Learning)이나 반자기지도학습(Semi-Supervised 용된다. 이렇게 대규모 언어 모델을 처음부터 학 Learning)을 사용하여 레이블링되지 않은 상당한 습하려면 상당한 투자가 필요하기 때문에 보다 양의 텍스트로 사전 학습된 언어 모델(Pre-trained 경제적인 대안으로 기존 언어 모델을 특정 사용 Language Model, PLM)이다.\n"
     ]
    }
   ],
   "source": [
    "print(sample.reference_contexts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0),\n",
    "]\n",
    "\n",
    "for query, _ in distribution:\n",
    "    prompts = await query.adapt_prompts(\"korean\", llm=generator_llm)\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loaded_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SingleHopScenario(\n",
       " nodes=1\n",
       " term=\n",
       " persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
       " style=QueryStyle.PERFECT_GRAMMAR\n",
       " length=QueryLength.MEDIUM),\n",
       " SingleHopScenario(\n",
       " nodes=1\n",
       " term=\n",
       " persona=name='Financial Data Scientist' role_description='Specializes in analyzing financial data using advanced algorithms to ensure compliance, security, and accurate predictions.'\n",
       " style=QueryStyle.PERFECT_GRAMMAR\n",
       " length=QueryLength.SHORT)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario_sample_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(id: 421d36, type: NodeType.CHUNK, properties: ['page_content', 'entities', 'themes']),\n",
       " Node(id: e4d209, type: NodeType.CHUNK, properties: ['page_content', 'entities', 'themes']),\n",
       " Node(id: 8cb85b, type: NodeType.CHUNK, properties: ['page_content', 'entities', 'themes']),\n",
       " Node(id: a4b129, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 9d4361, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 479c20, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 3fd12d, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: e4b2f0, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: cab49c, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 6b320f, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 8eba31, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: d75d66, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 6f7196, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities'])]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n in loaded_kg.nodes if n.type == NodeType.CHUNK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Relationship(Node(id: a4b129) -> Node(id: e4b2f0), type: entities_overlap, properties: ['entities_overlap_score', 'overlapped_items']),\n",
       " Relationship(Node(id: a4b129) -> Node(id: d75d66), type: entities_overlap, properties: ['entities_overlap_score', 'overlapped_items']),\n",
       " Relationship(Node(id: 479c20) -> Node(id: e4b2f0), type: entities_overlap, properties: ['entities_overlap_score', 'overlapped_items']),\n",
       " Relationship(Node(id: e4b2f0) -> Node(id: cab49c), type: entities_overlap, properties: ['entities_overlap_score', 'overlapped_items'])]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rel for rel in loaded_kg.relationships if rel.type == \"entities_overlap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHopAbstractQuerySynthesizer(name='multi_hop_abstract_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "3. **Multi-Hop Context Tags**:\n",
       "   - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "   - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), concept_combination_prompt=ConceptCombinationPrompt(instruction=Form combinations by pairing concepts from at least two different lists.\n",
       "**Instructions:**\n",
       "- Review the concepts from each node.\n",
       "- Identify concepts that can logically be connected or contrasted.\n",
       "- Form combinations that involve concepts from different nodes.\n",
       "- Each combination should include at least one concept from two or more nodes.\n",
       "- List the combinations clearly and concisely.\n",
       "- Do not repeat the same combination more than once., examples=[(ConceptsList(lists_of_concepts=[['Artificial intelligence', 'Automation'], ['Healthcare', 'Data privacy']], max_combinations=2), ConceptCombinations(combinations=[['Artificial intelligence', 'Healthcare'], ['Automation', 'Data privacy']]))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_distribution[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHopSpecificQuerySynthesizer(name='multi_hop_specific_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
       "1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
       "2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
       "3. **Multi-Hop Context Tags**:\n",
       "   - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
       "   - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), relation_type='entities_overlap', property_name='entities', theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_distribution[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = query_distribution[2][0].get_node_clusters(loaded_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시나리오 생성시 한글 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, _ in query_distribution:\n",
    "    prompts = await query.adapt_prompts(\"korean\", llm=generator_llm)\n",
    "    query.set_prompts(**prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios: 100%|██████████| 3/3 [00:19<00:00,  6.62s/it]\n",
      "Generating Samples: 100%|██████████| 22/22 [00:07<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "testset_generator = TestsetGenerator(embedding_model=ragas_embeddings, llm=generator_llm, knowledge_graph=loaded_kg, persona_list=persona_list)\n",
    "samples = testset_generator.generate(testset_size=20, query_distribution=query_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = samples.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nijkamp et al.의 연구에서 파운데이션 모델의 특징은 무엇인가요?</td>\n",
       "      <td>[2.1.2. 파운데이션 모델(Foundation Model) 및 첫 번째 작업은 ...</td>\n",
       "      <td>Nijkamp et al.의 연구에 따르면, 파운데이션 모델은 일반 데이터와 전문 ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023d에서 언급된 파인튜닝의 목적은 무엇인가요?</td>\n",
       "      <td>[사전학습하기 위한 사례에 맞게 파인튜닝을 하게 된다(정천수, 2023d). &lt;그림...</td>\n",
       "      <td>2023d에서는 사전학습하기 위한 사례에 맞게 파인튜닝을 하게 된다고 언급하고 있습니다.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>금융 뉴스의 하이퍼파라미터 조정이 모델 성능에 미치는 영향은 무엇입니까?</td>\n",
       "      <td>[2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하이퍼파라미터 조정 모...</td>\n",
       "      <td>금융 뉴스 하이퍼파라미터 조정은 모델의 성능을 극대화하기 위해 중요한 단계이며, 감...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BloombergGPT의 가용성에 대한 정보는 무엇인가요?</td>\n",
       "      <td>[모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써 모델의 학습과 일반...</td>\n",
       "      <td>BloombergGPT는 금융 특화 대규모 언어 모델로, 100억 개의 매개변수를 ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>금융 분야에서 LLM 파인튜닝을 수행할 때 고려해야 할 사항은 무엇인가요?</td>\n",
       "      <td>[3.3.2. 파인튜닝 알고리즘 적용 이터 보안 및 개인정보 보호를 고려하여 데이터...</td>\n",
       "      <td>금융 분야의 LLM 파인튜닝을 수행할 때는 데이터 보안, 개인정보 보호, 규정 준수...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>금융 분야에서 BloombergGPT의 역할은 무엇입니까?</td>\n",
       "      <td>[3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 규정 준수 금융 분야...</td>\n",
       "      <td>BloombergGPT는 금융 분야에서 자연어 처리에 특화된 모델로, 금융 데이터의...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>금융 특화 파인튜닝이란 무엇이며, 이 기술이 금융 분야에서 어떻게 높은 성능을 발휘...</td>\n",
       "      <td>[하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융 특화 파인튜닝 LL...</td>\n",
       "      <td>금융 특화 파인튜닝은 금융 분야의 특정 작업에 높은 성능을 보이는 LLM(대형 언어...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>금융 데이터의 특성을 고려한 파인튜닝이 고객 응대 개선에 어떻게 기여할 수 있나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...</td>\n",
       "      <td>금융 데이터의 특성을 고려한 파인튜닝은 LLM 모델의 성능을 향상시켜 금융 예측 및...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>금융 데이터의 특성을 고려한 LLM의 고객 응대 개선 가능성은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...</td>\n",
       "      <td>금융 데이터의 특성을 고려한 LLM은 고객 응대 개선에 있어 자동 응답 시스템과 금...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>금융 데이터의 특성을 고려한 LLM의 파인튜닝이 고객 응대 개선에 어떻게 기여할 수...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...</td>\n",
       "      <td>금융 데이터의 특성을 고려한 LLM의 파인튜닝은 고객 응대 개선에 기여할 수 있는 ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>금융 분야에서 모델 성능 극대화를 위해 하이퍼파라미터 조정은 어떻게 이루어지나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...</td>\n",
       "      <td>금융 분야에서 모델 성능 극대화를 위해 하이퍼파라미터 조정은 모델의 용도에 따라 적...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>금융 분야에서 LLM 파인튜닝은 어떤 모델들이 사용되고 있나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융...</td>\n",
       "      <td>금융 분야에서 LLM 파인튜닝은 여러 모델들이 사용되고 있으며, 그 중 FinGPT...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>사전 훈련된 LLM 모델을 활용하여 금융 뉴스의 감성 분석을 수행할 때, 모델 성능...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...</td>\n",
       "      <td>금융 뉴스의 감성 분석을 수행하기 위해 사전 훈련된 LLM 모델을 활용할 때, 모델...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>금융 데이터의 특성을 고려한 모델 성능 극대화 방법은 무엇이며, 이를 위해 어떤 하...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...</td>\n",
       "      <td>금융 데이터의 특성을 고려한 모델 성능 극대화 방법으로는 파인튜닝을 통해 모델의 성...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GPT-4와 FinGPT의 금융 도메인에서의 차이점은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...</td>\n",
       "      <td>GPT-4는 OpenAI에서 개발한 대규모 언어 모델로, 1,750억 개 이상의 매...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GPT-4와 FinGPT는 금융 분야에서 어떻게 다르게 활용되며, 각각의 모델이 가...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...</td>\n",
       "      <td>GPT-4는 OpenAI에서 개발한 대규모 언어 모델로, 1,750억 개 이상의 매...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FinGPT는 금융 분야에서 어떤 방식으로 파인튜닝되어 있으며, BloombergG...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 ...</td>\n",
       "      <td>FinGPT는 OpenAI의 GPT 아키텍처를 기반으로 하여 금융 도메인에서 처음부...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FinGPT와 BloombergGPT는 금융 분야에서 어떻게 파인튜닝되어 있으며, ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 ...</td>\n",
       "      <td>FinGPT와 BloombergGPT는 금융 분야에 특화된 파인튜닝을 통해 높은 성...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BLOOM과 BloombergGPT의 금융 특화 파인튜닝은 어떤 차이점이 있나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n&lt;표 7&gt; Evaluation Benchmarks of Blo...</td>\n",
       "      <td>BLOOM과 BloombergGPT는 모두 금융 분야에 특화된 LLM 모델이지만, ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BLOOM과 BloombergGPT는 금융 분야에서 어떤 역할을 하나요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n&lt;표 7&gt; Evaluation Benchmarks of Blo...</td>\n",
       "      <td>BLOOM과 BloombergGPT는 금융 분야에서 각각의 특화된 역할을 수행합니다...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mistral-7B SLM을 활용한 금융 데이터의 파인튜닝 방법은 무엇인가요?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...</td>\n",
       "      <td>Mistral-7B SLM을 활용한 금융 데이터의 파인튜닝 방법은 금융 데이터의 특...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mistral-7B SLM의 금융 분야에서의 활용 가능성과 이를 위한 데이터 전처리...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...</td>\n",
       "      <td>Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 모델의 성...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0           Nijkamp et al.의 연구에서 파운데이션 모델의 특징은 무엇인가요?   \n",
       "1                        2023d에서 언급된 파인튜닝의 목적은 무엇인가요?   \n",
       "2            금융 뉴스의 하이퍼파라미터 조정이 모델 성능에 미치는 영향은 무엇입니까?   \n",
       "3                    BloombergGPT의 가용성에 대한 정보는 무엇인가요?   \n",
       "4           금융 분야에서 LLM 파인튜닝을 수행할 때 고려해야 할 사항은 무엇인가요?   \n",
       "5                    금융 분야에서 BloombergGPT의 역할은 무엇입니까?   \n",
       "6   금융 특화 파인튜닝이란 무엇이며, 이 기술이 금융 분야에서 어떻게 높은 성능을 발휘...   \n",
       "7      금융 데이터의 특성을 고려한 파인튜닝이 고객 응대 개선에 어떻게 기여할 수 있나요?   \n",
       "8           금융 데이터의 특성을 고려한 LLM의 고객 응대 개선 가능성은 무엇인가요?   \n",
       "9   금융 데이터의 특성을 고려한 LLM의 파인튜닝이 고객 응대 개선에 어떻게 기여할 수...   \n",
       "10      금융 분야에서 모델 성능 극대화를 위해 하이퍼파라미터 조정은 어떻게 이루어지나요?   \n",
       "11                금융 분야에서 LLM 파인튜닝은 어떤 모델들이 사용되고 있나요?   \n",
       "12  사전 훈련된 LLM 모델을 활용하여 금융 뉴스의 감성 분석을 수행할 때, 모델 성능...   \n",
       "13  금융 데이터의 특성을 고려한 모델 성능 극대화 방법은 무엇이며, 이를 위해 어떤 하...   \n",
       "14               GPT-4와 FinGPT의 금융 도메인에서의 차이점은 무엇인가요?   \n",
       "15  GPT-4와 FinGPT는 금융 분야에서 어떻게 다르게 활용되며, 각각의 모델이 가...   \n",
       "16  FinGPT는 금융 분야에서 어떤 방식으로 파인튜닝되어 있으며, BloombergG...   \n",
       "17  FinGPT와 BloombergGPT는 금융 분야에서 어떻게 파인튜닝되어 있으며, ...   \n",
       "18      BLOOM과 BloombergGPT의 금융 특화 파인튜닝은 어떤 차이점이 있나요?   \n",
       "19           BLOOM과 BloombergGPT는 금융 분야에서 어떤 역할을 하나요?   \n",
       "20        Mistral-7B SLM을 활용한 금융 데이터의 파인튜닝 방법은 무엇인가요?   \n",
       "21  Mistral-7B SLM의 금융 분야에서의 활용 가능성과 이를 위한 데이터 전처리...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [2.1.2. 파운데이션 모델(Foundation Model) 및 첫 번째 작업은 ...   \n",
       "1   [사전학습하기 위한 사례에 맞게 파인튜닝을 하게 된다(정천수, 2023d). <그림...   \n",
       "2   [2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하이퍼파라미터 조정 모...   \n",
       "3   [모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써 모델의 학습과 일반...   \n",
       "4   [3.3.2. 파인튜닝 알고리즘 적용 이터 보안 및 개인정보 보호를 고려하여 데이터...   \n",
       "5   [3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 규정 준수 금융 분야...   \n",
       "6   [하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융 특화 파인튜닝 LL...   \n",
       "7   [<1-hop>\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...   \n",
       "8   [<1-hop>\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...   \n",
       "9   [<1-hop>\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...   \n",
       "10  [<1-hop>\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...   \n",
       "11  [<1-hop>\\n\\n하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융...   \n",
       "12  [<1-hop>\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...   \n",
       "13  [<1-hop>\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...   \n",
       "14  [<1-hop>\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...   \n",
       "15  [<1-hop>\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...   \n",
       "16  [<1-hop>\\n\\n3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 ...   \n",
       "17  [<1-hop>\\n\\n3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 ...   \n",
       "18  [<1-hop>\\n\\n<표 7> Evaluation Benchmarks of Blo...   \n",
       "19  [<1-hop>\\n\\n<표 7> Evaluation Benchmarks of Blo...   \n",
       "20  [<1-hop>\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...   \n",
       "21  [<1-hop>\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Nijkamp et al.의 연구에 따르면, 파운데이션 모델은 일반 데이터와 전문 ...   \n",
       "1   2023d에서는 사전학습하기 위한 사례에 맞게 파인튜닝을 하게 된다고 언급하고 있습니다.   \n",
       "2   금융 뉴스 하이퍼파라미터 조정은 모델의 성능을 극대화하기 위해 중요한 단계이며, 감...   \n",
       "3   BloombergGPT는 금융 특화 대규모 언어 모델로, 100억 개의 매개변수를 ...   \n",
       "4   금융 분야의 LLM 파인튜닝을 수행할 때는 데이터 보안, 개인정보 보호, 규정 준수...   \n",
       "5   BloombergGPT는 금융 분야에서 자연어 처리에 특화된 모델로, 금융 데이터의...   \n",
       "6   금융 특화 파인튜닝은 금융 분야의 특정 작업에 높은 성능을 보이는 LLM(대형 언어...   \n",
       "7   금융 데이터의 특성을 고려한 파인튜닝은 LLM 모델의 성능을 향상시켜 금융 예측 및...   \n",
       "8   금융 데이터의 특성을 고려한 LLM은 고객 응대 개선에 있어 자동 응답 시스템과 금...   \n",
       "9   금융 데이터의 특성을 고려한 LLM의 파인튜닝은 고객 응대 개선에 기여할 수 있는 ...   \n",
       "10  금융 분야에서 모델 성능 극대화를 위해 하이퍼파라미터 조정은 모델의 용도에 따라 적...   \n",
       "11  금융 분야에서 LLM 파인튜닝은 여러 모델들이 사용되고 있으며, 그 중 FinGPT...   \n",
       "12  금융 뉴스의 감성 분석을 수행하기 위해 사전 훈련된 LLM 모델을 활용할 때, 모델...   \n",
       "13  금융 데이터의 특성을 고려한 모델 성능 극대화 방법으로는 파인튜닝을 통해 모델의 성...   \n",
       "14  GPT-4는 OpenAI에서 개발한 대규모 언어 모델로, 1,750억 개 이상의 매...   \n",
       "15  GPT-4는 OpenAI에서 개발한 대규모 언어 모델로, 1,750억 개 이상의 매...   \n",
       "16  FinGPT는 OpenAI의 GPT 아키텍처를 기반으로 하여 금융 도메인에서 처음부...   \n",
       "17  FinGPT와 BloombergGPT는 금융 분야에 특화된 파인튜닝을 통해 높은 성...   \n",
       "18  BLOOM과 BloombergGPT는 모두 금융 분야에 특화된 LLM 모델이지만, ...   \n",
       "19  BLOOM과 BloombergGPT는 금융 분야에서 각각의 특화된 역할을 수행합니다...   \n",
       "20  Mistral-7B SLM을 활용한 금융 데이터의 파인튜닝 방법은 금융 데이터의 특...   \n",
       "21  Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 모델의 성...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   single_hop_specifc_query_synthesizer  \n",
       "6   single_hop_specifc_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_abstract_query_synthesizer  \n",
       "9   multi_hop_abstract_query_synthesizer  \n",
       "10  multi_hop_abstract_query_synthesizer  \n",
       "11  multi_hop_abstract_query_synthesizer  \n",
       "12  multi_hop_abstract_query_synthesizer  \n",
       "13  multi_hop_abstract_query_synthesizer  \n",
       "14  multi_hop_specific_query_synthesizer  \n",
       "15  multi_hop_specific_query_synthesizer  \n",
       "16  multi_hop_specific_query_synthesizer  \n",
       "17  multi_hop_specific_query_synthesizer  \n",
       "18  multi_hop_specific_query_synthesizer  \n",
       "19  multi_hop_specific_query_synthesizer  \n",
       "20  multi_hop_specific_query_synthesizer  \n",
       "21  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What role does Semi-Supervised Learning play in the development of foundation models?\n",
      "What does the term '2023d' refer to in the context of fine-tuning for pre-training?\n",
      "금융 특화 LLM의 하이퍼파라미터 조정은 왜 중요한가?\n",
      "Mistral-7B는 어떤 모델이고, 금융 분야에서 어떻게 사용될 수 있나요?\n",
      "금융 데이터의 특성을 고려한 파인튜닝이 고객 응대 개선에 어떻게 기여할 수 있는지 설명해줘.\n",
      "What are the implications of fine-tuning LLMs for financial data in improving customer service and predictive accuracy?\n",
      "What are the implications of fine-tuning LLMs for financial data in improving customer service and predictive accuracy?\n",
      "금융 분야 특화 모델인 BloombergGPT와 FinBERT의 성능 극대화에 필요한 하이퍼파라미터 조정은 어떻게 이루어져야 하나요?\n",
      "GPT-4와 FinGPT는 금융 분야에서 어떻게 활용되고 있으며, 이 두 모델의 차이점은 무엇인가요?\n",
      "FinGPT와 BloombergGPT는 금융 분야에서 어떻게 특화된 파인튜닝을 통해 성능을 향상시키고 있나요?\n",
      "What advancements have been made in financial language models like BloombergGPT and how do they compare to other models such as FinGPT and BLOOM in terms of their training and application in the finance sector?\n",
      "Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 어떤 성능 향상을 이루었나요?\n"
     ]
    }
   ],
   "source": [
    "for q in df.user_input:\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What role does Semi-Supervised Learning play i...</td>\n",
       "      <td>[2.1.2. 파운데이션 모델(Foundation Model) 및 첫 번째 작업은 ...</td>\n",
       "      <td>Semi-Supervised Learning is utilized in the de...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does the term '2023d' refer to in the con...</td>\n",
       "      <td>[사전학습하기 위한 사례에 맞게 파인튜닝을 하게 된다(정천수, 2023d). &lt;그림...</td>\n",
       "      <td>'2023d' refers to a source by Jeong Cheon-soo ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>금융 특화 LLM의 하이퍼파라미터 조정은 왜 중요한가?</td>\n",
       "      <td>[2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하이퍼파라미터 조정 모...</td>\n",
       "      <td>금융 특화 LLM의 하이퍼파라미터 조정은 모델의 성능을 극대화하기 위해 중요한 단계...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral-7B는 어떤 모델이고, 금융 분야에서 어떻게 사용될 수 있나요?</td>\n",
       "      <td>[모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써 모델의 학습과 일반...</td>\n",
       "      <td>Mistral-7B는 프랑스의 스타트업 미스트랄 AI가 개발한 매개변수 73억 개의...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>금융 데이터의 특성을 고려한 파인튜닝이 고객 응대 개선에 어떻게 기여할 수 있는지 ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...</td>\n",
       "      <td>금융 데이터의 특성을 고려한 파인튜닝은 고객 응대 개선에 기여할 수 있는 여러 방법...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the implications of fine-tuning LLMs ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...</td>\n",
       "      <td>Fine-tuning LLMs for financial data has signif...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the implications of fine-tuning LLMs ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...</td>\n",
       "      <td>Fine-tuning LLMs for financial data has signif...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>금융 분야 특화 모델인 BloombergGPT와 FinBERT의 성능 극대화에 필요...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...</td>\n",
       "      <td>금융 분야 특화 모델인 BloombergGPT와 FinBERT의 성능 극대화를 위해...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPT-4와 FinGPT는 금융 분야에서 어떻게 활용되고 있으며, 이 두 모델의 차...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...</td>\n",
       "      <td>GPT-4는 OpenAI에서 개발한 대규모 언어 모델로, 1,750억 개 이상의 매...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FinGPT와 BloombergGPT는 금융 분야에서 어떻게 특화된 파인튜닝을 통해...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 ...</td>\n",
       "      <td>FinGPT와 BloombergGPT는 금융 분야에 특화된 파인튜닝을 통해 성능을 ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What advancements have been made in financial ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n&lt;표 7&gt; Evaluation Benchmarks of Blo...</td>\n",
       "      <td>BloombergGPT has shown outstanding performance...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 어떤 성능...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...</td>\n",
       "      <td>Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 모델의 성...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What role does Semi-Supervised Learning play i...   \n",
       "1   What does the term '2023d' refer to in the con...   \n",
       "2                      금융 특화 LLM의 하이퍼파라미터 조정은 왜 중요한가?   \n",
       "3         Mistral-7B는 어떤 모델이고, 금융 분야에서 어떻게 사용될 수 있나요?   \n",
       "4   금융 데이터의 특성을 고려한 파인튜닝이 고객 응대 개선에 어떻게 기여할 수 있는지 ...   \n",
       "5   What are the implications of fine-tuning LLMs ...   \n",
       "6   What are the implications of fine-tuning LLMs ...   \n",
       "7   금융 분야 특화 모델인 BloombergGPT와 FinBERT의 성능 극대화에 필요...   \n",
       "8   GPT-4와 FinGPT는 금융 분야에서 어떻게 활용되고 있으며, 이 두 모델의 차...   \n",
       "9   FinGPT와 BloombergGPT는 금융 분야에서 어떻게 특화된 파인튜닝을 통해...   \n",
       "10  What advancements have been made in financial ...   \n",
       "11  Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 어떤 성능...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [2.1.2. 파운데이션 모델(Foundation Model) 및 첫 번째 작업은 ...   \n",
       "1   [사전학습하기 위한 사례에 맞게 파인튜닝을 하게 된다(정천수, 2023d). <그림...   \n",
       "2   [2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하이퍼파라미터 조정 모...   \n",
       "3   [모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써 모델의 학습과 일반...   \n",
       "4   [<1-hop>\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...   \n",
       "5   [<1-hop>\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...   \n",
       "6   [<1-hop>\\n\\n금융 데이터의 특성을 고려한 파인튜닝을 통해 된 데이터셋은 생...   \n",
       "7   [<1-hop>\\n\\n2) 모델의 용도: 모델의 용도에 따라 적합한 3.2.2. 하...   \n",
       "8   [<1-hop>\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...   \n",
       "9   [<1-hop>\\n\\n3.4. 금융 분야를 위한 LLM 구성 3.3.3. 보안 및 ...   \n",
       "10  [<1-hop>\\n\\n<표 7> Evaluation Benchmarks of Blo...   \n",
       "11  [<1-hop>\\n\\n모델의 가용성: 모델이 공개되어 있지 않다 적절히 조정함으로써...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Semi-Supervised Learning is utilized in the de...   \n",
       "1   '2023d' refers to a source by Jeong Cheon-soo ...   \n",
       "2   금융 특화 LLM의 하이퍼파라미터 조정은 모델의 성능을 극대화하기 위해 중요한 단계...   \n",
       "3   Mistral-7B는 프랑스의 스타트업 미스트랄 AI가 개발한 매개변수 73억 개의...   \n",
       "4   금융 데이터의 특성을 고려한 파인튜닝은 고객 응대 개선에 기여할 수 있는 여러 방법...   \n",
       "5   Fine-tuning LLMs for financial data has signif...   \n",
       "6   Fine-tuning LLMs for financial data has signif...   \n",
       "7   금융 분야 특화 모델인 BloombergGPT와 FinBERT의 성능 극대화를 위해...   \n",
       "8   GPT-4는 OpenAI에서 개발한 대규모 언어 모델로, 1,750억 개 이상의 매...   \n",
       "9   FinGPT와 BloombergGPT는 금융 분야에 특화된 파인튜닝을 통해 성능을 ...   \n",
       "10  BloombergGPT has shown outstanding performance...   \n",
       "11  Mistral-7B SLM은 금융 데이터의 특성을 고려한 파인튜닝을 통해 모델의 성...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이후 변환 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:   0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    }
   ],
   "source": [
    "apply_transforms(new_kg,trans[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 38, relationships: 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(id: d5f1ac, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: dd6f45, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 717795, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: e8e202, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: cab49c, type: NodeType.CHUNK, properties: ['page_content', 'entities', 'themes']),\n",
       " Node(id: 6c5799, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: c07e55, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 3fd12d, type: NodeType.CHUNK, properties: ['page_content', 'entities', 'themes']),\n",
       " Node(id: d75d66, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 533e23, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 542663, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 479c20, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 761566, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 6b320f, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: f63445, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: e4d209, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: e94830, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 6f7196, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 438a11, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 026ec0, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 0a5256, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: f6a9e5, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 55746f, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: c60096, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 8cb85b, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: a4b129, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 14101c, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 8eba31, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 776df5, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: e4b2f0, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 9d4361, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 08c7fb, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata']),\n",
       " Node(id: cea3aa, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata']),\n",
       " Node(id: 406f1e, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 666985, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: 421d36, type: NodeType.CHUNK, properties: ['page_content', 'themes', 'entities']),\n",
       " Node(id: 61fcbd, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding']),\n",
       " Node(id: fe875f, type: NodeType.DOCUMENT, properties: ['page_content', 'document_metadata', 'headlines', 'summary', 'summary_embedding'])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_kg.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kg.save(\"test_kg/kg_RelationBuilder_NoDupli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_kg=KnowledgeGraph().load(\"test_kg/kg_RelationBuilder_NoDupli.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 62.23ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:06<00:00,  6.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/copycatQ/ragas_practice_dataset_korean/commit/1151094a46265af5bf8eefb2337fd5f9def6cb2b', commit_message='Upload dataset', commit_description='', oid='1151094a46265af5bf8eefb2337fd5f9def6cb2b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/copycatQ/ragas_practice_dataset_korean', endpoint='https://huggingface.co', repo_type='dataset', repo_id='copycatQ/ragas_practice_dataset_korean'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "# pandas DataFrame을 Hugging Face Dataset으로 변환\n",
    "dataset = Dataset.from_pandas(final_data)\n",
    "\n",
    "# 데이터셋 이름 설정 (원하는 이름으로 변경하세요)\n",
    "dataset_name = \"copycatQ/ragas_practice_dataset_korean\"\n",
    "\n",
    "# 데이터셋 업로드\n",
    "dataset.push_to_hub(\n",
    "    dataset_name,\n",
    "    private=True,  # private=False로 설정하면 공개 데이터셋이 됩니다.\n",
    "    split=\"korean_v1\",  # 데이터셋 split 이름 입력\n",
    "    token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS 라이브러리와 형식 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.prompt.pydantic_prompt import PydanticPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_check_input(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "    reference_context: t.List[str]\n",
    "\n",
    "class QA_check_output(BaseModel):\n",
    "    validity: bool\n",
    "    reference_context_relevance: bool\n",
    "    qa_appropriateness:bool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "class QA_checkPrompt(PydanticPrompt[QA_check_input, QA_check_output]):\n",
    "    instruction: str = (\n",
    "        \"Evaluate whether the following question and answer are appropriate based on the provided paper.\"\n",
    "        \"Please sequentially assess the following items:\"\n",
    "\n",
    "        \"1. Question Validity\"\n",
    "        \"- Is the question clearly structured based on the terms, expressions, or concepts mentioned in the paper?\"\n",
    "        \"- It is inappropriate if the question misinterprets an author's name or citation (e.g., (Hong, 2024)) as a term or concept.\"\n",
    "\n",
    "        \"2. Reference Context Relevance\"\n",
    "        \"- Does the provided reference context accurately match the actual content of the paper and relate properly to the question and answer?\"\n",
    "\n",
    "        \"3. QA Appropriateness\"\n",
    "        \"- Does the provided answer appropriately respond to the question based on information explicitly stated in the paper?\"\n",
    "    )\n",
    "    input_model: t.Type[QA_check_input] = QA_check_input\n",
    "    output_model: t.Type[QA_check_output] = QA_check_output\n",
    "    examples: t.List[t.Tuple[QA_check_input, QA_check_output]] = [\n",
    "        (\n",
    "            QA_check_input(\n",
    "                question=\"What impact do few-shot prompting techniques have on LLM models?\",\n",
    "                answer=\"Few-shot prompting techniques help improve the question-answering performance of LLM models.\",\n",
    "                reference_context=[\"Recent LLM models are known to improve question-answering performance using few-shot prompting techniques (Lee, 2023).\"],\n",
    "            ),\n",
    "            QA_check_output(\n",
    "                validity=True,\n",
    "                reference_context_relevance=True,\n",
    "                qa_appropriateness=True\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            QA_check_input(\n",
    "                question=\"What does Kim mean?\",\n",
    "                answer=\"Kim refers to the fine-tuning method of further training models on specific tasks.\",\n",
    "                reference_context=[\"Fine-tuning is a methodology to improve performance by further training pre-trained models on specific tasks (Kim, 2022).\"],\n",
    "            ),\n",
    "            QA_check_output(\n",
    "                validity=False,\n",
    "                reference_context_relevance=False,\n",
    "                qa_appropriateness=False\n",
    "            )\n",
    "        )\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "introduction_prompt_kor = \"\"\"\"\n",
    "다음 질문과 답변이 주어진 논문을 기준으로 적절한지 평가하십시오.\n",
    "\n",
    "다음 항목을 순차적으로 평가해 주세요:\n",
    "\n",
    "1. 질문의 적절성 (Validity)\n",
    "- 질문이 논문에 언급된 용어, 표현, 개념에 대해 논문에서 제공하는 정보를 바탕으로 답할 수 있도록 명확히 구성되었나요?\n",
    "- 논문에서 인용된 사람의 이름 또는 특정 저자명을 단순 인용 표기(예: (홍길동, 2024))임에도 불구하고 단어나 개념처럼 잘못 해석하여 그 의미를 묻는 질문은 부적절합니다.\n",
    "(예: 논문 인용 표기에서 \"(홍길동, 2024)\"와 같은 저자 이름을 하나의 개념이나 용어로 잘못 파악하고 질문하는 경우는 잘못된 질문임.)\n",
    "\n",
    "2. 참조 문맥의 관련성 (Reference Context Relevance)\n",
    "- 제공된 참조 문맥이 질문과 답변에 관련 있으며, 논문의 실제 내용과 정확히 일치하는가요?\n",
    "\n",
    "3. 답변의 적합성 (QA Appropriateness)\n",
    "- 제공된 답변이 논문에서 실제로 제시된 정보를 근거로 질문에 적절히 대응하는가요?\" \\\n",
    "\"\"\"\n",
    "\n",
    "example_kor = [\n",
    "        (\n",
    "            QA_check_input(\n",
    "                question=\"Few-shot 프롬프트 기법이 LLM 모델에 미치는 영향은 무엇인가요?\",\n",
    "                answer=\"Few-shot 프롬프트 기법은 LLM 모델의 질문-답변 성능을 향상시키는 데 도움을 줍니다.\",\n",
    "                reference_context=[\"최근 LLM 모델은 Few-shot 프롬프트 기법을 활용하여 질문-답변 성능을 향상시킬 수 있다고 알려졌다(AAA, 2023).\"],\n",
    "            ),\n",
    "            QA_check_output(\n",
    "                validity=True,\n",
    "                reference_context_relevance=True,\n",
    "                qa_appropriateness=True\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            QA_check_input(\n",
    "                question=\"BBB는 무엇을 의미하나요?\",\n",
    "                answer=\"김철수는 특정 작업에 맞게 모델을 추가 학습하는 파인튜닝 방법을 의미합니다.\",\n",
    "                reference_context=[\"파인튜닝은 특정 작업에 맞게 사전 학습된 모델을 추가 학습하여 성능을 개선하는 방법론이다(BBB, 2022).\"],\n",
    "            ),\n",
    "            QA_check_output(\n",
    "                validity=False,\n",
    "                reference_context_relevance=False,\n",
    "                qa_appropriateness=False\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "qa_check = QA_checkPrompt()\n",
    "qa_check.instruction = introduction_prompt_kor\n",
    "qa_check.examples = example_kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleTurnSample(user_input='What evaluation benchmarks are used for BloombergGPT, and what specific tasks does it measure in the financial domain?', retrieved_contexts=None, reference_contexts=['<표 7> Evaluation Benchmarks of BloombergGPT. Suit Tasks What does it measure? Public Financial Tasks 5 Public datasets in the financial domain Bloomberg Financial Tasks 12 NER and sentiment analysis tasks Big-bench Hard (Suzgun et al., 2022) 23 Reasoning and general NLP tasks Knowledge Assessments 5 Testing closed-book information recall Reading Comprehension 5 Testing open-book tasks Linguistic Tasks 9 Not directly user-facing NLP tasks 109'], response=None, multi_responses=None, reference='BloombergGPT uses several evaluation benchmarks, including Public Financial Tasks, which measure 5 public datasets in the financial domain, and Bloomberg Financial Tasks, which consist of 12 NER and sentiment analysis tasks. Additionally, it includes Big-bench Hard (Suzgun et al., 2022) with 23 reasoning and general NLP tasks, Knowledge Assessments with 5 testing closed-book information recall tasks, Reading Comprehension with 5 testing open-book tasks, and Linguistic Tasks, which encompass 9 not directly user-facing NLP tasks, totaling 109 tasks.', rubrics=None)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.to_evaluation_dataset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample2qainput(sample):\n",
    "    return QA_check_input(\n",
    "        question=sample.user_input,\n",
    "        answer=sample.reference,\n",
    "        reference_context=sample.reference_contexts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QA_check_input(question='금융 특화 파인튜닝이란 무엇이며, 어떤 성능을 보이나요?', answer='금융 특화 파인튜닝은 금융 분야의 특정 작업에 높은 성능을 보이는 LLM(대형 언어 모델)으로, 금융 분야에 특화된 파인튜닝이 적용된 모델입니다.', reference_context=['하여, 금융 분야의 특정 작업에 높은 성능을 3.4.2. 금융 특화 파인튜닝 LLM 보이고 있다. (LLM fine-tuned for finance) 금융 분야에 특화된 파인튜닝이 적용된 모델 '])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2qainput(samples.to_evaluation_dataset()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = await qa_check.generate(data=sample2qainput(samples.to_evaluation_dataset()[5]), llm=generator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QA_check_output(validity=False, reference_context_relevance=True, qa_appropriateness=False)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
