{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyC06D**********\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['GOOGLE_API_KEY'][:10]+'*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Naive RAG TEST\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"Naive RAG TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain import hub\n",
    "\n",
    "# prompt_txt = \"\"\"\n",
    "# You are an AI assistant specializing in Question-Answering (QA) tasks within a Retrieval-Augmented Generation (RAG) system. \n",
    "# Your primary mission is to answer questions based on provided context or chat history.\n",
    "# Ensure your response is concise and directly addresses the question without any additional narration.\n",
    "\n",
    "# ###\n",
    "\n",
    "# You may consider the previous conversation history to answer the question.\n",
    "\n",
    "# # Here's the previous conversation history:\n",
    "# {chat_history}\n",
    "\n",
    "# ###\n",
    "\n",
    "# Your final answer should be written concisely (but include important numerical values, technical terms, jargon, and names), followed by the source of the information.\n",
    "\n",
    "# # Steps\n",
    "\n",
    "# 1. Carefully read and understand the context provided.\n",
    "# 2. Identify the key information related to the question within the context.\n",
    "# 3. Formulate a concise answer based on the relevant information.\n",
    "# 4. Ensure your final answer directly addresses the question.\n",
    "# 5. List the source of the answer in bullet points, which must be a file name (with a page number) or URL from the context. Omit if the answer is based on previous conversation or if the source cannot be found.\n",
    "\n",
    "# # Output Format:\n",
    "# [Your final answer here, with numerical values, technical terms, jargon, and names in their original language]\n",
    "\n",
    "# **Source**(Optional)\n",
    "# - (Source of the answer, must be a file name(with a page number) or URL from the context. Omit if the answer is based on previous conversation or can't find the source.)\n",
    "# - (list more if there are multiple sources)\n",
    "# - ...\n",
    "\n",
    "# ###\n",
    "\n",
    "# Remember:\n",
    "# - It's crucial to base your answer solely on the **provided context** or **chat history**. \n",
    "# - DO NOT use any external knowledge or information not present in the given materials.\n",
    "# - If a user asks based on the previous conversation, but if there's no previous conversation or not enough information, you should answer that you don't know.\n",
    "\n",
    "# ###\n",
    "\n",
    "# # Here is the user's question:\n",
    "# {question}\n",
    "\n",
    "# # Here is the context that you should use to answer the question:\n",
    "# {context}\n",
    "\n",
    "# # Your final answer to the user's question:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(prompt_txt)\n",
    "# hub.push(\"naive_rag_gemni\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from operator import itemgetter\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "class RetrievalChain(ABC):\n",
    "    def __init__(self):\n",
    "        self.source_uri = None\n",
    "        self.k = 10\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_documents(self, source_uris):\n",
    "        \"\"\"loader를 사용하여 문서를 로드합니다.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_text_splitter(self):\n",
    "        \"\"\"text splitter를 생성합니다.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def split_documents(self, docs, text_splitter):\n",
    "        \"\"\"text splitter를 사용하여 문서를 분할합니다.\"\"\"\n",
    "        return text_splitter.split_documents(docs)\n",
    "\n",
    "    def create_embedding(self):\n",
    "        return OllamaEmbeddings(model=\"bge-m3\")\n",
    "    \n",
    "    def create_embdding_eng(self):\n",
    "        return GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "\n",
    "    def create_vectorstore(self, split_docs, inlang = \"ko\"):\n",
    "        if inlang == \"ko\":\n",
    "            return FAISS.from_documents(\n",
    "                documents=split_docs, embedding=self.create_embedding()\n",
    "            )\n",
    "        elif inlang == \"eng\":\n",
    "            return FAISS.from_documents(\n",
    "                documents=split_docs, embedding=self.create_embdding_eng()\n",
    "            )\n",
    "\n",
    "    def create_retriever(self, vectorstore):\n",
    "        # MMR을 사용하여 검색을 수행하는 retriever를 생성합니다.\n",
    "        dense_retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": self.k}\n",
    "        )\n",
    "        return dense_retriever\n",
    "\n",
    "    def create_model(self):\n",
    "        # return ChatOllama(model_name=\"dnotitia/dna\", temperature=0)\n",
    "        return ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "    def create_prompt(self):\n",
    "        return hub.pull(\"naive_rag_gemni\")\n",
    "\n",
    "    @staticmethod\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\".join(docs)\n",
    "\n",
    "    def create_chain(self, inlang = \"ko\"):\n",
    "        docs = self.load_documents(self.source_uri)\n",
    "        text_splitter = self.create_text_splitter()\n",
    "        split_docs = self.split_documents(docs, text_splitter)\n",
    "        self.vectorstore = self.create_vectorstore(split_docs, inlang)\n",
    "        self.retriever = self.create_retriever(self.vectorstore)\n",
    "        model = self.create_model()\n",
    "        prompt = self.create_prompt()\n",
    "        self.chain = (\n",
    "            {\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"context\": itemgetter(\"context\"),\n",
    "                \"chat_history\": itemgetter(\"chat_history\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List, Annotated\n",
    "\n",
    "\n",
    "class PDFRetrievalChain(RetrievalChain):\n",
    "    def __init__(self, source_uri: Annotated[str, \"Source URI\"]):\n",
    "        self.source_uri = source_uri\n",
    "        self.k = 10\n",
    "\n",
    "    def load_documents(self, source_uris: List[str]):\n",
    "        docs = []\n",
    "        for source_uri in source_uris:\n",
    "            # loader = PDFPlumberLoader(source_uri)\n",
    "            loader = PyPDFLoader(source_uri)\n",
    "            docs.extend(loader.load())\n",
    "\n",
    "        return docs\n",
    "\n",
    "    def create_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf\"]).create_chain(inlang=\"ko\")\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근의 PEFT 파인튜닝 방법으로는 Prompt \n",
      "modification, Adapter methods, Parameterization 으\n",
      "로 분류하고 있다 . Prompt modification 은 Hard \n",
      "prompt tuning 과 Soft prompt tuning, Prefix-tuning 이 \n",
      "있다. Adapter methods 는 LLaMA-Adapter 등이 \n",
      "있으며 Adapter를 통한 PEFT로 전체 모델의 파인\n",
      "튜닝 부작용을 최소화하기 위해 모듈화한 파라\n",
      "미터를 <그림 6>과 같이 추가 삽입하여 학습한다 . \n",
      "하나의 Adapter 모듈은 Bottleneck Layer 를 중심\n",
      "으로 Down-projection 과 Up-projection 의 선형변\n",
      "환을 수행하고 파인튜닝 과정에서 Pre-trained LLM\n",
      "은 Frozen된다.\n",
      "<그림 6> Adapter methods\n",
      "\n",
      "대해 사전 학습되며 파인튜닝 , In-context learning, \n",
      "Zero/one/few-shot learning 같은 기술을 사용한다\n",
      "(Dilmegani, 2023). 사전학습 후에는 모델 성능을 \n",
      "측정하기 위한 학습 데이터 세트로 사용되지 않은 \n",
      "테스트 데이터 세트에서 모델을 평가하고 평가 결과에 따라 모델의 성능을 향상시키기 위해 하\n",
      "이퍼파라미터를 조정하거나 , 아키텍처를 변경하\n",
      "거나, 추가 데이터에 대한 교육을 통해 일부 파인\n",
      "튜닝을 한다 (정천수 , 2023d). 이렇게 파인튜닝 된 \n",
      "언어 모델 (Fine-tuned Language Model, FLM) 은 \n",
      "다양한 도메인 특화된 소규모 언어 모델 (SLM)로 \n",
      "활용된다 .\n",
      "2.2.1. 최신 파인튜닝 (Fine Tuning)\n",
      "최근의 PEFT 파인튜닝 방법으로는 Prompt \n",
      "modification, Adapter methods, Parameterization 으\n",
      "\n",
      "들을 Full Fine-tuning 을 하기에는 컴퓨팅 소스가 \n",
      "매우 크기 때문에 LoRA와 같이 기존의 Pre-trained \n",
      "Layer의 가중치는 고정하고 , 새로운 레이어의 가\n",
      "중치만을 학습을 시키는데도 , 실제 성능의 차이\n",
      "가 많지 않은 것으로 검증됨에 따라 최근에는 모\n",
      "든 매개변수를 튜닝하는 것이 아닌 사전 훈련된 \n",
      "LLM에 소수의 새로운 매개변수를 추가하고 , 추\n",
      "가된 매개변수만 파인튜닝하여 적은 비용으로 \n",
      "더 나은 성능을 발휘하도록 하는 PEFT(Parameter-\n",
      "Efficient Fine-Tuning) 방법을 주로 사용한다 (Raschka, \n",
      "2023). \n",
      "대표적인 것인 LoRA는 LLM의 일부 Weight \n",
      "Matrix들에 대해서만 추가적인 학습을 허용하며 \n",
      "각각의 Transformer Layer 내에서 일부의 Weight \n",
      "Matrix에 대해 파인튜닝 대상을 결정하며 해당 \n",
      "<그림 4> LLM의 Fine-tuning\n",
      "\n",
      "SFT) 모델을 생성하고 훈련할 수 있도록 SFTTrainer\n",
      "에 필요한 구성 요소들을 제공하고 , 이는 모델 , \n",
      "데이터셋 , Lora 설정, 토크나이저 , 그리고 훈련 매개\n",
      "변수 등을 포함한다 .\n",
      "<그림 13> SFT parameters\n",
      "마지막은 <그림 14>와 같이 모델 학습의 순서\n",
      "로 이루어 지는데 PLM에 추가적인 데이터셋을 \n",
      "학습하는 파인튜닝 실행 코드 및 결과이다 . \n",
      "<그림 14> 파인튜닝 학습 실행이 코드는 PEFT 모델의 캐시 사용 여부를 비\n",
      "활성화하고 , 그 후에 트레이너를 사용하여 모델을  \n",
      "훈련시키는 과정을 나타내는 것으로 <그림 12> \n",
      "하이퍼파라미터 설정에서 ‘max_steps = 60’ 으로 \n",
      "설정하여 학습이 진행되는 총 스텝 횟수가 60이 \n",
      "완료된 것을 볼 수 있으며 , 파인튜닝된 ‘Mistral-\n",
      "7B-Fine-tuning-Insurance’ FLM 이 로컬 드라이브에  \n",
      "저장된 것을 확인할 수 있다 . 이렇게 생성된 FLM은\n",
      "\n",
      "도메인 특화 LLM: Mistral 7B를 활용한 금융 업무분야 파인튜닝 및 활용 방법\n",
      "󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏\n",
      "113위한 학습 설정을 제어하며 , 하이퍼파라미터 및 \n",
      "학습 전략에 관련된 다양한 요소를 조정할 수 있다 . \n",
      "또한 <그림 13>은 Hugging Face 의 TRL(Transformer \n",
      "Reinforcement Learning) 라이브러리가 사용자 친화\n",
      "적인 API를 제공하여 최소한의 코딩으로 데이터셋\n",
      "에서 지도학습 파인튜닝 (Supervised Fine-Tuning, \n",
      "SFT) 모델을 생성하고 훈련할 수 있도록 SFTTrainer\n",
      "에 필요한 구성 요소들을 제공하고 , 이는 모델 ,\n",
      "\n",
      "정 천 수\n",
      "󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏\n",
      "114다른 질문인 “선물이 뭐야 ?” 라고 질문했을 때도 \n",
      "PLM에서는 일반적인 책 , 휴대전화 등과 같은 제\n",
      "품 선물에 대한 답변을 했으나 FLM PEFT 모델\n",
      "에서는 금융 용어에 적합한 “미래의 상품을 현재\n",
      "에서 거래하는 것입니다 .”라고 생성해주는 것을 \n",
      "확인할 수 있었다 . \n",
      "<그림 16> PEFT Model 테스트\n",
      "지금까지 PLM에 금융 특화 데이터셋 추가하여  \n",
      "FLM으로 파인튜닝하는 방법과 결과를 검증하는 \n",
      "방법을 알아보았다 . 본 구현 사례를 참조한다면 \n",
      "도메인의 분류에 따라 , 그리고 업무 크기 정도에 \n",
      "따라 업무에 맞게 관련된 LLM을 다양하게 파인\n",
      "\n",
      "7B-Fine-tuning-Insurance’ FLM 이 로컬 드라이브에  \n",
      "저장된 것을 확인할 수 있다 . 이렇게 생성된 FLM은 \n",
      "관련업무에 맞게 자유롭게 로컬에서 활용 수 있다 .\n",
      "4.1.4. FLM 테스트\n",
      "생성된 FLM을 테스트하기 위해 <그림 15>와 \n",
      "같이 PEFT FLM 을 로드 하는 과정을 나타내고 \n",
      "있다. FLM 모델에 <그림 16>과 같이 질문하여 \n",
      "정상적으로 모델이 작동하는 것을 확인할 수 있다 .\n",
      "<그림 15> PEFT Model 로드\n",
      "사전 학습된 PLM과 PEFT 튜닝된 PLM에 ‘골프\n",
      "보험 알려줘 ’라는 질문을 했을 때 파인튜닝되기\n",
      "전 PLM 모델에서는 보험 내용이 아닌 전혀 다른 \n",
      "답변을 생성한 것 비해 FLM에서는 보험에 특화\n",
      "된 데이터셋으로 PEFT 파인튜닝된 모델에서는 \n",
      "보험에 관련된 내용으로 학습된 답변 (예시: “골프\n",
      "장에서의 사고를 대상으로 ,”)을 생성하였으며 , 또\n",
      "\n",
      "기본모델로 두고 Instruction tuning 한 모델이다 .3. 연구 방법\n",
      "본 장에서는 금융 도메인에 특화된 LLM의 생\n",
      "성을 위한 체계적인 접근 방법을 제시한다 . 파인\n",
      "튜닝 진행 방법은 <그림 8>에서 제시하는 절차\n",
      "로 진행하며 데이터 수집과 전처리 단계에서는 \n",
      "금융 특화 데이터셋을 선정하고 , 효과적인 전처\n",
      "리 방법을 도입한다 . 모델 선정과 파인튜닝 절차\n",
      "에서는 적절한 사전 훈련된 LLM인 PLM을 선정\n",
      "하고, 하이퍼파라미터를 조정하여 튜닝한다 . 금\n",
      "융 분야의 특성을 고려한 파인튜닝 고려사항에\n",
      "서는 금융 데이터 특성 , 도메인 특화 어휘 , 파인\n",
      "튜닝 알고리즘에 대한 고려사항을 다룬다 . 이후 \n",
      "금융 분야를 위한 LLM 구성에서는 처음부터 학\n",
      "습하는 방법과 이미 존재하는 모델을 튜닝하는 \n",
      "방법에 대한 구성 방안을 소개한다 . 마지막으로 , \n",
      "평가 기준과 지표에서는 정량적 성능 지표와 정성적 \n",
      "성능 지표를 활용한 모델의 평가기준을 가이드\n",
      "\n",
      "확인하고\n",
      ", 학습 과정에서 발생한 문제를 신\n",
      "속하게 파악할 수 있다 .\n",
      "7)하이퍼파라미터 튜닝 : 하이퍼파라미터 최\n",
      "적화 도구를 활용하여 자동으로 최적의 하이\n",
      "퍼파라미터 조합 찾기를 하게 되는데 Grid \n",
      "Search 또는 Random Search 와 같은 튜닝 \n",
      "기법을 사용하여 하이퍼파라미터를 조정하\n",
      "면 모델의 성능을 극대화할 수 있다 .\n",
      "이렇게 모델 파인튜닝 실행 환경 설정은 실험\n",
      "의 효율성 및 모델의 수렴을 보장하기 위해 신중\n",
      "한 계획과 감독이 필요하다 . 설정된 환경에서 수\n",
      "행되는 실험 결과를 기반으로 계속해서 최적화\n",
      "를 진행해야 한다 .\n",
      "3.3. 금융 특화 LLM 파인튜닝시 고려사항\n",
      "금융 분야의 LLM 파인튜닝은 다음과 같은 단\n",
      "계를 포함하여 진행한다 .\n",
      "3.3.1. 금융 데이터 특성을 고려한 도메인 특화 \n",
      "어휘 구축\n",
      "금융 데이터는 독특한 특성을 지니고 있으며 , \n",
      "주식 가격의 변동 , 금융 뉴스의 감성 등 다양한 \n",
      "측면이 모델에 영향을 미친다 . 따라서 , 이러한\n",
      "\n",
      "판단을 내리기 위하여 LLM을 활용한다 (장갑수 , \n",
      "2023). 이렇게 가장 늦게 신기술을 도입하는 금\n",
      "융권에서도 생성형 AI인 LLM의 활용이 확대되\n",
      "고 있다 . 하지만 일반적인 LLM을 가지고 도입을 도메인 특화 LLM: Mistral 7B 를 활용한 \n",
      "금융 업무분야 파인튜닝 및 활용 방법\n",
      "정천수\n",
      "삼 성 S D S  A I  A u t o m a t i o n  T e a m\n",
      "(csu.jeong@samsung.com)\n",
      "․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․\n",
      "최근 사전학습된 범용적인 LLM(Large Language Model) 출시가 활발해지고 있지만 , 도메인 특화 파인튜닝된 LLM 연\n",
      "구와 생성 방법을 제시하는 것은 부족한 실정이다 . 본 연구는 도메인에 특화된 LLM의 파인튜닝과 활용에 대한 방안을\n"
     ]
    }
   ],
   "source": [
    "search_result = pdf_retriever.invoke(\"최근의 PEFT 파인튜닝 방법들은?\")\n",
    "print('\\n\\n'.join([doc.page_content for doc in search_result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최근의 PEFT 파인튜닝 방법은 Prompt modification, Adapter methods, Parameterization으로 분류됩니다. Prompt modification에는 Hard prompt tuning, Soft prompt tuning, Prefix-tuning이 있습니다. Adapter methods에는 LLaMA-Adapter 등이 있습니다.\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf (page 9)\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과를 기반으로 답변을 생성합니다.\n",
    "answer = pdf_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"최근의 PEFT 파인튜닝 방법들은?\",\n",
    "        \"context\": search_result,\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# GraphState 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  # 질문\n",
    "    context: Annotated[str, \"Context\"]  # 문서의 검색 결과\n",
    "    answer: Annotated[str, \"Answer\"]  # 답변\n",
    "    messages: Annotated[list, add_messages]  # 메시지(누적되는 list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"<document><content>{doc.page_content}</content><source>{doc.metadata['source']}</source><page>{int(doc.metadata['page'])+1}</page></document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def format_searched_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"<document><content>{doc['content']}</content><source>{doc['url']}</source></document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def format_task(tasks):\n",
    "    # 결과를 저장할 빈 리스트 생성\n",
    "    task_time_pairs = []\n",
    "\n",
    "    # 리스트를 순회하면서 각 항목을 처리\n",
    "    for item in tasks:\n",
    "        # 콜론(:) 기준으로 문자열을 분리\n",
    "        task, time_str = item.rsplit(\":\", 1)\n",
    "        # '시간' 문자열을 제거하고 정수로 변환\n",
    "        time = int(time_str.replace(\"시간\", \"\").strip())\n",
    "        # 할 일과 시간을 튜플로 만들어 리스트에 추가\n",
    "        task_time_pairs.append((task, time))\n",
    "\n",
    "    # 결과 출력\n",
    "    return task_time_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import messages_to_history\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    # 검색된 문서를 형식화합니다.(프롬프트 입력으로 넣어주기 위함)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 검색된 문서를 상태에서 가져옵니다.\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # 체인을 호출하여 답변을 생성합니다.\n",
    "    response = pdf_chain.invoke(\n",
    "        {\n",
    "            \"question\": latest_question,\n",
    "            \"context\": context,\n",
    "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "        }\n",
    "    )\n",
    "    # 생성된 답변, (유저의 질문, 답변) 메시지를 상태에 저장합니다.\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"messages\": [(\"user\", latest_question), (\"assistant\", response)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 생성\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "# 엣지 정의\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "workflow.add_edge(\"llm_answer\", END)  # 답변 -> 종료\n",
    "\n",
    "# 그래프 진입점 설정\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 체크포인터 설정\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 컴파일\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mretrieve\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>최근의 PEFT 파인튜닝 방법으로는 Prompt \n",
      "modification, Adapter methods, Parameterization 으\n",
      "로 분류하고 있다 . Prompt modification 은 Hard \n",
      "prompt tuning 과 Soft prompt tuning, Prefix-tuning 이 \n",
      "있다. Adapter methods 는 LLaMA-Adapter 등이 \n",
      "있으며 Adapter를 통한 PEFT로 전체 모델의 파인\n",
      "튜닝 부작용을 최소화하기 위해 모듈화한 파라\n",
      "미터를 <그림 6>과 같이 추가 삽입하여 학습한다 . \n",
      "하나의 Adapter 모듈은 Bottleneck Layer 를 중심\n",
      "으로 Down-projection 과 Up-projection 의 선형변\n",
      "환을 수행하고 파인튜닝 과정에서 Pre-trained LLM\n",
      "은 Frozen된다.\n",
      "<그림 6> Adapter methods</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>10</page></document>\n",
      "<document><content>대해 사전 학습되며 파인튜닝 , In-context learning, \n",
      "Zero/one/few-shot learning 같은 기술을 사용한다\n",
      "(Dilmegani, 2023). 사전학습 후에는 모델 성능을 \n",
      "측정하기 위한 학습 데이터 세트로 사용되지 않은 \n",
      "테스트 데이터 세트에서 모델을 평가하고 평가 결과에 따라 모델의 성능을 향상시키기 위해 하\n",
      "이퍼파라미터를 조정하거나 , 아키텍처를 변경하\n",
      "거나, 추가 데이터에 대한 교육을 통해 일부 파인\n",
      "튜닝을 한다 (정천수 , 2023d). 이렇게 파인튜닝 된 \n",
      "언어 모델 (Fine-tuned Language Model, FLM) 은 \n",
      "다양한 도메인 특화된 소규모 언어 모델 (SLM)로 \n",
      "활용된다 .\n",
      "2.2.1. 최신 파인튜닝 (Fine Tuning)\n",
      "최근의 PEFT 파인튜닝 방법으로는 Prompt \n",
      "modification, Adapter methods, Parameterization 으</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>10</page></document>\n",
      "<document><content>들을 Full Fine-tuning 을 하기에는 컴퓨팅 소스가 \n",
      "매우 크기 때문에 LoRA와 같이 기존의 Pre-trained \n",
      "Layer의 가중치는 고정하고 , 새로운 레이어의 가\n",
      "중치만을 학습을 시키는데도 , 실제 성능의 차이\n",
      "가 많지 않은 것으로 검증됨에 따라 최근에는 모\n",
      "든 매개변수를 튜닝하는 것이 아닌 사전 훈련된 \n",
      "LLM에 소수의 새로운 매개변수를 추가하고 , 추\n",
      "가된 매개변수만 파인튜닝하여 적은 비용으로 \n",
      "더 나은 성능을 발휘하도록 하는 PEFT(Parameter-\n",
      "Efficient Fine-Tuning) 방법을 주로 사용한다 (Raschka, \n",
      "2023). \n",
      "대표적인 것인 LoRA는 LLM의 일부 Weight \n",
      "Matrix들에 대해서만 추가적인 학습을 허용하며 \n",
      "각각의 Transformer Layer 내에서 일부의 Weight \n",
      "Matrix에 대해 파인튜닝 대상을 결정하며 해당 \n",
      "<그림 4> LLM의 Fine-tuning</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>9</page></document>\n",
      "<document><content>SFT) 모델을 생성하고 훈련할 수 있도록 SFTTrainer\n",
      "에 필요한 구성 요소들을 제공하고 , 이는 모델 , \n",
      "데이터셋 , Lora 설정, 토크나이저 , 그리고 훈련 매개\n",
      "변수 등을 포함한다 .\n",
      "<그림 13> SFT parameters\n",
      "마지막은 <그림 14>와 같이 모델 학습의 순서\n",
      "로 이루어 지는데 PLM에 추가적인 데이터셋을 \n",
      "학습하는 파인튜닝 실행 코드 및 결과이다 . \n",
      "<그림 14> 파인튜닝 학습 실행이 코드는 PEFT 모델의 캐시 사용 여부를 비\n",
      "활성화하고 , 그 후에 트레이너를 사용하여 모델을  \n",
      "훈련시키는 과정을 나타내는 것으로 <그림 12> \n",
      "하이퍼파라미터 설정에서 ‘max_steps = 60’ 으로 \n",
      "설정하여 학습이 진행되는 총 스텝 횟수가 60이 \n",
      "완료된 것을 볼 수 있으며 , 파인튜닝된 ‘Mistral-\n",
      "7B-Fine-tuning-Insurance’ FLM 이 로컬 드라이브에  \n",
      "저장된 것을 확인할 수 있다 . 이렇게 생성된 FLM은</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>22</page></document>\n",
      "<document><content>도메인 특화 LLM: Mistral 7B를 활용한 금융 업무분야 파인튜닝 및 활용 방법\n",
      "󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏\n",
      "113위한 학습 설정을 제어하며 , 하이퍼파라미터 및 \n",
      "학습 전략에 관련된 다양한 요소를 조정할 수 있다 . \n",
      "또한 <그림 13>은 Hugging Face 의 TRL(Transformer \n",
      "Reinforcement Learning) 라이브러리가 사용자 친화\n",
      "적인 API를 제공하여 최소한의 코딩으로 데이터셋\n",
      "에서 지도학습 파인튜닝 (Supervised Fine-Tuning, \n",
      "SFT) 모델을 생성하고 훈련할 수 있도록 SFTTrainer\n",
      "에 필요한 구성 요소들을 제공하고 , 이는 모델 ,</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>22</page></document>\n",
      "<document><content>정 천 수\n",
      "󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏 󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏󰠏\n",
      "114다른 질문인 “선물이 뭐야 ?” 라고 질문했을 때도 \n",
      "PLM에서는 일반적인 책 , 휴대전화 등과 같은 제\n",
      "품 선물에 대한 답변을 했으나 FLM PEFT 모델\n",
      "에서는 금융 용어에 적합한 “미래의 상품을 현재\n",
      "에서 거래하는 것입니다 .”라고 생성해주는 것을 \n",
      "확인할 수 있었다 . \n",
      "<그림 16> PEFT Model 테스트\n",
      "지금까지 PLM에 금융 특화 데이터셋 추가하여  \n",
      "FLM으로 파인튜닝하는 방법과 결과를 검증하는 \n",
      "방법을 알아보았다 . 본 구현 사례를 참조한다면 \n",
      "도메인의 분류에 따라 , 그리고 업무 크기 정도에 \n",
      "따라 업무에 맞게 관련된 LLM을 다양하게 파인</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>23</page></document>\n",
      "<document><content>7B-Fine-tuning-Insurance’ FLM 이 로컬 드라이브에  \n",
      "저장된 것을 확인할 수 있다 . 이렇게 생성된 FLM은 \n",
      "관련업무에 맞게 자유롭게 로컬에서 활용 수 있다 .\n",
      "4.1.4. FLM 테스트\n",
      "생성된 FLM을 테스트하기 위해 <그림 15>와 \n",
      "같이 PEFT FLM 을 로드 하는 과정을 나타내고 \n",
      "있다. FLM 모델에 <그림 16>과 같이 질문하여 \n",
      "정상적으로 모델이 작동하는 것을 확인할 수 있다 .\n",
      "<그림 15> PEFT Model 로드\n",
      "사전 학습된 PLM과 PEFT 튜닝된 PLM에 ‘골프\n",
      "보험 알려줘 ’라는 질문을 했을 때 파인튜닝되기\n",
      "전 PLM 모델에서는 보험 내용이 아닌 전혀 다른 \n",
      "답변을 생성한 것 비해 FLM에서는 보험에 특화\n",
      "된 데이터셋으로 PEFT 파인튜닝된 모델에서는 \n",
      "보험에 관련된 내용으로 학습된 답변 (예시: “골프\n",
      "장에서의 사고를 대상으로 ,”)을 생성하였으며 , 또</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>22</page></document>\n",
      "<document><content>기본모델로 두고 Instruction tuning 한 모델이다 .3. 연구 방법\n",
      "본 장에서는 금융 도메인에 특화된 LLM의 생\n",
      "성을 위한 체계적인 접근 방법을 제시한다 . 파인\n",
      "튜닝 진행 방법은 <그림 8>에서 제시하는 절차\n",
      "로 진행하며 데이터 수집과 전처리 단계에서는 \n",
      "금융 특화 데이터셋을 선정하고 , 효과적인 전처\n",
      "리 방법을 도입한다 . 모델 선정과 파인튜닝 절차\n",
      "에서는 적절한 사전 훈련된 LLM인 PLM을 선정\n",
      "하고, 하이퍼파라미터를 조정하여 튜닝한다 . 금\n",
      "융 분야의 특성을 고려한 파인튜닝 고려사항에\n",
      "서는 금융 데이터 특성 , 도메인 특화 어휘 , 파인\n",
      "튜닝 알고리즘에 대한 고려사항을 다룬다 . 이후 \n",
      "금융 분야를 위한 LLM 구성에서는 처음부터 학\n",
      "습하는 방법과 이미 존재하는 모델을 튜닝하는 \n",
      "방법에 대한 구성 방안을 소개한다 . 마지막으로 , \n",
      "평가 기준과 지표에서는 정량적 성능 지표와 정성적 \n",
      "성능 지표를 활용한 모델의 평가기준을 가이드</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>11</page></document>\n",
      "<document><content>확인하고\n",
      ", 학습 과정에서 발생한 문제를 신\n",
      "속하게 파악할 수 있다 .\n",
      "7)하이퍼파라미터 튜닝 : 하이퍼파라미터 최\n",
      "적화 도구를 활용하여 자동으로 최적의 하이\n",
      "퍼파라미터 조합 찾기를 하게 되는데 Grid \n",
      "Search 또는 Random Search 와 같은 튜닝 \n",
      "기법을 사용하여 하이퍼파라미터를 조정하\n",
      "면 모델의 성능을 극대화할 수 있다 .\n",
      "이렇게 모델 파인튜닝 실행 환경 설정은 실험\n",
      "의 효율성 및 모델의 수렴을 보장하기 위해 신중\n",
      "한 계획과 감독이 필요하다 . 설정된 환경에서 수\n",
      "행되는 실험 결과를 기반으로 계속해서 최적화\n",
      "를 진행해야 한다 .\n",
      "3.3. 금융 특화 LLM 파인튜닝시 고려사항\n",
      "금융 분야의 LLM 파인튜닝은 다음과 같은 단\n",
      "계를 포함하여 진행한다 .\n",
      "3.3.1. 금융 데이터 특성을 고려한 도메인 특화 \n",
      "어휘 구축\n",
      "금융 데이터는 독특한 특성을 지니고 있으며 , \n",
      "주식 가격의 변동 , 금융 뉴스의 감성 등 다양한 \n",
      "측면이 모델에 영향을 미친다 . 따라서 , 이러한</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>16</page></document>\n",
      "<document><content>판단을 내리기 위하여 LLM을 활용한다 (장갑수 , \n",
      "2023). 이렇게 가장 늦게 신기술을 도입하는 금\n",
      "융권에서도 생성형 AI인 LLM의 활용이 확대되\n",
      "고 있다 . 하지만 일반적인 LLM을 가지고 도입을 도메인 특화 LLM: Mistral 7B 를 활용한 \n",
      "금융 업무분야 파인튜닝 및 활용 방법\n",
      "정천수\n",
      "삼 성 S D S  A I  A u t o m a t i o n  T e a m\n",
      "(csu.jeong@samsung.com)\n",
      "․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․․\n",
      "최근 사전학습된 범용적인 LLM(Large Language Model) 출시가 활발해지고 있지만 , 도메인 특화 파인튜닝된 LLM 연\n",
      "구와 생성 방법을 제시하는 것은 부족한 실정이다 . 본 연구는 도메인에 특화된 LLM의 파인튜닝과 활용에 대한 방안을</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>2</page></document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "최근의 PEFT 파인튜닝 방법은 Prompt modification, Adapter methods, Parameterization으로 분류되며, Prompt modification에는 Hard prompt tuning, Soft prompt tuning, Prefix-tuning이 있다. Adapter methods의 예시로는 LLaMA-Adapter가 있다.\n",
      "\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)\n",
      "('user', '최근의 PEFT 파인튜닝 방법들은?')\n",
      "('assistant', '최근의 PEFT 파인튜닝 방법은 Prompt modification, Adapter methods, Parameterization으로 분류되며, Prompt modification에는 Hard prompt tuning, Soft prompt tuning, Prefix-tuning이 있다. Adapter methods의 예시로는 LLaMA-Adapter가 있다.\\n\\n**Source**\\n- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import invoke_graph, stream_graph, random_uuid\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = GraphState(question=\"최근의 PEFT 파인튜닝 방법들은?\")\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "최근의 PEFT 파인튜닝 방법은 Prompt modification, Adapter methods, Parameterization으로 분류되며, Prompt modification에는 Hard prompt tuning, Soft prompt tuning, Prefix-tuning이 있다. Adapter methods의 예시로는 LLaMA-Adapter가 있다.\n",
      "\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)"
     ]
    }
   ],
   "source": [
    "# 그래프를 스트리밍 출력\n",
    "stream_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 최근의 PEFT 파인튜닝 방법들은?\n",
      "============================================================\n",
      "Answer:\n",
      "최근의 PEFT 파인튜닝 방법은 Prompt modification, Adapter methods, Parameterization으로 분류되며, Prompt modification에는 Hard prompt tuning, Soft prompt tuning, Prefix-tuning이 있다. Adapter methods의 예시로는 LLaMA-Adapter가 있다.\n",
      "\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)\n"
     ]
    }
   ],
   "source": [
    "outputs = app.get_state(config).values\n",
    "\n",
    "print(f'Question: {outputs[\"question\"]}')\n",
    "print(\"===\" * 20)\n",
    "print(f'Answer:\\n{outputs[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-6XMr01W1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
