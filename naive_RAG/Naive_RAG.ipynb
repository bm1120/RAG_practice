{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyC06D**********\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['GOOGLE_API_KEY'][:10]+'*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith μ¶”μ μ„ μ‹μ‘ν•©λ‹λ‹¤.\n",
      "[ν”„λ΅μ νΈλ…]\n",
      "Naive RAG TEST\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"Naive RAG TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain import hub\n",
    "\n",
    "# prompt_txt = \"\"\"\n",
    "# You are an AI assistant specializing in Question-Answering (QA) tasks within a Retrieval-Augmented Generation (RAG) system. \n",
    "# Your primary mission is to answer questions based on provided context or chat history.\n",
    "# Ensure your response is concise and directly addresses the question without any additional narration.\n",
    "\n",
    "# ###\n",
    "\n",
    "# You may consider the previous conversation history to answer the question.\n",
    "\n",
    "# # Here's the previous conversation history:\n",
    "# {chat_history}\n",
    "\n",
    "# ###\n",
    "\n",
    "# Your final answer should be written concisely (but include important numerical values, technical terms, jargon, and names), followed by the source of the information.\n",
    "\n",
    "# # Steps\n",
    "\n",
    "# 1. Carefully read and understand the context provided.\n",
    "# 2. Identify the key information related to the question within the context.\n",
    "# 3. Formulate a concise answer based on the relevant information.\n",
    "# 4. Ensure your final answer directly addresses the question.\n",
    "# 5. List the source of the answer in bullet points, which must be a file name (with a page number) or URL from the context. Omit if the answer is based on previous conversation or if the source cannot be found.\n",
    "\n",
    "# # Output Format:\n",
    "# [Your final answer here, with numerical values, technical terms, jargon, and names in their original language]\n",
    "\n",
    "# **Source**(Optional)\n",
    "# - (Source of the answer, must be a file name(with a page number) or URL from the context. Omit if the answer is based on previous conversation or can't find the source.)\n",
    "# - (list more if there are multiple sources)\n",
    "# - ...\n",
    "\n",
    "# ###\n",
    "\n",
    "# Remember:\n",
    "# - It's crucial to base your answer solely on the **provided context** or **chat history**. \n",
    "# - DO NOT use any external knowledge or information not present in the given materials.\n",
    "# - If a user asks based on the previous conversation, but if there's no previous conversation or not enough information, you should answer that you don't know.\n",
    "\n",
    "# ###\n",
    "\n",
    "# # Here is the user's question:\n",
    "# {question}\n",
    "\n",
    "# # Here is the context that you should use to answer the question:\n",
    "# {context}\n",
    "\n",
    "# # Your final answer to the user's question:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(prompt_txt)\n",
    "# hub.push(\"naive_rag_gemni\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from operator import itemgetter\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "class RetrievalChain(ABC):\n",
    "    def __init__(self):\n",
    "        self.source_uri = None\n",
    "        self.k = 10\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_documents(self, source_uris):\n",
    "        \"\"\"loaderλ¥Ό μ‚¬μ©ν•μ—¬ λ¬Έμ„λ¥Ό λ΅λ“ν•©λ‹λ‹¤.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_text_splitter(self):\n",
    "        \"\"\"text splitterλ¥Ό μƒμ„±ν•©λ‹λ‹¤.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def split_documents(self, docs, text_splitter):\n",
    "        \"\"\"text splitterλ¥Ό μ‚¬μ©ν•μ—¬ λ¬Έμ„λ¥Ό λ¶„ν• ν•©λ‹λ‹¤.\"\"\"\n",
    "        return text_splitter.split_documents(docs)\n",
    "\n",
    "    def create_embedding(self):\n",
    "        return OllamaEmbeddings(model=\"bge-m3\")\n",
    "    \n",
    "    def create_embdding_eng(self):\n",
    "        return GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "\n",
    "    def create_vectorstore(self, split_docs, inlang = \"ko\"):\n",
    "        if inlang == \"ko\":\n",
    "            return FAISS.from_documents(\n",
    "                documents=split_docs, embedding=self.create_embedding()\n",
    "            )\n",
    "        elif inlang == \"eng\":\n",
    "            return FAISS.from_documents(\n",
    "                documents=split_docs, embedding=self.create_embdding_eng()\n",
    "            )\n",
    "\n",
    "    def create_retriever(self, vectorstore):\n",
    "        # MMRμ„ μ‚¬μ©ν•μ—¬ κ²€μƒ‰μ„ μν–‰ν•λ” retrieverλ¥Ό μƒμ„±ν•©λ‹λ‹¤.\n",
    "        dense_retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": self.k}\n",
    "        )\n",
    "        return dense_retriever\n",
    "\n",
    "    def create_model(self):\n",
    "        # return ChatOllama(model_name=\"dnotitia/dna\", temperature=0)\n",
    "        return ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "    def create_prompt(self):\n",
    "        return hub.pull(\"naive_rag_gemni\")\n",
    "\n",
    "    @staticmethod\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\".join(docs)\n",
    "\n",
    "    def create_chain(self, inlang = \"ko\"):\n",
    "        docs = self.load_documents(self.source_uri)\n",
    "        text_splitter = self.create_text_splitter()\n",
    "        split_docs = self.split_documents(docs, text_splitter)\n",
    "        self.vectorstore = self.create_vectorstore(split_docs, inlang)\n",
    "        self.retriever = self.create_retriever(self.vectorstore)\n",
    "        model = self.create_model()\n",
    "        prompt = self.create_prompt()\n",
    "        self.chain = (\n",
    "            {\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"context\": itemgetter(\"context\"),\n",
    "                \"chat_history\": itemgetter(\"chat_history\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List, Annotated\n",
    "\n",
    "\n",
    "class PDFRetrievalChain(RetrievalChain):\n",
    "    def __init__(self, source_uri: Annotated[str, \"Source URI\"]):\n",
    "        self.source_uri = source_uri\n",
    "        self.k = 10\n",
    "\n",
    "    def load_documents(self, source_uris: List[str]):\n",
    "        docs = []\n",
    "        for source_uri in source_uris:\n",
    "            # loader = PDFPlumberLoader(source_uri)\n",
    "            loader = PyPDFLoader(source_uri)\n",
    "            docs.extend(loader.load())\n",
    "\n",
    "        return docs\n",
    "\n",
    "    def create_text_splitter(self):\n",
    "        return RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF λ¬Έμ„λ¥Ό λ΅λ“ν•©λ‹λ‹¤.\n",
    "pdf = PDFRetrievalChain([\"../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf\"]).create_chain(inlang=\"ko\")\n",
    "\n",
    "# retrieverμ™€ chainμ„ μƒμ„±ν•©λ‹λ‹¤.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μΌλ΅λ” Prompt \n",
      "modification, Adapter methods, Parameterization μΌ\n",
      "λ΅ λ¶„λ¥ν•κ³  μλ‹¤ . Prompt modification μ€ Hard \n",
      "prompt tuning κ³Ό Soft prompt tuning, Prefix-tuning μ΄ \n",
      "μλ‹¤. Adapter methods λ” LLaMA-Adapter λ“±μ΄ \n",
      "μμΌλ©° Adapterλ¥Ό ν†µν• PEFTλ΅ μ „μ²΄ λ¨λΈμ νμΈ\n",
      "νλ‹ λ¶€μ‘μ©μ„ μµμ†ν™”ν•κΈ° μ„ν•΄ λ¨λ“ν™”ν• νλΌ\n",
      "λ―Έν„°λ¥Ό <κ·Έλ¦Ό 6>κ³Ό κ°™μ΄ μ¶”κ°€ μ‚½μ…ν•μ—¬ ν•™μµν•λ‹¤ . \n",
      "ν•λ‚μ Adapter λ¨λ“μ€ Bottleneck Layer λ¥Ό μ¤‘μ‹¬\n",
      "μΌλ΅ Down-projection κ³Ό Up-projection μ μ„ ν•λ³€\n",
      "ν™μ„ μν–‰ν•κ³  νμΈνλ‹ κ³Όμ •μ—μ„ Pre-trained LLM\n",
      "μ€ Frozenλλ‹¤.\n",
      "<κ·Έλ¦Ό 6> Adapter methods\n",
      "\n",
      "λ€ν•΄ μ‚¬μ „ ν•™μµλλ©° νμΈνλ‹ , In-context learning, \n",
      "Zero/one/few-shot learning κ°™μ€ κΈ°μ μ„ μ‚¬μ©ν•λ‹¤\n",
      "(Dilmegani, 2023). μ‚¬μ „ν•™μµ ν›„μ—λ” λ¨λΈ μ„±λ¥μ„ \n",
      "μΈ΅μ •ν•κΈ° μ„ν• ν•™μµ λ°μ΄ν„° μ„ΈνΈλ΅ μ‚¬μ©λμ§€ μ•μ€ \n",
      "ν…μ¤νΈ λ°μ΄ν„° μ„ΈνΈμ—μ„ λ¨λΈμ„ ν‰κ°€ν•κ³  ν‰κ°€ κ²°κ³Όμ— λ”°λΌ λ¨λΈμ μ„±λ¥μ„ ν–¥μƒμ‹ν‚¤κΈ° μ„ν•΄ ν•\n",
      "μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•κ±°λ‚ , μ•„ν‚¤ν…μ²λ¥Ό λ³€κ²½ν•\n",
      "κ±°λ‚, μ¶”κ°€ λ°μ΄ν„°μ— λ€ν• κµμ΅μ„ ν†µν•΄ μΌλ¶€ νμΈ\n",
      "νλ‹μ„ ν•λ‹¤ (μ •μ²μ , 2023d). μ΄λ ‡κ² νμΈνλ‹ λ \n",
      "μ–Έμ–΄ λ¨λΈ (Fine-tuned Language Model, FLM) μ€ \n",
      "λ‹¤μ–‘ν• λ„λ©”μΈ νΉν™”λ μ†κ·λ¨ μ–Έμ–΄ λ¨λΈ (SLM)λ΅ \n",
      "ν™μ©λλ‹¤ .\n",
      "2.2.1. μµμ‹  νμΈνλ‹ (Fine Tuning)\n",
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μΌλ΅λ” Prompt \n",
      "modification, Adapter methods, Parameterization μΌ\n",
      "\n",
      "λ“¤μ„ Full Fine-tuning μ„ ν•κΈ°μ—λ” μ»΄ν“¨ν… μ†μ¤κ°€ \n",
      "λ§¤μ° ν¬κΈ° λ•λ¬Έμ— LoRAμ™€ κ°™μ΄ κΈ°μ΅΄μ Pre-trained \n",
      "Layerμ κ°€μ¤‘μΉλ” κ³ μ •ν•κ³  , μƒλ΅μ΄ λ μ΄μ–΄μ κ°€\n",
      "μ¤‘μΉλ§μ„ ν•™μµμ„ μ‹ν‚¤λ”λ°λ„ , μ‹¤μ  μ„±λ¥μ μ°¨μ΄\n",
      "κ°€ λ§μ§€ μ•μ€ κ²ƒμΌλ΅ κ²€μ¦λ¨μ— λ”°λΌ μµκ·Όμ—λ” λ¨\n",
      "λ“  λ§¤κ°λ³€μλ¥Ό νλ‹ν•λ” κ²ƒμ΄ μ•„λ‹ μ‚¬μ „ ν›λ ¨λ \n",
      "LLMμ— μ†μμ μƒλ΅μ΄ λ§¤κ°λ³€μλ¥Ό μ¶”κ°€ν•κ³  , μ¶”\n",
      "κ°€λ λ§¤κ°λ³€μλ§ νμΈνλ‹ν•μ—¬ μ μ€ λΉ„μ©μΌλ΅ \n",
      "λ” λ‚μ€ μ„±λ¥μ„ λ°νν•λ„λ΅ ν•λ” PEFT(Parameter-\n",
      "Efficient Fine-Tuning) λ°©λ²•μ„ μ£Όλ΅ μ‚¬μ©ν•λ‹¤ (Raschka, \n",
      "2023). \n",
      "λ€ν‘μ μΈ κ²ƒμΈ LoRAλ” LLMμ μΌλ¶€ Weight \n",
      "Matrixλ“¤μ— λ€ν•΄μ„λ§ μ¶”κ°€μ μΈ ν•™μµμ„ ν—μ©ν•λ©° \n",
      "κ°κ°μ Transformer Layer λ‚΄μ—μ„ μΌλ¶€μ Weight \n",
      "Matrixμ— λ€ν•΄ νμΈνλ‹ λ€μƒμ„ κ²°μ •ν•λ©° ν•΄λ‹Ή \n",
      "<κ·Έλ¦Ό 4> LLMμ Fine-tuning\n",
      "\n",
      "SFT) λ¨λΈμ„ μƒμ„±ν•κ³  ν›λ ¨ν•  μ μλ„λ΅ SFTTrainer\n",
      "μ— ν•„μ”ν• κµ¬μ„± μ”μ†λ“¤μ„ μ κ³µν•κ³  , μ΄λ” λ¨λΈ , \n",
      "λ°μ΄ν„°μ…‹ , Lora μ„¤μ •, ν† ν¬λ‚μ΄μ € , κ·Έλ¦¬κ³  ν›λ ¨ λ§¤κ°\n",
      "λ³€μ λ“±μ„ ν¬ν•¨ν•λ‹¤ .\n",
      "<κ·Έλ¦Ό 13> SFT parameters\n",
      "λ§μ§€λ§‰μ€ <κ·Έλ¦Ό 14>μ™€ κ°™μ΄ λ¨λΈ ν•™μµμ μμ„\n",
      "λ΅ μ΄λ£¨μ–΄ μ§€λ”λ° PLMμ— μ¶”κ°€μ μΈ λ°μ΄ν„°μ…‹μ„ \n",
      "ν•™μµν•λ” νμΈνλ‹ μ‹¤ν–‰ μ½”λ“ λ° κ²°κ³Όμ΄λ‹¤ . \n",
      "<κ·Έλ¦Ό 14> νμΈνλ‹ ν•™μµ μ‹¤ν–‰μ΄ μ½”λ“λ” PEFT λ¨λΈμ μΊμ‹ μ‚¬μ© μ—¬λ¶€λ¥Ό λΉ„\n",
      "ν™μ„±ν™”ν•κ³  , κ·Έ ν›„μ— νΈλ μ΄λ„λ¥Ό μ‚¬μ©ν•μ—¬ λ¨λΈμ„  \n",
      "ν›λ ¨μ‹ν‚¤λ” κ³Όμ •μ„ λ‚νƒ€λ‚΄λ” κ²ƒμΌλ΅ <κ·Έλ¦Ό 12> \n",
      "ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ—μ„ β€max_steps = 60β€™ μΌλ΅ \n",
      "μ„¤μ •ν•μ—¬ ν•™μµμ΄ μ§„ν–‰λλ” μ΄ μ¤ν… νμκ°€ 60μ΄ \n",
      "μ™„λ£λ κ²ƒμ„ λ³Ό μ μμΌλ©° , νμΈνλ‹λ β€Mistral-\n",
      "7B-Fine-tuning-Insuranceβ€™ FLM μ΄ λ΅μ»¬ λ“λΌμ΄λΈμ—  \n",
      "μ €μ¥λ κ²ƒμ„ ν™•μΈν•  μ μλ‹¤ . μ΄λ ‡κ² μƒμ„±λ FLMμ€\n",
      "\n",
      "λ„λ©”μΈ νΉν™” LLM: Mistral 7Bλ¥Ό ν™μ©ν• κΈμµ μ—…λ¬΄λ¶„μ•Ό νμΈνλ‹ λ° ν™μ© λ°©λ²•\n",
      "σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° \n",
      "113μ„ν• ν•™μµ μ„¤μ •μ„ μ μ–΄ν•λ©° , ν•μ΄νΌνλΌλ―Έν„° λ° \n",
      "ν•™μµ μ „λµμ— κ΄€λ ¨λ λ‹¤μ–‘ν• μ”μ†λ¥Ό μ΅°μ •ν•  μ μλ‹¤ . \n",
      "λν• <κ·Έλ¦Ό 13>μ€ Hugging Face μ TRL(Transformer \n",
      "Reinforcement Learning) λΌμ΄λΈλ¬λ¦¬κ°€ μ‚¬μ©μ μΉν™”\n",
      "μ μΈ APIλ¥Ό μ κ³µν•μ—¬ μµμ†ν•μ μ½”λ”©μΌλ΅ λ°μ΄ν„°μ…‹\n",
      "μ—μ„ μ§€λ„ν•™μµ νμΈνλ‹ (Supervised Fine-Tuning, \n",
      "SFT) λ¨λΈμ„ μƒμ„±ν•κ³  ν›λ ¨ν•  μ μλ„λ΅ SFTTrainer\n",
      "μ— ν•„μ”ν• κµ¬μ„± μ”μ†λ“¤μ„ μ κ³µν•κ³  , μ΄λ” λ¨λΈ ,\n",
      "\n",
      "μ • μ² μ\n",
      "σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° \n",
      "114λ‹¤λ¥Έ μ§λ¬ΈμΈ β€μ„ λ¬Όμ΄ λ­μ•Ό ?β€ λΌκ³  μ§λ¬Έν–μ„ λ•λ„ \n",
      "PLMμ—μ„λ” μΌλ°μ μΈ μ±… , ν΄λ€μ „ν™” λ“±κ³Ό κ°™μ€ μ \n",
      "ν’ μ„ λ¬Όμ— λ€ν• λ‹µλ³€μ„ ν–μΌλ‚ FLM PEFT λ¨λΈ\n",
      "μ—μ„λ” κΈμµ μ©μ–΄μ— μ ν•©ν• β€λ―Έλμ μƒν’μ„ ν„μ¬\n",
      "μ—μ„ κ±°λν•λ” κ²ƒμ…λ‹λ‹¤ .β€λΌκ³  μƒμ„±ν•΄μ£Όλ” κ²ƒμ„ \n",
      "ν™•μΈν•  μ μμ—λ‹¤ . \n",
      "<κ·Έλ¦Ό 16> PEFT Model ν…μ¤νΈ\n",
      "μ§€κΈκΉμ§€ PLMμ— κΈμµ νΉν™” λ°μ΄ν„°μ…‹ μ¶”κ°€ν•μ—¬  \n",
      "FLMμΌλ΅ νμΈνλ‹ν•λ” λ°©λ²•κ³Ό κ²°κ³Όλ¥Ό κ²€μ¦ν•λ” \n",
      "λ°©λ²•μ„ μ•μ•„λ³΄μ•λ‹¤ . λ³Έ κµ¬ν„ μ‚¬λ΅€λ¥Ό μ°Έμ΅°ν•λ‹¤λ©΄ \n",
      "λ„λ©”μΈμ λ¶„λ¥μ— λ”°λΌ , κ·Έλ¦¬κ³  μ—…λ¬΄ ν¬κΈ° μ •λ„μ— \n",
      "λ”°λΌ μ—…λ¬΄μ— λ§κ² κ΄€λ ¨λ LLMμ„ λ‹¤μ–‘ν•κ² νμΈ\n",
      "\n",
      "7B-Fine-tuning-Insuranceβ€™ FLM μ΄ λ΅μ»¬ λ“λΌμ΄λΈμ—  \n",
      "μ €μ¥λ κ²ƒμ„ ν™•μΈν•  μ μλ‹¤ . μ΄λ ‡κ² μƒμ„±λ FLMμ€ \n",
      "κ΄€λ ¨μ—…λ¬΄μ— λ§κ² μμ λ΅­κ² λ΅μ»¬μ—μ„ ν™μ© μ μλ‹¤ .\n",
      "4.1.4. FLM ν…μ¤νΈ\n",
      "μƒμ„±λ FLMμ„ ν…μ¤νΈν•κΈ° μ„ν•΄ <κ·Έλ¦Ό 15>μ™€ \n",
      "κ°™μ΄ PEFT FLM μ„ λ΅λ“ ν•λ” κ³Όμ •μ„ λ‚νƒ€λ‚΄κ³  \n",
      "μλ‹¤. FLM λ¨λΈμ— <κ·Έλ¦Ό 16>κ³Ό κ°™μ΄ μ§λ¬Έν•μ—¬ \n",
      "μ •μƒμ μΌλ΅ λ¨λΈμ΄ μ‘λ™ν•λ” κ²ƒμ„ ν™•μΈν•  μ μλ‹¤ .\n",
      "<κ·Έλ¦Ό 15> PEFT Model λ΅λ“\n",
      "μ‚¬μ „ ν•™μµλ PLMκ³Ό PEFT νλ‹λ PLMμ— β€κ³¨ν”„\n",
      "λ³΄ν— μ•λ ¤μ¤ β€™λΌλ” μ§λ¬Έμ„ ν–μ„ λ• νμΈνλ‹λκΈ°\n",
      "μ „ PLM λ¨λΈμ—μ„λ” λ³΄ν— λ‚΄μ©μ΄ μ•„λ‹ μ „ν€ λ‹¤λ¥Έ \n",
      "λ‹µλ³€μ„ μƒμ„±ν• κ²ƒ λΉ„ν•΄ FLMμ—μ„λ” λ³΄ν—μ— νΉν™”\n",
      "λ λ°μ΄ν„°μ…‹μΌλ΅ PEFT νμΈνλ‹λ λ¨λΈμ—μ„λ” \n",
      "λ³΄ν—μ— κ΄€λ ¨λ λ‚΄μ©μΌλ΅ ν•™μµλ λ‹µλ³€ (μμ‹: β€κ³¨ν”„\n",
      "μ¥μ—μ„μ μ‚¬κ³ λ¥Ό λ€μƒμΌλ΅ ,β€)μ„ μƒμ„±ν•μ€μΌλ©° , λ\n",
      "\n",
      "κΈ°λ³Έλ¨λΈλ΅ λ‘κ³  Instruction tuning ν• λ¨λΈμ΄λ‹¤ .3. μ—°κµ¬ λ°©λ²•\n",
      "λ³Έ μ¥μ—μ„λ” κΈμµ λ„λ©”μΈμ— νΉν™”λ LLMμ μƒ\n",
      "μ„±μ„ μ„ν• μ²΄κ³„μ μΈ μ ‘κ·Ό λ°©λ²•μ„ μ μ‹ν•λ‹¤ . νμΈ\n",
      "νλ‹ μ§„ν–‰ λ°©λ²•μ€ <κ·Έλ¦Ό 8>μ—μ„ μ μ‹ν•λ” μ μ°¨\n",
      "λ΅ μ§„ν–‰ν•λ©° λ°μ΄ν„° μμ§‘κ³Ό μ „μ²λ¦¬ λ‹¨κ³„μ—μ„λ” \n",
      "κΈμµ νΉν™” λ°μ΄ν„°μ…‹μ„ μ„ μ •ν•κ³  , ν¨κ³Όμ μΈ μ „μ²\n",
      "λ¦¬ λ°©λ²•μ„ λ„μ…ν•λ‹¤ . λ¨λΈ μ„ μ •κ³Ό νμΈνλ‹ μ μ°¨\n",
      "μ—μ„λ” μ μ ν• μ‚¬μ „ ν›λ ¨λ LLMμΈ PLMμ„ μ„ μ •\n",
      "ν•κ³ , ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•μ—¬ νλ‹ν•λ‹¤ . κΈ\n",
      "μµ λ¶„μ•Όμ νΉμ„±μ„ κ³ λ ¤ν• νμΈνλ‹ κ³ λ ¤μ‚¬ν•­μ—\n",
      "μ„λ” κΈμµ λ°μ΄ν„° νΉμ„± , λ„λ©”μΈ νΉν™” μ–΄ν , νμΈ\n",
      "νλ‹ μ•κ³ λ¦¬μ¦μ— λ€ν• κ³ λ ¤μ‚¬ν•­μ„ λ‹¤λ£¬λ‹¤ . μ΄ν›„ \n",
      "κΈμµ λ¶„μ•Όλ¥Ό μ„ν• LLM κµ¬μ„±μ—μ„λ” μ²μλ¶€ν„° ν•™\n",
      "μµν•λ” λ°©λ²•κ³Ό μ΄λ―Έ μ΅΄μ¬ν•λ” λ¨λΈμ„ νλ‹ν•λ” \n",
      "λ°©λ²•μ— λ€ν• κµ¬μ„± λ°©μ•μ„ μ†κ°ν•λ‹¤ . λ§μ§€λ§‰μΌλ΅ , \n",
      "ν‰κ°€ κΈ°μ¤€κ³Ό μ§€ν‘μ—μ„λ” μ •λ‰μ  μ„±λ¥ μ§€ν‘μ™€ μ •μ„±μ  \n",
      "μ„±λ¥ μ§€ν‘λ¥Ό ν™μ©ν• λ¨λΈμ ν‰κ°€κΈ°μ¤€μ„ κ°€μ΄λ“\n",
      "\n",
      "ν™•μΈν•κ³ \n",
      ", ν•™μµ κ³Όμ •μ—μ„ λ°μƒν• λ¬Έμ λ¥Ό μ‹ \n",
      "μ†ν•κ² νμ•…ν•  μ μλ‹¤ .\n",
      "7)ν•μ΄νΌνλΌλ―Έν„° νλ‹ : ν•μ΄νΌνλΌλ―Έν„° μµ\n",
      "μ ν™” λ„κµ¬λ¥Ό ν™μ©ν•μ—¬ μλ™μΌλ΅ μµμ μ ν•μ΄\n",
      "νΌνλΌλ―Έν„° μ΅°ν•© μ°ΎκΈ°λ¥Ό ν•κ² λλ”λ° Grid \n",
      "Search λλ” Random Search μ™€ κ°™μ€ νλ‹ \n",
      "κΈ°λ²•μ„ μ‚¬μ©ν•μ—¬ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•\n",
      "λ©΄ λ¨λΈμ μ„±λ¥μ„ κ·Ήλ€ν™”ν•  μ μλ‹¤ .\n",
      "μ΄λ ‡κ² λ¨λΈ νμΈνλ‹ μ‹¤ν–‰ ν™κ²½ μ„¤μ •μ€ μ‹¤ν—\n",
      "μ ν¨μ¨μ„± λ° λ¨λΈμ μλ ΄μ„ λ³΄μ¥ν•κΈ° μ„ν•΄ μ‹ μ¤‘\n",
      "ν• κ³„νκ³Ό κ°λ…μ΄ ν•„μ”ν•λ‹¤ . μ„¤μ •λ ν™κ²½μ—μ„ μ\n",
      "ν–‰λλ” μ‹¤ν— κ²°κ³Όλ¥Ό κΈ°λ°μΌλ΅ κ³„μ†ν•΄μ„ μµμ ν™”\n",
      "λ¥Ό μ§„ν–‰ν•΄μ•Ό ν•λ‹¤ .\n",
      "3.3. κΈμµ νΉν™” LLM νμΈνλ‹μ‹ κ³ λ ¤μ‚¬ν•­\n",
      "κΈμµ λ¶„μ•Όμ LLM νμΈνλ‹μ€ λ‹¤μκ³Ό κ°™μ€ λ‹¨\n",
      "κ³„λ¥Ό ν¬ν•¨ν•μ—¬ μ§„ν–‰ν•λ‹¤ .\n",
      "3.3.1. κΈμµ λ°μ΄ν„° νΉμ„±μ„ κ³ λ ¤ν• λ„λ©”μΈ νΉν™” \n",
      "μ–΄ν κµ¬μ¶•\n",
      "κΈμµ λ°μ΄ν„°λ” λ…νΉν• νΉμ„±μ„ μ§€λ‹κ³  μμΌλ©° , \n",
      "μ£Όμ‹ κ°€κ²©μ λ³€λ™ , κΈμµ λ‰΄μ¤μ κ°μ„± λ“± λ‹¤μ–‘ν• \n",
      "μΈ΅λ©΄μ΄ λ¨λΈμ— μν–¥μ„ λ―ΈμΉλ‹¤ . λ”°λΌμ„ , μ΄λ¬ν•\n",
      "\n",
      "νλ‹¨μ„ λ‚΄λ¦¬κΈ° μ„ν•μ—¬ LLMμ„ ν™μ©ν•λ‹¤ (μ¥κ°‘μ , \n",
      "2023). μ΄λ ‡κ² κ°€μ¥ λ¦κ² μ‹ κΈ°μ μ„ λ„μ…ν•λ” κΈ\n",
      "μµκ¶μ—μ„λ„ μƒμ„±ν• AIμΈ LLMμ ν™μ©μ΄ ν™•λ€λ\n",
      "κ³  μλ‹¤ . ν•μ§€λ§ μΌλ°μ μΈ LLMμ„ κ°€μ§€κ³  λ„μ…μ„ λ„λ©”μΈ νΉν™” LLM: Mistral 7B λ¥Ό ν™μ©ν• \n",
      "κΈμµ μ—…λ¬΄λ¶„μ•Ό νμΈνλ‹ λ° ν™μ© λ°©λ²•\n",
      "μ •μ²μ\n",
      "μ‚Ό μ„± S D S  A I  A u t o m a t i o n  T e a m\n",
      "(csu.jeong@samsung.com)\n",
      "β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤\n",
      "μµκ·Ό μ‚¬μ „ν•™μµλ λ²”μ©μ μΈ LLM(Large Language Model) μ¶μ‹κ°€ ν™λ°ν•΄μ§€κ³  μμ§€λ§ , λ„λ©”μΈ νΉν™” νμΈνλ‹λ LLM μ—°\n",
      "κµ¬μ™€ μƒμ„± λ°©λ²•μ„ μ μ‹ν•λ” κ²ƒμ€ λ¶€μ΅±ν• μ‹¤μ •μ΄λ‹¤ . λ³Έ μ—°κµ¬λ” λ„λ©”μΈμ— νΉν™”λ LLMμ νμΈνλ‹κ³Ό ν™μ©μ— λ€ν• λ°©μ•μ„\n"
     ]
    }
   ],
   "source": [
    "search_result = pdf_retriever.invoke(\"μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•λ“¤μ€?\")\n",
    "print('\\n\\n'.join([doc.page_content for doc in search_result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μ€ Prompt modification, Adapter methods, ParameterizationμΌλ΅ λ¶„λ¥λ©λ‹λ‹¤. Prompt modificationμ—λ” Hard prompt tuning, Soft prompt tuning, Prefix-tuningμ΄ μμµλ‹λ‹¤. Adapter methodsμ—λ” LLaMA-Adapter λ“±μ΄ μμµλ‹λ‹¤.\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf (page 9)\n"
     ]
    }
   ],
   "source": [
    "# κ²€μƒ‰ κ²°κ³Όλ¥Ό κΈ°λ°μΌλ΅ λ‹µλ³€μ„ μƒμ„±ν•©λ‹λ‹¤.\n",
    "answer = pdf_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•λ“¤μ€?\",\n",
    "        \"context\": search_result,\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# GraphState μƒνƒ μ •μ\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  # μ§λ¬Έ\n",
    "    context: Annotated[str, \"Context\"]  # λ¬Έμ„μ κ²€μƒ‰ κ²°κ³Ό\n",
    "    answer: Annotated[str, \"Answer\"]  # λ‹µλ³€\n",
    "    messages: Annotated[list, add_messages]  # λ©”μ‹μ§€(λ„μ λλ” list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"<document><content>{doc.page_content}</content><source>{doc.metadata['source']}</source><page>{int(doc.metadata['page'])+1}</page></document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def format_searched_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"<document><content>{doc['content']}</content><source>{doc['url']}</source></document>\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def format_task(tasks):\n",
    "    # κ²°κ³Όλ¥Ό μ €μ¥ν•  λΉ λ¦¬μ¤νΈ μƒμ„±\n",
    "    task_time_pairs = []\n",
    "\n",
    "    # λ¦¬μ¤νΈλ¥Ό μνν•λ©΄μ„ κ° ν•­λ©μ„ μ²λ¦¬\n",
    "    for item in tasks:\n",
    "        # μ½λ΅ (:) κΈ°μ¤€μΌλ΅ λ¬Έμμ—΄μ„ λ¶„λ¦¬\n",
    "        task, time_str = item.rsplit(\":\", 1)\n",
    "        # 'μ‹κ°„' λ¬Έμμ—΄μ„ μ κ±°ν•κ³  μ •μλ΅ λ³€ν™\n",
    "        time = int(time_str.replace(\"μ‹κ°„\", \"\").strip())\n",
    "        # ν•  μΌκ³Ό μ‹κ°„μ„ νν”λ΅ λ§λ“¤μ–΄ λ¦¬μ¤νΈμ— μ¶”κ°€\n",
    "        task_time_pairs.append((task, time))\n",
    "\n",
    "    # κ²°κ³Ό μ¶λ ¥\n",
    "    return task_time_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import messages_to_history\n",
    "\n",
    "\n",
    "# λ¬Έμ„ κ²€μƒ‰ λ…Έλ“\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # μ§λ¬Έμ„ μƒνƒμ—μ„ κ°€μ Έμµλ‹λ‹¤.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # λ¬Έμ„μ—μ„ κ²€μƒ‰ν•μ—¬ κ΄€λ ¨μ„± μλ” λ¬Έμ„λ¥Ό μ°Ύμµλ‹λ‹¤.\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    # κ²€μƒ‰λ λ¬Έμ„λ¥Ό ν•μ‹ν™”ν•©λ‹λ‹¤.(ν”„λ΅¬ν”„νΈ μ…λ ¥μΌλ΅ λ„£μ–΄μ£ΌκΈ° μ„ν•¨)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # κ²€μƒ‰λ λ¬Έμ„λ¥Ό context ν‚¤μ— μ €μ¥ν•©λ‹λ‹¤.\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# λ‹µλ³€ μƒμ„± λ…Έλ“\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    # μ§λ¬Έμ„ μƒνƒμ—μ„ κ°€μ Έμµλ‹λ‹¤.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # κ²€μƒ‰λ λ¬Έμ„λ¥Ό μƒνƒμ—μ„ κ°€μ Έμµλ‹λ‹¤.\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # μ²΄μΈμ„ νΈμ¶ν•μ—¬ λ‹µλ³€μ„ μƒμ„±ν•©λ‹λ‹¤.\n",
    "    response = pdf_chain.invoke(\n",
    "        {\n",
    "            \"question\": latest_question,\n",
    "            \"context\": context,\n",
    "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "        }\n",
    "    )\n",
    "    # μƒμ„±λ λ‹µλ³€, (μ μ €μ μ§λ¬Έ, λ‹µλ³€) λ©”μ‹μ§€λ¥Ό μƒνƒμ— μ €μ¥ν•©λ‹λ‹¤.\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"messages\": [(\"user\", latest_question), (\"assistant\", response)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# κ·Έλν”„ μƒμ„±\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# λ…Έλ“ μ •μ\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "# μ—£μ§€ μ •μ\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # κ²€μƒ‰ -> λ‹µλ³€\n",
    "workflow.add_edge(\"llm_answer\", END)  # λ‹µλ³€ -> μΆ…λ£\n",
    "\n",
    "# κ·Έλν”„ μ§„μ…μ  μ„¤μ •\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# μ²΄ν¬ν¬μΈν„° μ„¤μ •\n",
    "memory = MemorySaver()\n",
    "\n",
    "# μ»΄νμΌ\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "π”„ Node: \u001b[1;36mretrieve\u001b[0m π”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μΌλ΅λ” Prompt \n",
      "modification, Adapter methods, Parameterization μΌ\n",
      "λ΅ λ¶„λ¥ν•κ³  μλ‹¤ . Prompt modification μ€ Hard \n",
      "prompt tuning κ³Ό Soft prompt tuning, Prefix-tuning μ΄ \n",
      "μλ‹¤. Adapter methods λ” LLaMA-Adapter λ“±μ΄ \n",
      "μμΌλ©° Adapterλ¥Ό ν†µν• PEFTλ΅ μ „μ²΄ λ¨λΈμ νμΈ\n",
      "νλ‹ λ¶€μ‘μ©μ„ μµμ†ν™”ν•κΈ° μ„ν•΄ λ¨λ“ν™”ν• νλΌ\n",
      "λ―Έν„°λ¥Ό <κ·Έλ¦Ό 6>κ³Ό κ°™μ΄ μ¶”κ°€ μ‚½μ…ν•μ—¬ ν•™μµν•λ‹¤ . \n",
      "ν•λ‚μ Adapter λ¨λ“μ€ Bottleneck Layer λ¥Ό μ¤‘μ‹¬\n",
      "μΌλ΅ Down-projection κ³Ό Up-projection μ μ„ ν•λ³€\n",
      "ν™μ„ μν–‰ν•κ³  νμΈνλ‹ κ³Όμ •μ—μ„ Pre-trained LLM\n",
      "μ€ Frozenλλ‹¤.\n",
      "<κ·Έλ¦Ό 6> Adapter methods</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>10</page></document>\n",
      "<document><content>λ€ν•΄ μ‚¬μ „ ν•™μµλλ©° νμΈνλ‹ , In-context learning, \n",
      "Zero/one/few-shot learning κ°™μ€ κΈ°μ μ„ μ‚¬μ©ν•λ‹¤\n",
      "(Dilmegani, 2023). μ‚¬μ „ν•™μµ ν›„μ—λ” λ¨λΈ μ„±λ¥μ„ \n",
      "μΈ΅μ •ν•κΈ° μ„ν• ν•™μµ λ°μ΄ν„° μ„ΈνΈλ΅ μ‚¬μ©λμ§€ μ•μ€ \n",
      "ν…μ¤νΈ λ°μ΄ν„° μ„ΈνΈμ—μ„ λ¨λΈμ„ ν‰κ°€ν•κ³  ν‰κ°€ κ²°κ³Όμ— λ”°λΌ λ¨λΈμ μ„±λ¥μ„ ν–¥μƒμ‹ν‚¤κΈ° μ„ν•΄ ν•\n",
      "μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•κ±°λ‚ , μ•„ν‚¤ν…μ²λ¥Ό λ³€κ²½ν•\n",
      "κ±°λ‚, μ¶”κ°€ λ°μ΄ν„°μ— λ€ν• κµμ΅μ„ ν†µν•΄ μΌλ¶€ νμΈ\n",
      "νλ‹μ„ ν•λ‹¤ (μ •μ²μ , 2023d). μ΄λ ‡κ² νμΈνλ‹ λ \n",
      "μ–Έμ–΄ λ¨λΈ (Fine-tuned Language Model, FLM) μ€ \n",
      "λ‹¤μ–‘ν• λ„λ©”μΈ νΉν™”λ μ†κ·λ¨ μ–Έμ–΄ λ¨λΈ (SLM)λ΅ \n",
      "ν™μ©λλ‹¤ .\n",
      "2.2.1. μµμ‹  νμΈνλ‹ (Fine Tuning)\n",
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μΌλ΅λ” Prompt \n",
      "modification, Adapter methods, Parameterization μΌ</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>10</page></document>\n",
      "<document><content>λ“¤μ„ Full Fine-tuning μ„ ν•κΈ°μ—λ” μ»΄ν“¨ν… μ†μ¤κ°€ \n",
      "λ§¤μ° ν¬κΈ° λ•λ¬Έμ— LoRAμ™€ κ°™μ΄ κΈ°μ΅΄μ Pre-trained \n",
      "Layerμ κ°€μ¤‘μΉλ” κ³ μ •ν•κ³  , μƒλ΅μ΄ λ μ΄μ–΄μ κ°€\n",
      "μ¤‘μΉλ§μ„ ν•™μµμ„ μ‹ν‚¤λ”λ°λ„ , μ‹¤μ  μ„±λ¥μ μ°¨μ΄\n",
      "κ°€ λ§μ§€ μ•μ€ κ²ƒμΌλ΅ κ²€μ¦λ¨μ— λ”°λΌ μµκ·Όμ—λ” λ¨\n",
      "λ“  λ§¤κ°λ³€μλ¥Ό νλ‹ν•λ” κ²ƒμ΄ μ•„λ‹ μ‚¬μ „ ν›λ ¨λ \n",
      "LLMμ— μ†μμ μƒλ΅μ΄ λ§¤κ°λ³€μλ¥Ό μ¶”κ°€ν•κ³  , μ¶”\n",
      "κ°€λ λ§¤κ°λ³€μλ§ νμΈνλ‹ν•μ—¬ μ μ€ λΉ„μ©μΌλ΅ \n",
      "λ” λ‚μ€ μ„±λ¥μ„ λ°νν•λ„λ΅ ν•λ” PEFT(Parameter-\n",
      "Efficient Fine-Tuning) λ°©λ²•μ„ μ£Όλ΅ μ‚¬μ©ν•λ‹¤ (Raschka, \n",
      "2023). \n",
      "λ€ν‘μ μΈ κ²ƒμΈ LoRAλ” LLMμ μΌλ¶€ Weight \n",
      "Matrixλ“¤μ— λ€ν•΄μ„λ§ μ¶”κ°€μ μΈ ν•™μµμ„ ν—μ©ν•λ©° \n",
      "κ°κ°μ Transformer Layer λ‚΄μ—μ„ μΌλ¶€μ Weight \n",
      "Matrixμ— λ€ν•΄ νμΈνλ‹ λ€μƒμ„ κ²°μ •ν•λ©° ν•΄λ‹Ή \n",
      "<κ·Έλ¦Ό 4> LLMμ Fine-tuning</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>9</page></document>\n",
      "<document><content>SFT) λ¨λΈμ„ μƒμ„±ν•κ³  ν›λ ¨ν•  μ μλ„λ΅ SFTTrainer\n",
      "μ— ν•„μ”ν• κµ¬μ„± μ”μ†λ“¤μ„ μ κ³µν•κ³  , μ΄λ” λ¨λΈ , \n",
      "λ°μ΄ν„°μ…‹ , Lora μ„¤μ •, ν† ν¬λ‚μ΄μ € , κ·Έλ¦¬κ³  ν›λ ¨ λ§¤κ°\n",
      "λ³€μ λ“±μ„ ν¬ν•¨ν•λ‹¤ .\n",
      "<κ·Έλ¦Ό 13> SFT parameters\n",
      "λ§μ§€λ§‰μ€ <κ·Έλ¦Ό 14>μ™€ κ°™μ΄ λ¨λΈ ν•™μµμ μμ„\n",
      "λ΅ μ΄λ£¨μ–΄ μ§€λ”λ° PLMμ— μ¶”κ°€μ μΈ λ°μ΄ν„°μ…‹μ„ \n",
      "ν•™μµν•λ” νμΈνλ‹ μ‹¤ν–‰ μ½”λ“ λ° κ²°κ³Όμ΄λ‹¤ . \n",
      "<κ·Έλ¦Ό 14> νμΈνλ‹ ν•™μµ μ‹¤ν–‰μ΄ μ½”λ“λ” PEFT λ¨λΈμ μΊμ‹ μ‚¬μ© μ—¬λ¶€λ¥Ό λΉ„\n",
      "ν™μ„±ν™”ν•κ³  , κ·Έ ν›„μ— νΈλ μ΄λ„λ¥Ό μ‚¬μ©ν•μ—¬ λ¨λΈμ„  \n",
      "ν›λ ¨μ‹ν‚¤λ” κ³Όμ •μ„ λ‚νƒ€λ‚΄λ” κ²ƒμΌλ΅ <κ·Έλ¦Ό 12> \n",
      "ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ—μ„ β€max_steps = 60β€™ μΌλ΅ \n",
      "μ„¤μ •ν•μ—¬ ν•™μµμ΄ μ§„ν–‰λλ” μ΄ μ¤ν… νμκ°€ 60μ΄ \n",
      "μ™„λ£λ κ²ƒμ„ λ³Ό μ μμΌλ©° , νμΈνλ‹λ β€Mistral-\n",
      "7B-Fine-tuning-Insuranceβ€™ FLM μ΄ λ΅μ»¬ λ“λΌμ΄λΈμ—  \n",
      "μ €μ¥λ κ²ƒμ„ ν™•μΈν•  μ μλ‹¤ . μ΄λ ‡κ² μƒμ„±λ FLMμ€</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>22</page></document>\n",
      "<document><content>λ„λ©”μΈ νΉν™” LLM: Mistral 7Bλ¥Ό ν™μ©ν• κΈμµ μ—…λ¬΄λ¶„μ•Ό νμΈνλ‹ λ° ν™μ© λ°©λ²•\n",
      "σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° \n",
      "113μ„ν• ν•™μµ μ„¤μ •μ„ μ μ–΄ν•λ©° , ν•μ΄νΌνλΌλ―Έν„° λ° \n",
      "ν•™μµ μ „λµμ— κ΄€λ ¨λ λ‹¤μ–‘ν• μ”μ†λ¥Ό μ΅°μ •ν•  μ μλ‹¤ . \n",
      "λν• <κ·Έλ¦Ό 13>μ€ Hugging Face μ TRL(Transformer \n",
      "Reinforcement Learning) λΌμ΄λΈλ¬λ¦¬κ°€ μ‚¬μ©μ μΉν™”\n",
      "μ μΈ APIλ¥Ό μ κ³µν•μ—¬ μµμ†ν•μ μ½”λ”©μΌλ΅ λ°μ΄ν„°μ…‹\n",
      "μ—μ„ μ§€λ„ν•™μµ νμΈνλ‹ (Supervised Fine-Tuning, \n",
      "SFT) λ¨λΈμ„ μƒμ„±ν•κ³  ν›λ ¨ν•  μ μλ„λ΅ SFTTrainer\n",
      "μ— ν•„μ”ν• κµ¬μ„± μ”μ†λ“¤μ„ μ κ³µν•κ³  , μ΄λ” λ¨λΈ ,</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>22</page></document>\n",
      "<document><content>μ • μ² μ\n",
      "σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ°  σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° σ° \n",
      "114λ‹¤λ¥Έ μ§λ¬ΈμΈ β€μ„ λ¬Όμ΄ λ­μ•Ό ?β€ λΌκ³  μ§λ¬Έν–μ„ λ•λ„ \n",
      "PLMμ—μ„λ” μΌλ°μ μΈ μ±… , ν΄λ€μ „ν™” λ“±κ³Ό κ°™μ€ μ \n",
      "ν’ μ„ λ¬Όμ— λ€ν• λ‹µλ³€μ„ ν–μΌλ‚ FLM PEFT λ¨λΈ\n",
      "μ—μ„λ” κΈμµ μ©μ–΄μ— μ ν•©ν• β€λ―Έλμ μƒν’μ„ ν„μ¬\n",
      "μ—μ„ κ±°λν•λ” κ²ƒμ…λ‹λ‹¤ .β€λΌκ³  μƒμ„±ν•΄μ£Όλ” κ²ƒμ„ \n",
      "ν™•μΈν•  μ μμ—λ‹¤ . \n",
      "<κ·Έλ¦Ό 16> PEFT Model ν…μ¤νΈ\n",
      "μ§€κΈκΉμ§€ PLMμ— κΈμµ νΉν™” λ°μ΄ν„°μ…‹ μ¶”κ°€ν•μ—¬  \n",
      "FLMμΌλ΅ νμΈνλ‹ν•λ” λ°©λ²•κ³Ό κ²°κ³Όλ¥Ό κ²€μ¦ν•λ” \n",
      "λ°©λ²•μ„ μ•μ•„λ³΄μ•λ‹¤ . λ³Έ κµ¬ν„ μ‚¬λ΅€λ¥Ό μ°Έμ΅°ν•λ‹¤λ©΄ \n",
      "λ„λ©”μΈμ λ¶„λ¥μ— λ”°λΌ , κ·Έλ¦¬κ³  μ—…λ¬΄ ν¬κΈ° μ •λ„μ— \n",
      "λ”°λΌ μ—…λ¬΄μ— λ§κ² κ΄€λ ¨λ LLMμ„ λ‹¤μ–‘ν•κ² νμΈ</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>23</page></document>\n",
      "<document><content>7B-Fine-tuning-Insuranceβ€™ FLM μ΄ λ΅μ»¬ λ“λΌμ΄λΈμ—  \n",
      "μ €μ¥λ κ²ƒμ„ ν™•μΈν•  μ μλ‹¤ . μ΄λ ‡κ² μƒμ„±λ FLMμ€ \n",
      "κ΄€λ ¨μ—…λ¬΄μ— λ§κ² μμ λ΅­κ² λ΅μ»¬μ—μ„ ν™μ© μ μλ‹¤ .\n",
      "4.1.4. FLM ν…μ¤νΈ\n",
      "μƒμ„±λ FLMμ„ ν…μ¤νΈν•κΈ° μ„ν•΄ <κ·Έλ¦Ό 15>μ™€ \n",
      "κ°™μ΄ PEFT FLM μ„ λ΅λ“ ν•λ” κ³Όμ •μ„ λ‚νƒ€λ‚΄κ³  \n",
      "μλ‹¤. FLM λ¨λΈμ— <κ·Έλ¦Ό 16>κ³Ό κ°™μ΄ μ§λ¬Έν•μ—¬ \n",
      "μ •μƒμ μΌλ΅ λ¨λΈμ΄ μ‘λ™ν•λ” κ²ƒμ„ ν™•μΈν•  μ μλ‹¤ .\n",
      "<κ·Έλ¦Ό 15> PEFT Model λ΅λ“\n",
      "μ‚¬μ „ ν•™μµλ PLMκ³Ό PEFT νλ‹λ PLMμ— β€κ³¨ν”„\n",
      "λ³΄ν— μ•λ ¤μ¤ β€™λΌλ” μ§λ¬Έμ„ ν–μ„ λ• νμΈνλ‹λκΈ°\n",
      "μ „ PLM λ¨λΈμ—μ„λ” λ³΄ν— λ‚΄μ©μ΄ μ•„λ‹ μ „ν€ λ‹¤λ¥Έ \n",
      "λ‹µλ³€μ„ μƒμ„±ν• κ²ƒ λΉ„ν•΄ FLMμ—μ„λ” λ³΄ν—μ— νΉν™”\n",
      "λ λ°μ΄ν„°μ…‹μΌλ΅ PEFT νμΈνλ‹λ λ¨λΈμ—μ„λ” \n",
      "λ³΄ν—μ— κ΄€λ ¨λ λ‚΄μ©μΌλ΅ ν•™μµλ λ‹µλ³€ (μμ‹: β€κ³¨ν”„\n",
      "μ¥μ—μ„μ μ‚¬κ³ λ¥Ό λ€μƒμΌλ΅ ,β€)μ„ μƒμ„±ν•μ€μΌλ©° , λ</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>22</page></document>\n",
      "<document><content>κΈ°λ³Έλ¨λΈλ΅ λ‘κ³  Instruction tuning ν• λ¨λΈμ΄λ‹¤ .3. μ—°κµ¬ λ°©λ²•\n",
      "λ³Έ μ¥μ—μ„λ” κΈμµ λ„λ©”μΈμ— νΉν™”λ LLMμ μƒ\n",
      "μ„±μ„ μ„ν• μ²΄κ³„μ μΈ μ ‘κ·Ό λ°©λ²•μ„ μ μ‹ν•λ‹¤ . νμΈ\n",
      "νλ‹ μ§„ν–‰ λ°©λ²•μ€ <κ·Έλ¦Ό 8>μ—μ„ μ μ‹ν•λ” μ μ°¨\n",
      "λ΅ μ§„ν–‰ν•λ©° λ°μ΄ν„° μμ§‘κ³Ό μ „μ²λ¦¬ λ‹¨κ³„μ—μ„λ” \n",
      "κΈμµ νΉν™” λ°μ΄ν„°μ…‹μ„ μ„ μ •ν•κ³  , ν¨κ³Όμ μΈ μ „μ²\n",
      "λ¦¬ λ°©λ²•μ„ λ„μ…ν•λ‹¤ . λ¨λΈ μ„ μ •κ³Ό νμΈνλ‹ μ μ°¨\n",
      "μ—μ„λ” μ μ ν• μ‚¬μ „ ν›λ ¨λ LLMμΈ PLMμ„ μ„ μ •\n",
      "ν•κ³ , ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•μ—¬ νλ‹ν•λ‹¤ . κΈ\n",
      "μµ λ¶„μ•Όμ νΉμ„±μ„ κ³ λ ¤ν• νμΈνλ‹ κ³ λ ¤μ‚¬ν•­μ—\n",
      "μ„λ” κΈμµ λ°μ΄ν„° νΉμ„± , λ„λ©”μΈ νΉν™” μ–΄ν , νμΈ\n",
      "νλ‹ μ•κ³ λ¦¬μ¦μ— λ€ν• κ³ λ ¤μ‚¬ν•­μ„ λ‹¤λ£¬λ‹¤ . μ΄ν›„ \n",
      "κΈμµ λ¶„μ•Όλ¥Ό μ„ν• LLM κµ¬μ„±μ—μ„λ” μ²μλ¶€ν„° ν•™\n",
      "μµν•λ” λ°©λ²•κ³Ό μ΄λ―Έ μ΅΄μ¬ν•λ” λ¨λΈμ„ νλ‹ν•λ” \n",
      "λ°©λ²•μ— λ€ν• κµ¬μ„± λ°©μ•μ„ μ†κ°ν•λ‹¤ . λ§μ§€λ§‰μΌλ΅ , \n",
      "ν‰κ°€ κΈ°μ¤€κ³Ό μ§€ν‘μ—μ„λ” μ •λ‰μ  μ„±λ¥ μ§€ν‘μ™€ μ •μ„±μ  \n",
      "μ„±λ¥ μ§€ν‘λ¥Ό ν™μ©ν• λ¨λΈμ ν‰κ°€κΈ°μ¤€μ„ κ°€μ΄λ“</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>11</page></document>\n",
      "<document><content>ν™•μΈν•κ³ \n",
      ", ν•™μµ κ³Όμ •μ—μ„ λ°μƒν• λ¬Έμ λ¥Ό μ‹ \n",
      "μ†ν•κ² νμ•…ν•  μ μλ‹¤ .\n",
      "7)ν•μ΄νΌνλΌλ―Έν„° νλ‹ : ν•μ΄νΌνλΌλ―Έν„° μµ\n",
      "μ ν™” λ„κµ¬λ¥Ό ν™μ©ν•μ—¬ μλ™μΌλ΅ μµμ μ ν•μ΄\n",
      "νΌνλΌλ―Έν„° μ΅°ν•© μ°ΎκΈ°λ¥Ό ν•κ² λλ”λ° Grid \n",
      "Search λλ” Random Search μ™€ κ°™μ€ νλ‹ \n",
      "κΈ°λ²•μ„ μ‚¬μ©ν•μ—¬ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•\n",
      "λ©΄ λ¨λΈμ μ„±λ¥μ„ κ·Ήλ€ν™”ν•  μ μλ‹¤ .\n",
      "μ΄λ ‡κ² λ¨λΈ νμΈνλ‹ μ‹¤ν–‰ ν™κ²½ μ„¤μ •μ€ μ‹¤ν—\n",
      "μ ν¨μ¨μ„± λ° λ¨λΈμ μλ ΄μ„ λ³΄μ¥ν•κΈ° μ„ν•΄ μ‹ μ¤‘\n",
      "ν• κ³„νκ³Ό κ°λ…μ΄ ν•„μ”ν•λ‹¤ . μ„¤μ •λ ν™κ²½μ—μ„ μ\n",
      "ν–‰λλ” μ‹¤ν— κ²°κ³Όλ¥Ό κΈ°λ°μΌλ΅ κ³„μ†ν•΄μ„ μµμ ν™”\n",
      "λ¥Ό μ§„ν–‰ν•΄μ•Ό ν•λ‹¤ .\n",
      "3.3. κΈμµ νΉν™” LLM νμΈνλ‹μ‹ κ³ λ ¤μ‚¬ν•­\n",
      "κΈμµ λ¶„μ•Όμ LLM νμΈνλ‹μ€ λ‹¤μκ³Ό κ°™μ€ λ‹¨\n",
      "κ³„λ¥Ό ν¬ν•¨ν•μ—¬ μ§„ν–‰ν•λ‹¤ .\n",
      "3.3.1. κΈμµ λ°μ΄ν„° νΉμ„±μ„ κ³ λ ¤ν• λ„λ©”μΈ νΉν™” \n",
      "μ–΄ν κµ¬μ¶•\n",
      "κΈμµ λ°μ΄ν„°λ” λ…νΉν• νΉμ„±μ„ μ§€λ‹κ³  μμΌλ©° , \n",
      "μ£Όμ‹ κ°€κ²©μ λ³€λ™ , κΈμµ λ‰΄μ¤μ κ°μ„± λ“± λ‹¤μ–‘ν• \n",
      "μΈ΅λ©΄μ΄ λ¨λΈμ— μν–¥μ„ λ―ΈμΉλ‹¤ . λ”°λΌμ„ , μ΄λ¬ν•</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>16</page></document>\n",
      "<document><content>νλ‹¨μ„ λ‚΄λ¦¬κΈ° μ„ν•μ—¬ LLMμ„ ν™μ©ν•λ‹¤ (μ¥κ°‘μ , \n",
      "2023). μ΄λ ‡κ² κ°€μ¥ λ¦κ² μ‹ κΈ°μ μ„ λ„μ…ν•λ” κΈ\n",
      "μµκ¶μ—μ„λ„ μƒμ„±ν• AIμΈ LLMμ ν™μ©μ΄ ν™•λ€λ\n",
      "κ³  μλ‹¤ . ν•μ§€λ§ μΌλ°μ μΈ LLMμ„ κ°€μ§€κ³  λ„μ…μ„ λ„λ©”μΈ νΉν™” LLM: Mistral 7B λ¥Ό ν™μ©ν• \n",
      "κΈμµ μ—…λ¬΄λ¶„μ•Ό νμΈνλ‹ λ° ν™μ© λ°©λ²•\n",
      "μ •μ²μ\n",
      "μ‚Ό μ„± S D S  A I  A u t o m a t i o n  T e a m\n",
      "(csu.jeong@samsung.com)\n",
      "β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤β€¤\n",
      "μµκ·Ό μ‚¬μ „ν•™μµλ λ²”μ©μ μΈ LLM(Large Language Model) μ¶μ‹κ°€ ν™λ°ν•΄μ§€κ³  μμ§€λ§ , λ„λ©”μΈ νΉν™” νμΈνλ‹λ LLM μ—°\n",
      "κµ¬μ™€ μƒμ„± λ°©λ²•μ„ μ μ‹ν•λ” κ²ƒμ€ λ¶€μ΅±ν• μ‹¤μ •μ΄λ‹¤ . λ³Έ μ—°κµ¬λ” λ„λ©”μΈμ— νΉν™”λ LLMμ νμΈνλ‹κ³Ό ν™μ©μ— λ€ν• λ°©μ•μ„</content><source>../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf</source><page>2</page></document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "π”„ Node: \u001b[1;36mllm_answer\u001b[0m π”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μ€ Prompt modification, Adapter methods, ParameterizationμΌλ΅ λ¶„λ¥λλ©°, Prompt modificationμ—λ” Hard prompt tuning, Soft prompt tuning, Prefix-tuningμ΄ μλ‹¤. Adapter methodsμ μμ‹λ΅λ” LLaMA-Adapterκ°€ μλ‹¤.\n",
      "\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)\n",
      "('user', 'μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•λ“¤μ€?')\n",
      "('assistant', 'μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μ€ Prompt modification, Adapter methods, ParameterizationμΌλ΅ λ¶„λ¥λλ©°, Prompt modificationμ—λ” Hard prompt tuning, Soft prompt tuning, Prefix-tuningμ΄ μλ‹¤. Adapter methodsμ μμ‹λ΅λ” LLaMA-Adapterκ°€ μλ‹¤.\\n\\n**Source**\\n- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import invoke_graph, stream_graph, random_uuid\n",
    "\n",
    "# config μ„¤μ •(μ¬κ·€ μµλ€ νμ, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# μ§λ¬Έ μ…λ ¥\n",
    "inputs = GraphState(question=\"μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•λ“¤μ€?\")\n",
    "\n",
    "# κ·Έλν”„ μ‹¤ν–‰\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "π”„ Node: \u001b[1;36mllm_answer\u001b[0m π”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μ€ Prompt modification, Adapter methods, ParameterizationμΌλ΅ λ¶„λ¥λλ©°, Prompt modificationμ—λ” Hard prompt tuning, Soft prompt tuning, Prefix-tuningμ΄ μλ‹¤. Adapter methodsμ μμ‹λ΅λ” LLaMA-Adapterκ°€ μλ‹¤.\n",
      "\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)"
     ]
    }
   ],
   "source": [
    "# κ·Έλν”„λ¥Ό μ¤νΈλ¦¬λ° μ¶λ ¥\n",
    "stream_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•λ“¤μ€?\n",
      "============================================================\n",
      "Answer:\n",
      "μµκ·Όμ PEFT νμΈνλ‹ λ°©λ²•μ€ Prompt modification, Adapter methods, ParameterizationμΌλ΅ λ¶„λ¥λλ©°, Prompt modificationμ—λ” Hard prompt tuning, Soft prompt tuning, Prefix-tuningμ΄ μλ‹¤. Adapter methodsμ μμ‹λ΅λ” LLaMA-Adapterκ°€ μλ‹¤.\n",
      "\n",
      "**Source**\n",
      "- ../data/Domain-specialized-LLM-Financial-fine-tuning-and-utilization-method-using-Mistral-7B.pdf(page 10)\n"
     ]
    }
   ],
   "source": [
    "outputs = app.get_state(config).values\n",
    "\n",
    "print(f'Question: {outputs[\"question\"]}')\n",
    "print(\"===\" * 20)\n",
    "print(f'Answer:\\n{outputs[\"answer\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-6XMr01W1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
